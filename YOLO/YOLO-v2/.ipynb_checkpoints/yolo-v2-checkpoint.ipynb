{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "#解析使用\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import imageio\n",
    "from skimage import transform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC #类别分类使用\n",
    "from sklearn.linear_model import Ridge #bounding-box回归\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TEST_DATA_PATH = '../../../tensorflow2/dataset/VOC2012test/JPEGImages/'\n",
    "\n",
    "TRAIN_XML_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'\n",
    "TEST_XML_PATH = '../../../tensorflow2/dataset/VOC2012test/Annotations/'\n",
    "\n",
    "CLASSES_NUM = 20\n",
    "\n",
    "STR = [\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}\n",
    "#STR2LABEL = {value:idx for idx , value in enumerate(STR)}\n",
    "\n",
    "STR2LABEL['none'] = 'none' #先不使用part部分 只进行naive目标检测\n",
    "\n",
    "#目标检测相关\n",
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "#SVM相关\n",
    "SVM_IoU_THRESHOLD = 0.3\n",
    "\n",
    "#NMS相关\n",
    "NMS_IoU_THRESHOLD = 0.3 #or ~0.5\n",
    "\n",
    "#bbox回归\n",
    "BBOX_REGRESS_IoU_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file_names_train = glob(TRAIN_XML_PATH + '*') #所有的xml文件 完整路径\n",
    "\n",
    "#从xml文件中读出图片相关的信息\n",
    "\n",
    "def xml_parse(xml_file):\n",
    "    '''\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "    xml文件中的shape格式为 (width height 3)\n",
    "    '''\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    \n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        #name\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        name_box = name_list[0].childNodes[0].data\n",
    "\n",
    "        #bounding box points\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        x1_list = bndbox[0].getElementsByTagName('xmin')\n",
    "        x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "        y1_list = bndbox[0].getElementsByTagName('ymin')\n",
    "        y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "        x2_list = bndbox[0].getElementsByTagName('xmax')\n",
    "        x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "        y2_list = bndbox[0].getElementsByTagName('ymax')\n",
    "        y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "        crop_box = [x1,x2,y1,y2]\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    #crop_box:[x1 x2 y1 y2]\n",
    "    return filename , name_boxes , np.array(crop_boxes) #filename调试使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xml_parse(xml_file_names_train[897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "    '''\n",
    "    图片的真实信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH+'*') #训练全路径信息\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        if not img_path_name:\n",
    "            img_path_name = np.random.choice(self.img_file_names_train) #随机选择一张图片\n",
    "            #img_path_idx = np.random.randint(0 , high = len(self.img_file_names_train)) #随机索引\n",
    "\n",
    "        img_arr = cv2.imread(img_path_name) #BGR height*width*chanel\n",
    "        \n",
    "        xml_file_name = TRAIN_XML_PATH + img_path_name[-15:-4] +  '.xml'\n",
    "        \n",
    "        _ , name_boxes , crop_boxes = xml_parse(xml_file_name)\n",
    "        \n",
    "        labels = [] #存储与bndbox对应的 label信息\n",
    "\n",
    "        for i in range(len(crop_boxes)): #多个object \n",
    "            labels.append(STR2LABEL.get(name_boxes[i] , 'none'))\n",
    "        \n",
    "        return img_arr , labels , crop_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reference: github:sualab\n",
    "class Img_generator(object):\n",
    "    def __init__(self):\n",
    "        self.img_loader = Image()\n",
    "   \n",
    "        \n",
    "    def get_train_proposal(self , ground_truth_labels , ground_truth_coord , img_shape): #img_shape:[height width 3] \n",
    "        #[[1.3221,1.73145],[3.19275,4.00944],[5.05587,8009892],[9.47112,4.84053],[11.2364,10.0071]]\n",
    "        #将上述的anchor信息（13*13坐标系中） 乘以32 转换为416*416坐标系中\n",
    "        anchors = [[42.3072,55.4064],[102.168,128.30208],[161.78784,256.316544],[303.07584,154.89696],[359.5648,320.2272]] #只有宽高信息\n",
    "        #grid cell尺寸 feature map尺寸\n",
    "        grid_w = 13\n",
    "        grid_h = 13\n",
    "        \n",
    "        oh = img_shape[0] #原图height\n",
    "        ow = img_shape[1] #原图width\n",
    "        \n",
    "        labels = []\n",
    "        label = np.zeros((13 , 13 , 5 , 5+20))\n",
    "        \n",
    "        for idx , (x_min , x_max , y_min , y_max) in enumerate(ground_truth_coord):\n",
    "            x_min , y_min , x_max , y_max = x_min/ow , y_min/oh , x_max/ow , y_max/oh #变为在原图中的比例\n",
    "            x_min , y_min , x_max , y_max = np.clip([x_min , y_min , x_max , y_max] , a_min=0.0 , a_max=1.0)\n",
    "        \n",
    "            anchor_boxes = np.array(anchors) / np.array([ow , oh]) #将anchors转换为在原图中的比例\n",
    "            \n",
    "            #计算iou可以直接进行计算 将两个box的中点移动到同一点 因为由聚类得到的5个先验框 是聚类得到的 可以挪动到任何地方 普适性\n",
    "            best_anchor = self._get_best_anchor(anchor_boxes , [x_max-x_min , y_max-y_min])\n",
    "            \n",
    "            #当前ground truth的中点落在哪一个grid cell中\n",
    "            cx = int(np.floor((x_min+x_max)/2) * grid_w)\n",
    "            cy = int(np.floor((y_min+y_max)/2) * grid_h)\n",
    "            \n",
    "            label[cy , cx , best_anchor , 0:4] = [x_min , y_min , x_max , y_max] #训练集使用的是缩放成比例的ground truth信息\n",
    "            label[cy , cx , best_anchor , 4:5] = 1.0\n",
    "            label[cy , cx , best_anchor , 5+ground_truth_labels[idx]] = 1.0\n",
    "        \n",
    "        labels.append(label)\n",
    "        \n",
    "        return np.array(labels)\n",
    "    \n",
    "    \n",
    "    def _get_best_anchor(self , anchors , box_wh):\n",
    "        '''\n",
    "        此处使用的坐标均在(0 1)范围内\n",
    "        \n",
    "        此处计算iou的时候 不考虑坐标位置 只考虑height and width\n",
    "        '''\n",
    "        box_wh = np.array(box_wh)\n",
    "        \n",
    "        best_iou = 0.0\n",
    "        best_anchor = 0 #最好anchor的索引\n",
    "        \n",
    "        for k , anchor in enumerate(anchors):\n",
    "            intersect_wh = np.maximum(np.minimum(box_wh , anchor) , 0.0)\n",
    "            intersect_area = intersect_wh[0] * intersect_wh[1]\n",
    "            \n",
    "            box_area = box_wh[0] * box_wh[1]\n",
    "            anchor_area = anchor[0] * anchor[1]\n",
    "            \n",
    "            iou = intersect_area / (box_area+anchor_area-intersect_area)\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_anchor = k\n",
    "            \n",
    "        return best_anchor\n",
    "    \n",
    "    def load(self , img_path_name):\n",
    "        '''\n",
    "        img_path_name:绝对路径\n",
    "        '''\n",
    "        \n",
    "        #图片数据 label ground_truth坐标信息\n",
    "        img_arr , ground_truth_labels , ground_truth_coord = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        labels = self.get_train_proposal(ground_truth_labels , ground_truth_coord , img_arr.shape)\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (416 , 416))\n",
    "        img_arr = img_arr / 127.5 - 1 #对下面的get_train_proposal没有影响\n",
    "        \n",
    "        '''\n",
    "        resize 并 归一化像素值\n",
    "        img_arr 为 BGR形式\n",
    "        '''\n",
    "        \n",
    "        #[R G B] [123.68 116.779 103.939]\n",
    "        #减去每个通道的像素平均值 归一化\n",
    "        #因为cv2打开的形式为BGR\n",
    "        #img_arr[:,:,0] = img_arr[:,:,0] - 103.939\n",
    "        #img_arr[:,:,1] = img_arr[:,:,1] - 116.779\n",
    "        #img_arr[:,:,2] = img_arr[:,:,2] - 123.680\n",
    "        \n",
    "        return np.expand_dims(img_arr , axis=0) , labels\n",
    "    \n",
    "    \n",
    "    def load_test(self , img_path_name):\n",
    "        img_arr = cv2.imread(img_path_name)\n",
    "        \n",
    "        img_arr_resized = cv2.resize(img_arr , (416 , 416))\n",
    "        img_arr_resized_norm = img_arr_resized / 127.5 - 1\n",
    "        \n",
    "        return np.expand_dims(img_arr_resized_norm , axis=0) , img_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        path = np.random.choice(self.img_file_names_train)\n",
    "        \n",
    "        x , labels = self.img_generator.load(path)\n",
    "    \n",
    "        return x , labels\n",
    "    \n",
    "    def get_batch_test(self , path):\n",
    "        \n",
    "        if not path:\n",
    "            #未指定path 从测试目录中随机选一张图片测试\n",
    "            path = np.random.choice(self.img_file_names_test)\n",
    "        \n",
    "        x , img_arr = self.img_generator.load_test(path)\n",
    "        \n",
    "        return x , img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DarkNet(object):\n",
    "    def __init__(self , is_training=True):\n",
    "        \n",
    "        self.x = tf.placeholder(dtype=tf.float32 , shape=[1 , 416 , 416 , 3])        \n",
    "        \n",
    "        self.build(is_training) #构建网络产生输出\n",
    "        \n",
    "        self.y = tf.placeholder(dtype=tf.float32 , shape=[1 , 13 , 13 , 5 , (5+20)])\n",
    "        self.loss(is_training)\n",
    "\n",
    "    def build(self , is_training):\n",
    "        #arch from paper\n",
    "        def _batch_norm(_input , is_training):\n",
    "            return slim.batch_norm(_input , is_training=is_training) #\n",
    "        \n",
    "        def _weight_variable(shape , name):\n",
    "            return tf.get_variable('weights_'+name , shape=shape , dtype=tf.float32 ,\n",
    "                                    initializer = tf.initializers.truncated_normal(stddev=0.01) , trainable = True)\n",
    "        \n",
    "        def _bias_variable(shape , name):\n",
    "            return tf.get_variable('biases_'+name , shape=shape , dtype=tf.float32 ,\n",
    "                                    initializer = tf.initializers.constant(0.0))\n",
    "        \n",
    "        def _conv(_input , num_outputs , kernel_size , stride=1 , padding='SAME' , name='default' , is_activation=True):\n",
    "            weight = _weight_variable(shape=[kernel_size , kernel_size , _input.get_shape().as_list()[-1] , num_outputs] , name=name)\n",
    "            biases = _bias_variable(shape=[num_outputs] , name=name)\n",
    "            \n",
    "            if is_activation:\n",
    "                #conv->norm->relu [->pooling]\n",
    "                return tf.nn.leaky_relu( _batch_norm( tf.nn.conv2d(_input , weight , strides=[1,stride,stride,1] , padding=padding) + biases , is_training) ,\n",
    "                                     alpha=0.1)\n",
    "            else:\n",
    "                #conv\n",
    "                return tf.nn.conv2d(_input , weight , strides=[1,stride,stride,1] , padding=padding) + biases\n",
    "                          \n",
    "        def _max_pool(_input , kernel_size=2 , stride=2 , padding='VALID'):\n",
    "            return slim.max_pool2d(_input , kernel_size=kernel_size , stride=stride)\n",
    "        \n",
    "        \n",
    "        #_conv中已放入batch-norm\n",
    "        #darknet-19\n",
    "        output = _conv(self.x , 32 , 3 , name='conv1')\n",
    "        output = _max_pool(output)\n",
    "           \n",
    "        output = _conv(output , 64 , 3 , name='conv2')              \n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        output = _conv(output , 128 , 3 , name='conv3')\n",
    "        output = _conv(output , 64 , 1 , name='conv4')\n",
    "        output = _conv(output , 128 , 3 , name='conv5')\n",
    "        output = _max_pool(output)\n",
    "                \n",
    "        output = _conv(output , 256 , 3 , name='conv6')\n",
    "        output = _conv(output , 128 , 1 , name='conv7')\n",
    "        output = _conv(output , 256 , 3 , name='conv8')\n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        output = _conv(output , 512 , 3 , name='conv9')\n",
    "        output = _conv(output , 256 , 1 , name='conv10')\n",
    "        output = _conv(output , 512 , 3 , name='conv11')\n",
    "        output = _conv(output , 256 , 1 , name='conv12')\n",
    "        output = _conv(output , 512 , 3 , name='conv13')\n",
    "        #(26 26 512)\n",
    "        fine_grained = output #细粒度\n",
    "        \n",
    "        output = _max_pool(output) #细粒度 passthrough layer需要\n",
    "        #此时shape为（13 13 512）\n",
    "        \n",
    "        output = _conv(output , 1024 , 3 , name='conv14')\n",
    "        output = _conv(output , 512 , 1 , name='conv15')\n",
    "        output = _conv(output , 1024 , 3 , name='conv16')\n",
    "        output = _conv(output , 512 , 1 , name='conv17')\n",
    "        output = _conv(output , 1024 , 3 , name='conv18')\n",
    "        \n",
    "        #detection arch\n",
    "        output = _conv(output , 1024 , 3 , name='conv19')\n",
    "        output = _conv(output , 1024 , 3 , name='conv20')\n",
    "        #(13 13 1024)\n",
    "        '''\n",
    "        细粒度与粗粒度合并\n",
    "        '''\n",
    "        fine_grained = _conv(fine_grained , 64 , 1 , name='passthrough')\n",
    "        #(26 26 64)\n",
    "        fine_grained = tf.space_to_depth(fine_grained , block_size=2)\n",
    "        #(13 13 256)\n",
    "        \n",
    "        output = tf.concat((fine_grained , output) , axis=-1) #(13 13 256+1024) == (13 13 1280)\n",
    "\n",
    "        output = _conv(output , 1024 , 3 , name='conv21')\n",
    "        \n",
    "        #最后一层不归一 不激活 不池化\n",
    "        output = _conv(output , (5*(20+5)) , 1 , name='conv22' , is_activation=False)\n",
    "        \n",
    "        self.output = tf.reshape(output , shape=(-1 , 13 , 13 , 5 , 25))\n",
    "        \n",
    "        \n",
    "    def loss(self , is_training):\n",
    "        '''\n",
    "        reference: github:sualab\n",
    "        '''        \n",
    "        loss_weights = [5.0 , 5.0 , 5.0 , 0.5 , 1.0]\n",
    "        grid_h = 13\n",
    "        grid_w = 13\n",
    "        num_classes = 20\n",
    "        \n",
    "        grid_wh = np.reshape([grid_w , grid_h] , [1,1,1,1,2]).astype(np.float32)\n",
    "        \n",
    "        anchors = np.array( [[42.3072,55.4064],[102.168,128.30208],[161.78784,256.316544],[303.07584,154.89696],[359.5648,320.2272]] ) #可以不需要进行np.array转换 直接可以用np函数处理\n",
    "        \n",
    "        cxcy = np.transpose([ np.tile(np.arange(grid_w) , grid_h) , np.repeat(np.arange(grid_h) , grid_w) ])\n",
    "        cxcy = np.reshape(cxcy , (1,grid_h , grid_w , 1 , 2))\n",
    "        \n",
    "        '''\n",
    "        将网络的输出进行切分\n",
    "        '''\n",
    "        txty = self.output[:,:,:,:,0:2]\n",
    "        twth = self.output[:,:,:,:,2:4]\n",
    "        confidence = tf.sigmoid(self.output[:,:,:,:,4:5])\n",
    "        class_probs = tf.nn.softmax(self.output[:,:,:,:,5:] , axis=-1)\n",
    "        \n",
    "        '''\n",
    "        下面的转换均在13*13的feature map坐标系中进行\n",
    "        '''\n",
    "        bxby = tf.sigmoid(txty) + cxcy\n",
    "        pwph = np.reshape(anchors , (1,1,1,5,2)) / 32 #先验框 缩放到13*13feature map坐标系中（32为ratio）\n",
    "        bwbh = pwph * tf.exp(twth)\n",
    "        \n",
    "        '''\n",
    "        转换为在13*13中的比例(0 1)范围之间\n",
    "        '''\n",
    "        nxny = bxby / grid_wh #中点坐标\n",
    "        nwnh = bwbh / grid_wh #宽高\n",
    "        \n",
    "        '''\n",
    "        得到左上 右下 坐标 依旧是在比例尺度上进行\n",
    "        '''\n",
    "        nx1ny1 = nxny - nwnh/2\n",
    "        nx2ny2 = nxny + nwnh/2\n",
    "        \n",
    "        self.pred_y = tf.concat( (nx1ny1 , nx2ny2 , confidence , class_probs) , axis=-1 ) #shape为 [batch_size 13 13 5 25]\n",
    "        \n",
    "        if is_training:\n",
    "            '''\n",
    "            如果是训练 下面有意义\n",
    "            测试 下面无意义\n",
    "            '''\n",
    "            \n",
    "            #下面可以计算的原因是因为 构建训练样本时的y 在confidence域出根据有无object放的0或1\n",
    "            num_object = tf.reduce_sum(self.y[... , :4:5] , axis=[1,2,3,4]) #计算一个batch中每一张图片中有多少物体（实际有多少物体）\n",
    "\n",
    "            max_nx1ny1 = tf.maximum(self.y[... , 0:2] , nx1ny1)\n",
    "            min_nx2ny2 = tf.minimum(self.y[... , 2:4] , nx2ny2)\n",
    "\n",
    "            intersect_wh = tf.maximum(min_nx2ny2 - max_nx1ny1 , 0.0) #计算ground truth与预测框相交区域的宽高\n",
    "            intersect_area = tf.reduce_prod(intersect_wh , axis=-1) #计算上述相交区域的面积\n",
    "            intersect_area = tf.where(tf.equal(intersect_area , 0.0) , tf.zeros_like(intersect_area) , intersect_area)\n",
    "\n",
    "            gt_box_area = tf.reduce_prod(self.y[... , 2:4] - self.y[... , 0:2] , axis=-1) #计算ground truth的面积\n",
    "            box_area = tf.reduce_prod(nx2ny2 - nx1ny1 , axis=-1)  #计算预测框的面积\n",
    "            iou = tf.truediv(intersect_area , (gt_box_area + box_area - intersect_area)) #计算ground truth与预测框的iou\n",
    "\n",
    "            sum_iou = tf.reduce_sum(iou , axis=[1,2,3] )\n",
    "            self.iou = tf.truediv(sum_iou , num_object) #求平均iou\n",
    "\n",
    "            gt_bxby = (self.y[... , 0:2] + self.y[... , 2:4]) * grid_wh / 2 #ground truth的中心坐标 转换至13*13坐标系中\n",
    "            gt_bwbh = (self.y[... , 0:2] - self.y[... , 0:2]) * grid_wh #ground truth的宽高 转换至13*13坐标系中\n",
    "\n",
    "            resp_mask = self.y[... , 4:5]\n",
    "            no_resp_mask = 1.0 - resp_mask\n",
    "\n",
    "            gt_confidence = resp_mask * tf.expand_dims(iou , axis=-1)\n",
    "            gt_class_probs = self.y[... , 5:]\n",
    "            \n",
    "            #坐标损失\n",
    "            loss_bxby = loss_weights[0] * resp_mask * tf.square(gt_bxby-bxby)\n",
    "            loss_bwbh = loss_weights[1] * resp_mask * tf.square(tf.sqrt(gt_bwbh) - tf.sqrt(bwbh))\n",
    "            #iou损失\n",
    "            loss_resp_conf =    loss_weights[2] * resp_mask    * tf.square(gt_confidence - confidence)\n",
    "            loss_no_resp_conf = loss_weights[3] * no_resp_mask * tf.square(gt_confidence  - confidence)\n",
    "            #softmax概率损失\n",
    "            loss_class_probs =  loss_weights[4] * resp_mask * tf.square(gt_class_probs - class_probs)\n",
    "\n",
    "            total_loss = tf.concat((loss_bxby , loss_bwbh , loss_resp_conf , loss_no_resp_conf , loss_class_probs) , axis=-1)\n",
    "            self.total_loss = tf.reduce_mean(tf.reduce_sum(total_loss , axis=-1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(image , pred_boxes , name):    \n",
    "    im_h = image.shape[0]\n",
    "    im_w = image.shape[1]\n",
    "    \n",
    "    output = image.copy()\n",
    "    \n",
    "    for box in pred_boxes:\n",
    "        overlay = output.copy()\n",
    "        \n",
    "        class_idx = np.argmax(box[5:])\n",
    "        \n",
    "        x_min , x_max = [int(x * im_w) for x in [box[0] , box[2]]] #由比例单位转为图中的坐标系\n",
    "        y_min , y_max = [int(x * im_h) for y in [box[1] , box[3]]]\n",
    "        \n",
    "        cv2.rectangle(overlay , (x_min , y_min) , (x_max , y_max) , (255,255,255))\n",
    "\n",
    "        output = cv2.putText(overlay , LABEL2STR[np.argmax(box[5:])] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "\n",
    "    #plt.imshow(meta_img) #图像查看\n",
    "\n",
    "    plt.imsave(arr=image[: , : ,[2,1,0]] , fname = 'result/%s.jpg' % name) #保存图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class YOLO_V2(object):\n",
    "    '''\n",
    "    完整模型\n",
    "    '''\n",
    "    \n",
    "    def __init__(self , is_training = True):\n",
    "        self.dataset = Dataset()\n",
    "        \n",
    "        self.filewriter_path = 'save/logs' #模型可视化\n",
    "        self.checkpoint_path = 'save/model/' #模型持久化\n",
    "                              \n",
    "        self.model = DarkNet(is_training)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.saver = tf.train.Saver(max_to_keep=2) #max_to_keep 最大保存5次模型  之后继续保存则会覆盖前面的模型\n",
    "        \n",
    "        if is_training:\n",
    "            '''训练参数'''\n",
    "            self.epoch = 100000\n",
    "            \n",
    "            self.global_step = tf.Variable(initial_value=0 , trainable=False)\n",
    "            \n",
    "            self.learning_rate = tf.train.exponential_decay(learning_rate=0.00001 , global_step=self.global_step,\n",
    "                                                            decay_steps=900 , decay_rate=0.8 , staircase=True)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.model.total_loss , global_step=self.global_step)\n",
    "        \n",
    "            #引入滑动平均\n",
    "            self.ema = tf.train.ExponentialMovingAverage(decay=0.9) #滑动平均\n",
    "            self.average_op = self.ema.apply(tf.trainable_variables()) #给所有的可训练变量应用滑动平均\n",
    "            \n",
    "            with tf.control_dependencies([self.optimizer]):\n",
    "                self.train_op = tf.group(self.average_op)\n",
    "            \n",
    "            '''可视化'''\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            tf.summary.scalar('total_loss' , self.model.total_loss)\n",
    "            self.merged_summary = tf.summary.merge_all() #merge all summaries in the default graph\n",
    "            self.writer = tf.summary.FileWriter(self.filewriter_path , self.sess.graph) #可视化\n",
    "            \n",
    "    \n",
    "    def train(self):\n",
    "        if os.path.exists(self.checkpoint_path+'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path))\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(300):\n",
    "            x , labels = self.dataset.get_batch()\n",
    "            \n",
    "            self.sess.run(self.train_op , feed_dict={self.model.x : x , self.model.y : labels} )\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                self.saver.save(self.sess , self.checkpoint_path + 'model.ckpt' , global_step = i)\n",
    "                \n",
    "                total_loss , summary = self.sess.run([self.model.total_loss , self.merged_summary] , feed_dict={self.model.x : x , self.model.y : labels})\n",
    "                        \n",
    "                self.writer.add_summary(summary , global_step = i)\n",
    "                                \n",
    "                print(i , total_loss)\n",
    "            \n",
    "        self.writer.close() #event to disk and close the file\n",
    "\n",
    "    def predict(self , path=None , conf_thres = 0.5 , iou_thres = 0.5):\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path) )\n",
    "            \n",
    "            self._predict(path , conf_thres , iou_thres)\n",
    "        else:\n",
    "            print('no model!!!')\n",
    "            return \n",
    "            \n",
    "    def _predict(self , path , conf_thres , iou_thres):\n",
    "        # threshold_1 = 0.01\n",
    "        # threshold_nms = 0.7\n",
    "        \n",
    "        x , img_arr = self.dataset.get_batch_test(path)\n",
    "        \n",
    "        output = self.sess.run(self.model.pred_y , feed_dict={self.model.x : x})\n",
    "        \n",
    "        self._output = output\n",
    "        \n",
    "        #依次是 左上坐标 右下坐标 confidence softmax概率\n",
    "        boxes = np.reshape(output , (output.shape[0] , -1 , output.shape[-1])) #shape变为 [batch_size 13*13*5 25]\n",
    "        nms_boxes = []\n",
    "        \n",
    "        for box in boxes: #一次处理batch中的一张图片\n",
    "            '''\n",
    "            box的尺寸为 [13*13*5 25]\n",
    "            '''\n",
    "            nms_box = self.nms(box , conf_thres , iou_thres)\n",
    "            nms_boxes.append(nms_box)\n",
    "        \n",
    "        nms_boxes = np.array(nms_boxes)\n",
    "        \n",
    "        '''\n",
    "        下面的写法是因为不满足条件的预测框（confidence分数低于阈值） 25维向量元素全置为0 所以使用any（逻辑或）函数可以找见全0元素的索引\n",
    "        '''\n",
    "        bboxes = nms_boxes[np.nonzero( np.any(nms_boxes>0 , axis=1) ) ]\n",
    "        \n",
    "        display(img_arr , bboxes , 'first')\n",
    "        \n",
    "\n",
    "    def nms(self , boxes , conf_thres , iou_thres):\n",
    "        '''\n",
    "        iou需要小于指定的阈值\n",
    "        confidence需要大于指定的阈值\n",
    "        '''\n",
    "        '''\n",
    "        一次处理一张图片对应的网络给出结果\n",
    "        boxes的尺寸为[13*13*5 25]\n",
    "        '''\n",
    "        '''\n",
    "        对所有的预测框进行nms过程 不是分别对每个类别进行nms\n",
    "        '''\n",
    "        #左上 右下坐标 均为比例值 (0 1)范围之间\n",
    "        x1 = boxes[... , 0]\n",
    "        y1 = boxes[... , 1]\n",
    "        x2 = boxes[... , 2]\n",
    "        y2 = boxes[... , 3]\n",
    "        \n",
    "        areas = (x2-x1)*(y2-y1)\n",
    "        scores = boxes[... , 4]\n",
    "        \n",
    "        keep = []\n",
    "        order = scores.argsort()[::-1] #逆序变为升序排列的index argsort是升序排列的index\n",
    "        \n",
    "        while order.size > 0:\n",
    "            i = order[0]\n",
    "            keep.append(i)\n",
    "            \n",
    "            #下面的比较使用numpy的广播机制 先变成与第二个参数长度一样的 在进行比较 返回最大值\n",
    "            xx1 = np.maximum(x1[i] , x1[order[1:]])\n",
    "            yy1 = np.maximum(y1[i] , y1[order[1:]])\n",
    "            xx2 = np.maximum(x2[i] , x2[order[1:]])\n",
    "            yy2 = np.maximum(y2[i] , y2[order[1:]])\n",
    "            \n",
    "            w = np.maximum(0.0 , xx2-xx1)\n",
    "            h = np.maximum(0.0 , yy2-yy1)\n",
    "            \n",
    "            inter = w*h\n",
    "            ovr = inter/(areas[i] + areas[order[1:]] - inter)\n",
    "            \n",
    "            inds = np.where(ovr <= iou_thres)[0] #np.where() 返回满足条件的索引\n",
    "            \n",
    "            order = order[inds + 1]\n",
    "    \n",
    "        nms_box = []\n",
    "        for idx in range(len(boxes)):\n",
    "            if idx in keep and boxes[idx , 4] > conf_thres:\n",
    "                nms_box.append(boxes[idx]) #25个元素\n",
    "            else:\n",
    "                nms_box.append(np.zeros(boxes.shape[-1])) #25个0\n",
    "                \n",
    "        return np.array(nms_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = YOLO_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.56849897\n",
      "10 1.6498395\n",
      "20 1.0492408\n",
      "30 1.2971392\n",
      "40 0.47714478\n",
      "50 1.7881955\n",
      "60 0.5152417\n",
      "70 0.49427003\n",
      "80 0.4440512\n",
      "90 0.63722193\n",
      "100 2.341517\n",
      "110 0.39328712\n",
      "120 0.6648505\n",
      "130 0.47405463\n",
      "140 1.3099298\n",
      "150 0.37105387\n",
      "160 0.5389808\n",
      "170 0.3525883\n",
      "180 1.6754111\n",
      "190 1.8742914\n",
      "200 0.45636827\n",
      "210 1.0451202\n",
      "220 0.22119105\n",
      "230 0.4433879\n",
      "240 0.54642904\n",
      "250 0.47717527\n",
      "260 0.48467034\n",
      "270 1.4043194\n",
      "280 0.56810254\n",
      "290 0.3311335\n"
     ]
    }
   ],
   "source": [
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testt = YOLO_V2(is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model/model.ckpt-290\n"
     ]
    }
   ],
   "source": [
    "testt.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
