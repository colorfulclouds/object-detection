{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "#解析使用\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import imageio\n",
    "from skimage import transform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC #类别分类使用\n",
    "from sklearn.linear_model import Ridge #bounding-box回归\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "from ImageNet_classes import class_names #验证alexnet使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TEST_DATA_PATH = '../../../tensorflow2/dataset/VOC2012test/JPEGImages/'\n",
    "\n",
    "TRAIN_XML_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'\n",
    "TEST_XML_PATH = '../../../tensorflow2/dataset/VOC2012test/Annotations/'\n",
    "\n",
    "CLASSES_NUM = 20\n",
    "\n",
    "STR = [\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}\n",
    "#STR2LABEL = {value:idx for idx , value in enumerate(STR)}\n",
    "\n",
    "STR2LABEL['none'] = 'none' #先不使用part部分 只进行naive目标检测\n",
    "\n",
    "#目标检测相关\n",
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "#SVM相关\n",
    "SVM_IoU_THRESHOLD = 0.3\n",
    "\n",
    "#NMS相关\n",
    "NMS_IoU_THRESHOLD = 0.3 #or ~0.5\n",
    "\n",
    "#bbox回归\n",
    "BBOX_REGRESS_IoU_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file_names_train = glob(TRAIN_XML_PATH + '*') #所有的xml文件 完整路径\n",
    "\n",
    "#从xml文件中读出图片相关的信息\n",
    "\n",
    "def xml_parse(xml_file):\n",
    "    '''\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "    xml文件中的shape格式为 (width height 3)\n",
    "    '''\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    \n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        #name\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        name_box = name_list[0].childNodes[0].data\n",
    "\n",
    "        #bounding box points\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        x1_list = bndbox[0].getElementsByTagName('xmin')\n",
    "        x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "        y1_list = bndbox[0].getElementsByTagName('ymin')\n",
    "        y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "        x2_list = bndbox[0].getElementsByTagName('xmax')\n",
    "        x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "        y2_list = bndbox[0].getElementsByTagName('ymax')\n",
    "        y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "        crop_box = [x1,x2,y1,y2]\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    #crop_box:[x1 x2 y1 y2]\n",
    "    return filename , name_boxes , np.array(crop_boxes) #filename调试使用\n",
    "\n",
    "#xml_parse(xml_file_names_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2008_000281.jpg',\n",
       " ['car', 'car', 'person'],\n",
       " [[106, 186, 377, 419], [194, 283, 396, 444], [413, 429, 399, 444]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_parse(xml_file_names_train[897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "    '''\n",
    "    图片的真实信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH+'*') #训练全路径信息\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        if not img_path_name:\n",
    "            img_path_name = np.random.choice(self.img_file_names_train) #随机选择一张图片\n",
    "            #img_path_idx = np.random.randint(0 , high = len(self.img_file_names_train)) #随机索引\n",
    "\n",
    "        img_arr = cv2.imread(img_path_name) #BGR height*width*chanel\n",
    "        \n",
    "        xml_file_name = TRAIN_XML_PATH + img_path_name[-15:-4] +  '.xml'\n",
    "        \n",
    "        _ , name_boxes , crop_boxes = xml_parse(xml_file_name)\n",
    "        \n",
    "        labels = [] #存储与bndbox对应的 label信息\n",
    "\n",
    "        for i in range(len(crop_boxes)): #多个object \n",
    "            labels.append(STR2LABEL.get(name_boxes[i] , 'none'))\n",
    "        \n",
    "        return img_arr , labels , crop_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0==0.000000000000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 <=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Img_generator(object):\n",
    "    def __init__(self):\n",
    "        self.img_loader = Image()\n",
    "\n",
    "    #计算bbox面积\n",
    "    def bbox_area(self , bbox):\n",
    "        w = bbox[1] - bbox[0]\n",
    "        h = bbox[3] - bbox[2]\n",
    "        \n",
    "        return w*h\n",
    "    \n",
    "    #计算交并比\n",
    "    def IoU(self , bbox_a , bbox_b):\n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            union_area = self.bbox_area(bbox_a) + self.bbox_area(bbox_b) - area_inter\n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    \n",
    "    def map2new(self , img_shape , ground_truth_coord):\n",
    "        '''\n",
    "        坐标系映射至448*448坐标系中\n",
    "        '''\n",
    "        original_height = img_shape[0]\n",
    "        original_width = img_shape[1]\n",
    "        \n",
    "        ground_truth_coord[: , :2] = np.array( ground_truth_coord[: , :2] * (448/original_width) , dtype=int) #x1 x2\n",
    "        ground_truth_coord[: , 2:] = np.array( ground_truth_coord[: , 2:] * (448/original_height) , dtype=int) #y1 y2\n",
    "        \n",
    "        return ground_truth_coord\n",
    "        \n",
    "    \n",
    "    def get_train_proposal(self , img_arr , labels , ground_truth_coord):\n",
    "        #get_train_proposal为关键函数\n",
    "        \n",
    "        def _center(gt):\n",
    "            '''\n",
    "            gt的中心坐标\n",
    "            '''\n",
    "            x = int( ( gt[0] + gt[1] ) / 2 )\n",
    "            y = int( ( gt[2] + gt[3] ) / 2 )\n",
    "        \n",
    "            return [x,y]\n",
    "        \n",
    "        def _is_in_grid(gt_center , grid):\n",
    "            '''\n",
    "            判断gt的中心是否在此grid cell中\n",
    "            '''\n",
    "            if (grid[0] <= gt_center[0] <= grid[1]) and (grid[2] <= gt_center[1] <= grid[3]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        def _target_gt(gt , grid):\n",
    "            '''\n",
    "            将gt变为target需要的格式\n",
    "            '''\n",
    "            center = _center(gt)\n",
    "            #gt中心坐标在对应的grid中的偏移\n",
    "            target_x = ( center[0] - grid[0] ) / 64\n",
    "            target_y = ( center[1] - grid[2] ) / 64\n",
    "            \n",
    "            target_w = ( gt[1]-gt[0] ) / 448\n",
    "            target_h = ( gt[3]-gt[2] ) / 448\n",
    "            \n",
    "            return [target_x , target_y , target_w , target_h]\n",
    "            \n",
    "        \n",
    "        '''下面操作在448*448坐标系中进行'''\n",
    "        \n",
    "        #S*S grid cells\n",
    "        x_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        y_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        \n",
    "        grid = np.zeros(shape=[7 , 7] , dtype=list)\n",
    "        \n",
    "        for x_idx , x in enumerate(x_slice):\n",
    "            for y_idx , y in enumerate(y_slice):\n",
    "                grid[x_idx][y_idx] = y + x\n",
    "        \n",
    "        #训练样本中的y\n",
    "        #[confidence x y w h]*2 + cls_score\n",
    "        target = np.zeros(shape=[7 , 7 , 30] , dtype=float)\n",
    "        \n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                for idx , gt in enumerate(ground_truth_coord):\n",
    "                    \n",
    "                    if _is_in_grid( _center(gt) , grid[i][j]):\n",
    "                        '''\n",
    "                        此gt的中心位于此grid cell中\n",
    "                        '''\n",
    "                        iou = self.IoU(gt , grid[i][j])\n",
    "                        \n",
    "                        #如果出现一个grid cell有多个gt对应 则只保留iou最高的前两个\n",
    "                        if target[i][j][0] > target[i][j][5]:\n",
    "                            if iou > target[i][j][5]:\n",
    "                                target[i][j][5] = iou\n",
    "                                target[i][j][6 : 10] = _target_gt(gt , grid[i][j])\n",
    "                                target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                        elif target[i][j][0] <= target[i][j][5]:\n",
    "                            if iou > target[i][j][0]:\n",
    "                                target[i][j][0] = iou\n",
    "                                target[i][j][1 : 5] = _target_gt(gt , grid[i][j])\n",
    "                                target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                        #并入上面\n",
    "                        #else:\n",
    "                        #    #先执行此处\n",
    "                        #    if iou > target[i][j][0]:\n",
    "                        #        #只要大于 随意选一个位置即可\n",
    "                        #        target[i][j][0] = iou\n",
    "                        #        target[i][j][1 : 5] = _target_gt(gt)\n",
    "                        #        target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                \n",
    "                #here\n",
    "                #处理完一个grid cell\n",
    "                #如果[i , j] grid只有一个gt与之对应 则将其翻倍（因为yolo v1一个grid对应两个bounding box）\n",
    "                #只有一个gt与之对应 则只会出现在target[i][j][0 1 2 3 4]处\n",
    "                if (target[i][j][0] != 0.0) and (target[i][j][5] == 0.0):\n",
    "                    target[i][j][5:10] = target[i][j][0:5]\n",
    "                    #cls_score是一样的 同一个位置\n",
    "                                                  \n",
    "        return np.array(target)\n",
    "    \n",
    "    \n",
    "    def load(self , img_path_name):\n",
    "        '''\n",
    "        img_path_name:绝对路径\n",
    "        '''\n",
    "        \n",
    "        #图片数据 ground truth具体数据 ground truth对应label ground truth坐标信息 图片文件名\n",
    "        img_arr , labels , ground_truth_coord = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        ground_truth_coord = self.map2new(img_arr.shape , ground_truth_coord) #将ground_truch坐标从原坐标系映射至448*448坐标系中\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (448 , 448))\n",
    "        img_arr = img_arr / 127.5 - 1 #对下面的get_train_proposal没有影响\n",
    "        \n",
    "        target = self.get_train_proposal(img_arr , labels , ground_truth_coord)\n",
    "        \n",
    "        '''\n",
    "        resize 并 归一化像素值\n",
    "        img_arr 为 BGR形式\n",
    "        '''\n",
    "        \n",
    "        '''[R G B] [123.68 116.779 103.939]\n",
    "        减去每个通道的像素平均值 归一化'''\n",
    "        #img_arr[:,:,0] = img_arr[:,:,0] - 103.939\n",
    "        #img_arr[:,:,1] = img_arr[:,:,1] - 116.779\n",
    "        #img_arr[:,:,2] = img_arr[:,:,2] - 123.680\n",
    "        \n",
    "        #'''增加一维 batch维'''\n",
    "        return np.expand_dims(img_arr , axis=0) , target\n",
    "    \n",
    "    \n",
    "    def get_test_proposal(self , img_arr):\n",
    "        '''\n",
    "        return:rois\n",
    "        proposals_coord\n",
    "        '''\n",
    "        \n",
    "        h = img_arr.shape[0]\n",
    "        w = img_arr.shape[1]\n",
    "        \n",
    "        def bbox_trans(_rect):\n",
    "            rect = [-1,-1,-1,-1]\n",
    "            \n",
    "            rect[0] = int(_rect[0]*600 / w)\n",
    "            rect[1] = int(_rect[1]*600 / w)\n",
    "            rect[2] = int(_rect[2]*1000 / h)\n",
    "            rect[3] = int(_rect[3]*1000 / h)\n",
    "        \n",
    "            return rect\n",
    "        \n",
    "        anchors = [] #x1 x2 y1 y2 计算iou使用\n",
    "        \n",
    "        feature_map_height = 61\n",
    "        feature_map_width = 36\n",
    "        \n",
    "        scales = [128 , 256 , 512]\n",
    "        ratios = [[1,2] , [1,1] , [2,1]] #用scale除以即可 [height_ratio width_ratio]\n",
    "        \n",
    "        '''\n",
    "        x_0 y_0 为 feature map中的坐标\n",
    "        \n",
    "        x_0_coord y_0_coord 为原图中的坐标（中点坐标）\n",
    "        \n",
    "        跨越边界的anchor 进行截断\n",
    "        '''\n",
    "        \n",
    "        for x_0 in range(61): #height\n",
    "            for y_0 in range(36): #width\n",
    "                \n",
    "                x_0_coord = x_0 * 16\n",
    "                y_0_coord = y_0 * 16\n",
    "                \n",
    "                for scale in scales:\n",
    "                    for ratio in ratios:\n",
    "                        scale_height = int(scale / ratio[0])\n",
    "                        scale_width = int(scale / ratio[1])\n",
    "                    \n",
    "                        x_1_coord = int(x_0_coord - scale_width/2)\n",
    "                        y_1_coord = int(y_0_coord - scale_height/2)\n",
    "\n",
    "                        if x_1_coord < 0:\n",
    "                            x_1_coord = 0\n",
    "                            \n",
    "                        if y_1_coord < 0:\n",
    "                            y_1_coord = 0\n",
    "\n",
    "                        x_2_coord = int(x_0_coord + scale_width/2)\n",
    "                        y_2_coord = int(y_0_coord + scale_height/2)\n",
    "\n",
    "                        if x_2_coord > 600:\n",
    "                            x_2_coord = 600\n",
    "                            \n",
    "                        if y_2_coord > 1000:\n",
    "                            y_2_coord = 1000\n",
    "                        \n",
    "                        anchors.append( [x_1_coord , x_2_coord , y_1_coord , y_2_coord] )\n",
    "\n",
    "        return np.array(anchors)\n",
    "    \n",
    "    def load_test(self , img_path_name):\n",
    "        img_arr = cv2.imread(img_path_name)\n",
    "        \n",
    "        anchors = self.get_test_proposal(img_arr)\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (600 , 1000))\n",
    "        img_arr = img_arr / 127.5 - 1.0\n",
    "        \n",
    "        return np.expand_dims(img_arr , axis=0) , anchors\n",
    "\n",
    "# class Img_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Img_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = test.load('../../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2007_000129.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0.14227743 0.6875     0.53125    0.19419643 0.72544643 0.14227743\n",
      " 0.6875     0.53125    0.19419643 0.72544643 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0.03742519 0.609375   0.21875    0.59151786 0.921875   0.03742519\n",
      " 0.609375   0.21875    0.59151786 0.921875   1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0.0888696  0.140625   0.53125    0.24553571 0.93526786 0.0888696\n",
      " 0.140625   0.53125    0.24553571 0.93526786 1.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0.17506078 0.703125   0.046875   0.19642857 0.58258929 0.17506078\n",
      " 0.703125   0.046875   0.19642857 0.58258929 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0.06137985 0.390625   0.90625    0.55580357 0.59821429 0.06137985\n",
      " 0.390625   0.90625    0.55580357 0.59821429 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0.15763547 0.125      0.1875     0.25       0.51785714 0.15763547\n",
      " 0.125      0.1875     0.25       0.51785714 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 1.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        print(b[i][j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        path = np.random.choice(self.img_file_names_train)\n",
    "        \n",
    "        x , y_positive , y_negative = self.img_generator.load(path)\n",
    "        \n",
    "        y_pos_idx = np.random.choice( list( range( len(y_positive) ) ), size=128)\n",
    "        y_positive = y_positive[y_pos_idx]\n",
    "        \n",
    "        y_neg_idx = np.random.choice( list( range( len(y_negative) ) ) , size=128 )\n",
    "        y_negative = y_negative[y_neg_idx]\n",
    "        \n",
    "        y=np.concatenate((y_positive , y_negative) , axis=0)\n",
    "        np.random.shuffle(y)\n",
    "        \n",
    "        return x , y\n",
    "    \n",
    "    def get_batch_test(self , path):\n",
    "        '''\n",
    "        返回图片的真实img_arr 未resize 未归一化\n",
    "        注意cv2打开图片通道为BGR\n",
    "        '''\n",
    "        if not path:\n",
    "            #未指定path 从测试目录中随机选一张图片测试\n",
    "            path = np.random.choice(self.img_file_names_test)\n",
    "        \n",
    "        '''resize & norm/anchors/原图 '''\n",
    "        x , anchors = self.img_generator.load_test(path)\n",
    "        \n",
    "        return x , anchors\n",
    "    \n",
    "    \n",
    "    def target2coord(self , bbox_pred , img_arr , anchors):\n",
    "        img_height = img_arr.shape[0]\n",
    "        img_width = img_arr.shape[1]\n",
    "        \n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        def ot(target):\n",
    "            x_c = target[0]\n",
    "            y_c = target[1]\n",
    "            w = target[2]\n",
    "            h = target[3]\n",
    "            \n",
    "            x1 = 0.5*(2*x_c-w)\n",
    "            y1 = 0.5*(2*y_c-h)\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            \n",
    "            x1=int(round(x1))\n",
    "            y1=int(round(y1))\n",
    "            x2=int(round(x2))\n",
    "            y2=int(round(y2))\n",
    "            \n",
    "            if x1<0:\n",
    "                x1 = 0\n",
    "            if x2>img_width:\n",
    "                x2 = img_width\n",
    "            if y1<0:\n",
    "                y1 = 0\n",
    "            if y2>img_height:\n",
    "                y2 = img_height\n",
    "                            \n",
    "            return [x1 , x2 , y1 , y2]\n",
    "        \n",
    "        def target2rect(target_hat , P_box):\n",
    "            t_x = target_hat[0]\n",
    "            t_y = target_hat[1]\n",
    "            t_w = target_hat[2]\n",
    "            t_h = target_hat[3]\n",
    "            \n",
    "            P_x , P_y , P_w , P_h = to(P_box) #将P框转换为 中点坐标 宽 高 形式\n",
    "            \n",
    "            G_x_hat = P_w*t_x+P_x\n",
    "            G_y_hat = P_h*t_y+P_y\n",
    "            G_w_hat = P_w*np.exp(t_w)\n",
    "            G_h_hat = P_h*np.exp(t_h)\n",
    "            \n",
    "            return ot([G_x_hat , G_y_hat , G_w_hat , G_h_hat]) #ot还需要转化为(x1,x2,y1,y2)形式\n",
    "        \n",
    "        bbox_coord_pred = []\n",
    "        \n",
    "        for i in range(len(bbox_pred)):\n",
    "            bbox_coord_pred.append( target2rect(bbox_pred[i] , anchors[i]) )\n",
    "                \n",
    "        return bbox_coord_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
