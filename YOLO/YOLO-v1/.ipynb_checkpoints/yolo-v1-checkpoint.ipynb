{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "#解析使用\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import imageio\n",
    "from skimage import transform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC #类别分类使用\n",
    "from sklearn.linear_model import Ridge #bounding-box回归\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "from ImageNet_classes import class_names #验证alexnet使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TEST_DATA_PATH = '../../../tensorflow2/dataset/VOC2012test/JPEGImages/'\n",
    "\n",
    "TRAIN_XML_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'\n",
    "TEST_XML_PATH = '../../../tensorflow2/dataset/VOC2012test/Annotations/'\n",
    "\n",
    "CLASSES_NUM = 20\n",
    "\n",
    "STR = [\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}\n",
    "#STR2LABEL = {value:idx for idx , value in enumerate(STR)}\n",
    "\n",
    "STR2LABEL['none'] = 'none' #先不使用part部分 只进行naive目标检测\n",
    "\n",
    "#目标检测相关\n",
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "#SVM相关\n",
    "SVM_IoU_THRESHOLD = 0.3\n",
    "\n",
    "#NMS相关\n",
    "NMS_IoU_THRESHOLD = 0.3 #or ~0.5\n",
    "\n",
    "#bbox回归\n",
    "BBOX_REGRESS_IoU_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file_names_train = glob(TRAIN_XML_PATH + '*') #所有的xml文件 完整路径\n",
    "\n",
    "#从xml文件中读出图片相关的信息\n",
    "\n",
    "def xml_parse(xml_file):\n",
    "    '''\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "    xml文件中的shape格式为 (width height 3)\n",
    "    '''\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    \n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        #name\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        name_box = name_list[0].childNodes[0].data\n",
    "\n",
    "        #bounding box points\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        x1_list = bndbox[0].getElementsByTagName('xmin')\n",
    "        x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "        y1_list = bndbox[0].getElementsByTagName('ymin')\n",
    "        y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "        x2_list = bndbox[0].getElementsByTagName('xmax')\n",
    "        x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "        y2_list = bndbox[0].getElementsByTagName('ymax')\n",
    "        y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "        crop_box = [x1,x2,y1,y2]\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    #crop_box:[x1 x2 y1 y2]\n",
    "    return filename , name_boxes , np.array(crop_boxes) #filename调试使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xml_parse(xml_file_names_train[897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "    '''\n",
    "    图片的真实信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH+'*') #训练全路径信息\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        if not img_path_name:\n",
    "            img_path_name = np.random.choice(self.img_file_names_train) #随机选择一张图片\n",
    "            #img_path_idx = np.random.randint(0 , high = len(self.img_file_names_train)) #随机索引\n",
    "\n",
    "        img_arr = cv2.imread(img_path_name) #BGR height*width*chanel\n",
    "        \n",
    "        xml_file_name = TRAIN_XML_PATH + img_path_name[-15:-4] +  '.xml'\n",
    "        \n",
    "        _ , name_boxes , crop_boxes = xml_parse(xml_file_name)\n",
    "        \n",
    "        labels = [] #存储与bndbox对应的 label信息\n",
    "\n",
    "        for i in range(len(crop_boxes)): #多个object \n",
    "            labels.append(STR2LABEL.get(name_boxes[i] , 'none'))\n",
    "        \n",
    "        return img_arr , labels , crop_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Img_generator(object):\n",
    "    def __init__(self):\n",
    "        self.img_loader = Image()\n",
    "\n",
    "    #计算bbox面积\n",
    "    def bbox_area(self , bbox):\n",
    "        w = bbox[1] - bbox[0]\n",
    "        h = bbox[3] - bbox[2]\n",
    "        \n",
    "        return w*h\n",
    "    \n",
    "    #计算交并比\n",
    "    def IoU(self , bbox_a , bbox_b):\n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            union_area = self.bbox_area(bbox_a) + self.bbox_area(bbox_b) - area_inter\n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    \n",
    "    def map2new(self , img_shape , ground_truth_coord):\n",
    "        '''\n",
    "        坐标系映射至448*448坐标系中\n",
    "        '''\n",
    "        original_height = img_shape[0]\n",
    "        original_width = img_shape[1]\n",
    "        \n",
    "        ground_truth_coord[: , :2] = np.array( ground_truth_coord[: , :2] * (448/original_width) , dtype=int) #x1 x2\n",
    "        ground_truth_coord[: , 2:] = np.array( ground_truth_coord[: , 2:] * (448/original_height) , dtype=int) #y1 y2\n",
    "        \n",
    "        return ground_truth_coord\n",
    "        \n",
    "    \n",
    "    def get_train_proposal(self , labels , ground_truth_coord):\n",
    "        #get_train_proposal为关键函数\n",
    "        \n",
    "        def _center(gt):\n",
    "            '''\n",
    "            gt的中心坐标\n",
    "            '''\n",
    "            x = int( ( gt[0] + gt[1] ) / 2 )\n",
    "            y = int( ( gt[2] + gt[3] ) / 2 )\n",
    "        \n",
    "            return [x,y]\n",
    "        \n",
    "        def _is_in_grid(gt_center , grid):\n",
    "            '''\n",
    "            判断gt的中心是否在此grid cell中\n",
    "            '''\n",
    "            if (grid[0] <= gt_center[0] <= grid[1]) and (grid[2] <= gt_center[1] <= grid[3]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        def _target_gt(gt , grid):\n",
    "            '''\n",
    "            将gt变为target需要的格式\n",
    "            '''\n",
    "            center = _center(gt)\n",
    "            #gt中心坐标在对应的grid中的偏移\n",
    "            target_x = ( center[0] - grid[0] ) / 64\n",
    "            target_y = ( center[1] - grid[2] ) / 64\n",
    "            \n",
    "            target_w = ( gt[1]-gt[0] ) / 448\n",
    "            target_h = ( gt[3]-gt[2] ) / 448\n",
    "            \n",
    "            return [target_x , target_y , target_w , target_h]\n",
    "            \n",
    "        \n",
    "        '''下面操作在448*448坐标系中进行'''\n",
    "        \n",
    "        #S*S grid cells\n",
    "        x_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        y_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        \n",
    "        grid = np.zeros(shape=[7 , 7] , dtype=list)\n",
    "        \n",
    "        for x_idx , x in enumerate(x_slice):\n",
    "            for y_idx , y in enumerate(y_slice):\n",
    "                grid[x_idx][y_idx] = y + x\n",
    "        \n",
    "        #训练样本中的y\n",
    "        #[confidence x y w h]*2 + cls_score\n",
    "        target = np.zeros(shape=[7 , 7 , 30] , dtype=float)\n",
    "        \n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                for idx , gt in enumerate(ground_truth_coord):\n",
    "                    \n",
    "                    if _is_in_grid( _center(gt) , grid[i][j]):\n",
    "                        '''\n",
    "                        此gt的中心位于此grid cell中\n",
    "                        '''\n",
    "                        iou = self.IoU(gt , grid[i][j])\n",
    "                        \n",
    "                        #如果出现一个grid cell有多个gt对应 则只保留iou最高的前两个\n",
    "                        if target[i][j][0] > target[i][j][5]:\n",
    "                            if iou > target[i][j][5]:\n",
    "                                target[i][j][5] = iou\n",
    "                                target[i][j][6 : 10] = _target_gt(gt , grid[i][j])\n",
    "                                target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                        elif target[i][j][0] <= target[i][j][5]:\n",
    "                            if iou > target[i][j][0]:\n",
    "                                target[i][j][0] = iou\n",
    "                                target[i][j][1 : 5] = _target_gt(gt , grid[i][j])\n",
    "                                target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                        #并入上面\n",
    "                        #else:\n",
    "                        #    #先执行此处\n",
    "                        #    if iou > target[i][j][0]:\n",
    "                        #        #只要大于 随意选一个位置即可\n",
    "                        #        target[i][j][0] = iou\n",
    "                        #        target[i][j][1 : 5] = _target_gt(gt)\n",
    "                        #        target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                \n",
    "                #here\n",
    "                #处理完一个grid cell\n",
    "                #如果[i , j] grid只有一个gt与之对应 则将其翻倍（因为yolo v1一个grid对应两个bounding box）\n",
    "                #只有一个gt与之对应 则只会出现在target[i][j][0 1 2 3 4]处\n",
    "                if (target[i][j][0] != 0.0) and (target[i][j][5] == 0.0):\n",
    "                    target[i][j][5:10] = target[i][j][0:5]\n",
    "                    #cls_score是一样的 同一个位置\n",
    "                                                  \n",
    "        return np.array(target)\n",
    "    \n",
    "    \n",
    "    def load(self , img_path_name):\n",
    "        '''\n",
    "        img_path_name:绝对路径\n",
    "        '''\n",
    "        \n",
    "        #图片数据 ground truth具体数据 ground truth对应label ground truth坐标信息 图片文件名\n",
    "        img_arr , labels , ground_truth_coord = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        ground_truth_coord = self.map2new(img_arr.shape , ground_truth_coord) #将ground_truch坐标从原坐标系映射至448*448坐标系中\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (448 , 448))\n",
    "        img_arr = img_arr / 127.5 - 1 #对下面的get_train_proposal没有影响\n",
    "        \n",
    "        target = self.get_train_proposal(labels , ground_truth_coord)\n",
    "        \n",
    "        '''\n",
    "        resize 并 归一化像素值\n",
    "        img_arr 为 BGR形式\n",
    "        '''\n",
    "        \n",
    "        #[R G B] [123.68 116.779 103.939]\n",
    "        #减去每个通道的像素平均值 归一化\n",
    "        #因为cv2打开的形式为BGR\n",
    "        #img_arr[:,:,0] = img_arr[:,:,0] - 103.939\n",
    "        #img_arr[:,:,1] = img_arr[:,:,1] - 116.779\n",
    "        #img_arr[:,:,2] = img_arr[:,:,2] - 123.680\n",
    "        \n",
    "        return np.expand_dims(img_arr , axis=0) , target\n",
    "    \n",
    "    \n",
    "    def load_test(self , img_path_name):\n",
    "        img_arr = cv2.imread(img_path_name)\n",
    "        \n",
    "        img_arr_resize = cv2.resize(img_arr , (448 , 448))\n",
    "        img_arr_resize_norm = img_arr_resize / 127.5 - 1\n",
    "        \n",
    "        return np.expand_dims(img_arr_resize_norm , axis=0) , img_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        path = np.random.choice(self.img_file_names_train)\n",
    "        \n",
    "        x , target = self.img_generator.load(path)\n",
    "    \n",
    "        return x , target\n",
    "    \n",
    "    def get_batch_test(self , path):\n",
    "        \n",
    "        if not path:\n",
    "            #未指定path 从测试目录中随机选一张图片测试\n",
    "            path = np.random.choice(self.img_file_names_test)\n",
    "            print('test image:', path)\n",
    "        \n",
    "        \n",
    "        x , img_arr= self.img_generator.load_test(path)\n",
    "        \n",
    "        return x , img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DarkNet(object):\n",
    "    def __init__(self , is_training=True):\n",
    "        \n",
    "        self.x = tf.placeholder(dtype=tf.float32 , shape=[1 , 448 , 448 , 3])        \n",
    "        \n",
    "        self.build(is_training) #构建网络产生输出\n",
    "        \n",
    "        if is_training:\n",
    "            self.target = tf.placeholder(dtype=tf.float32 , shape=[7 , 7 , 30])\n",
    "            self.loss()\n",
    "\n",
    "    def build(self , is_training):\n",
    "        #arch from paper\n",
    "        def _conv(_input , num_outputs , kernel_size , stride=1 , padding='SAME'):\n",
    "            return slim.conv2d(_input , num_outputs=num_outputs , kernel_size=kernel_size , stride=stride , padding=padding)\n",
    "        \n",
    "        def _max_pool(_input , kernel_size=2 , stride=2 , padding='VALID'):\n",
    "            return slim.max_pool2d(_input , kernel_size=kernel_size , stride=stride)\n",
    "        \n",
    "        def _conv_module_a(_input):\n",
    "            _output = _conv(_input , 256 , 1)\n",
    "            return _conv(_output , 512 , 3)\n",
    "        \n",
    "        def _conv_module_b(_input):\n",
    "            _output = _conv(_input , 512 , 1)\n",
    "            return _conv(_output , 1024 , 3)\n",
    "        \n",
    "        output = _conv(self.x , 64 , 7 , 2)\n",
    "        output = _max_pool(output)\n",
    "           \n",
    "        output = _conv(output , 192 , 3)              \n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        output = _conv(output , 128 , 1)\n",
    "        output = _conv(output , 256 , 3)\n",
    "        output = _conv(output , 256 , 1)\n",
    "        output = _conv(output , 512 , 3)\n",
    "        output = _max_pool(output)\n",
    "                \n",
    "        #4 times\n",
    "        output = _conv_module_a(output)\n",
    "        output = _conv_module_a(output)\n",
    "        output = _conv_module_a(output)\n",
    "        output = _conv_module_a(output)\n",
    "        \n",
    "        output = _conv(output , 512 , 1)\n",
    "        output = _conv(output , 1024 , 3)\n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        #twice\n",
    "        output = _conv_module_b(output)\n",
    "        output = _conv_module_b(output)\n",
    "        \n",
    "        output = _conv(output , 1024 , 3)\n",
    "        output = _conv(output , 1024 , 3 , 2)\n",
    "        \n",
    "        output = _conv(output , 1024 , 3)\n",
    "        output = _conv(output , 1024 , 3)\n",
    "        \n",
    "        output = slim.flatten(output)\n",
    "                \n",
    "        #paper中为4096 pc性能达不到\n",
    "        output = slim.fully_connected(inputs=output , num_outputs=1024 , activation_fn=tf.nn.relu)\n",
    "        \n",
    "        #引入dropout\n",
    "        output = slim.dropout(output , keep_prob=0.5 , is_training=is_training)\n",
    "        \n",
    "        #tf.identity 使用线性激活函数 nan错误 使用leaky relu也会出错 换成relu\n",
    "        output = slim.fully_connected(inputs=output , num_outputs=7*7*30 , activation_fn=None)\n",
    "        \n",
    "        #防止结果出现[0 1]区间之外的数 本模型的输出全部为非负数\n",
    "        #后续开根 负数开根 会出现nan错误\n",
    "        output = tf.clip_by_value(output , clip_value_min=0.0 , clip_value_max=1.0) \n",
    "        \n",
    "        self.output = tf.reshape(output , shape=[7 , 7 , 30]) #丢弃掉batch维 没用\n",
    "\n",
    "        \n",
    "    def loss(self):\n",
    "        lambda_coord = 5.0\n",
    "        lambda_noobj = 0.5\n",
    "        \n",
    "        #[:,:,0]\n",
    "        _mask = tf.cast( tf.greater( tf.slice(self.target,begin=[0,0,0],size=[7,7,1]) , np.zeros(shape=[7,7,1] , dtype=float) ) , dtype=tf.float32 )\n",
    "        mask = tf.tile(_mask , multiples=[1 , 1 , 2]) #7*7*2\n",
    "        #[:,:,[1,2]]\n",
    "        self.loss_coord = tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,1],size=[7,7,2]) - tf.slice(self.target,begin=[0,0,1],size=[7,7,2]) ) * mask ) )\n",
    "        \n",
    "        '''========'''\n",
    "        '''此处不修正 不出现给负数开方 出现nan情况'''\n",
    "        #[:,:,[3,4]]\n",
    "        self.loss_coord += tf.reduce_sum( tf.square( (tf.sqrt( tf.slice(self.output,begin=[0,0,3],size=[7,7,2]) ) - tf.sqrt( tf.slice(self.target,begin=[0,0,3],size=[7,7,2]))) * mask ) )\n",
    "        '''========'''\n",
    "        \n",
    "        self.loss_coord = lambda_coord * self.loss_coord\n",
    "        \n",
    "        #[:,:,:[0,5]]\n",
    "        self.loss_iou = tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,0],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,0],size=[7,7,1])) * mask ) )\n",
    "        self.loss_iou += tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,5],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,5],size=[7,7,1])) * mask ) )\n",
    "        #[:,:,:[0,5]]\n",
    "        self.loss_iou += lambda_noobj * (tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,0],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,0],size=[7,7,1]) ) * (1.0-mask) ) ) +\\\n",
    "                                    tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,5],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,5],size=[7,7,1]) ) * (1.0-mask) ) ))\n",
    "        \n",
    "        mask = tf.tile(_mask , multiples=[1,1,20]) #7*7*20 (因为20 classes)\n",
    "        #[:,:,10:]\n",
    "        self.loss_cls = tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,10],size=[7,7,20]) - tf.slice(self.target,begin=[0,0,10],size=[7,7,20]) ) * mask ) )\n",
    "        \n",
    "        self.total_loss = self.loss_coord + self.loss_iou + self.loss_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(img_arr , labels , bbox , name):    \n",
    "    \n",
    "    print('debug:' , img_arr.shape , labels , bbox)\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        x1 = bbox[i][0]\n",
    "        x2 = bbox[i][1]\n",
    "        y1 = bbox[i][2]\n",
    "        y2 = bbox[i][3]\n",
    "\n",
    "        img_arr = cv2.rectangle(img_arr , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "\n",
    "        img_arr = cv2.putText(img_arr , LABEL2STR[labels[i]] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "\n",
    "    #plt.imshow(meta_img) #图像查看\n",
    "\n",
    "    plt.imsave(arr=img_arr[: , : ,[2,1,0]] , fname = 'result/%s.jpg' % name) #保存图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "\n",
    "class YOLO_V1(object):\n",
    "    '''\n",
    "    完整模型\n",
    "    '''\n",
    "    \n",
    "    def __init__(self , is_training = True):\n",
    "        self._grid() #创建grid cell 坐标信息\n",
    "        \n",
    "        self.dataset = Dataset()\n",
    "        \n",
    "        self.filewriter_path = 'save/logs' #模型可视化\n",
    "        self.checkpoint_path = 'save/model/' #模型持久化\n",
    "                              \n",
    "        self.model = DarkNet(is_training)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        self.saver = tf.train.Saver(max_to_keep=2) #max_to_keep 最大保存5次模型  之后继续保存则会覆盖前面的模型\n",
    "        \n",
    "        if is_training:\n",
    "            '''训练参数'''\n",
    "            self.epoch = 100000\n",
    "            \n",
    "            self.global_step = tf.Variable(initial_value=0 , trainable=False)\n",
    "            \n",
    "            self.learning_rate = tf.train.exponential_decay(learning_rate=0.00001 , global_step=self.global_step,\n",
    "                                                            decay_steps=900 , decay_rate=0.8 , staircase=True)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.model.total_loss , global_step=self.global_step)\n",
    "        \n",
    "            #引入滑动平均\n",
    "            self.ema = tf.train.ExponentialMovingAverage(decay=0.9) #滑动平均\n",
    "            self.average_op = self.ema.apply(tf.trainable_variables()) #给所有的可训练变量应用滑动平均\n",
    "            \n",
    "            with tf.control_dependencies([self.optimizer]):\n",
    "                self.train_op = tf.group(self.average_op)\n",
    "            \n",
    "            '''可视化'''\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            tf.summary.scalar('total_loss' , self.model.total_loss)\n",
    "            self.merged_summary = tf.summary.merge_all() #merge all summaries in the default graph\n",
    "            self.writer = tf.summary.FileWriter(self.filewriter_path , self.sess.graph) #可视化\n",
    "            \n",
    "    \n",
    "    def _grid(self):\n",
    "        #S*S grid cells\n",
    "        x_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        y_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        \n",
    "        self.grid = np.zeros(shape=[7 , 7] , dtype=list)\n",
    "        \n",
    "        for x_idx , x in enumerate(x_slice):\n",
    "            for y_idx , y in enumerate(y_slice):\n",
    "                self.grid[x_idx][y_idx] = y + x\n",
    "        \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        if os.path.exists(self.checkpoint_path+'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path))\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(300):\n",
    "            '''\n",
    "            构造target的时候（即构造训练集的时候）每一个grid cell中只构造一个bounding box 即7*7*(1+4+20) #confidence_score(iou)+offset+p_i\n",
    "            '''\n",
    "            x , target = self.dataset.get_batch()\n",
    "            \n",
    "            self.sess.run(self.train_op , feed_dict={self.model.x : x , self.model.target : target} )\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                self.saver.save(self.sess , self.checkpoint_path + 'model.ckpt' , global_step = i)\n",
    "                \n",
    "                total_loss , summary = self.sess.run([self.model.total_loss , self.merged_summary] , feed_dict={self.model.x : x , self.model.target : target})\n",
    "                        \n",
    "                self.writer.add_summary(summary , global_step = i)\n",
    "                                \n",
    "                print(i , total_loss)\n",
    "            \n",
    "        self.writer.close() #event to disk and close the file\n",
    "\n",
    "    def predict(self , path=None):\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path) )\n",
    "            \n",
    "            self._predict(path)\n",
    "        else:\n",
    "            print('no model!!!')\n",
    "            return \n",
    "        \n",
    "        #===================\n",
    "        #这里不导入预训练的参数 直接使用随机的参数进行尝试 看一下输出是否是不变的\n",
    "        #self.sess.run(tf.global_variables_initializer())\n",
    "        #self._predict(path)\n",
    "    \n",
    "    def _predict(self , path):\n",
    "        threshold_1 = 0.01\n",
    "        threshold_nms = 0.7\n",
    "        \n",
    "        x , img_arr= self.dataset.get_batch_test(path)\n",
    "        \n",
    "        output = self.sess.run(self.model.output , feed_dict={self.model.x : x})\n",
    "        self._output = output\n",
    "        \n",
    "        prod = self._confidence_p(output)\n",
    "        bbox = self._bbox(output)\n",
    "                \n",
    "        pred_labels = []\n",
    "        pred_bnds = []\n",
    "        \n",
    "        #step 1 set zero\n",
    "        prod = np.greater(prod , threshold_1).astype(dtype=int) * prod #小于阈值置0\n",
    "        \n",
    "        #step 2 sort and nms\n",
    "        for i in range(20):\n",
    "            des_idx = np.argsort(-1 * prod[i]) #降序排列\n",
    "            \n",
    "            nms_idx = self._nms(prod[i][des_idx] , bbox[: , des_idx] , des_idx , threshold_nms) #返回的对应被丢弃的bnd box索引\n",
    "            \n",
    "            #将丢弃的confidence*pi置0\n",
    "            prod[i][nms_idx] = 0\n",
    "        \n",
    "        #step 3 final prediction\n",
    "        for i in range(98): #一次处理每一个bounding box\n",
    "            if np.max(prod[: , i]) != 0:\n",
    "                pred_idx = np.argmax(prod[: , i])\n",
    "                \n",
    "                pred_labels.append(pred_idx)\n",
    "                pred_bnds.append( self._to_original(bbox[: , i] , img_arr.shape) )\n",
    "        \n",
    "        #step 4 draw in image\n",
    "        display(img_arr , pred_labels , pred_bnds , 'first')\n",
    "        \n",
    "    def _to_original(self , bbox , shape):\n",
    "        return [int( bbox[0]*(shape[1]/448) ) , int( bbox[1]*(shape[1]/448) ) , #x1 x2\n",
    "                 int( bbox[2]*(shape[0]/448) ) , int( bbox[3]*(shape[0]/448) ) ] #y1 y2\n",
    "    \n",
    "    def _confidence_p(self , output):\n",
    "        #置信度与分类概率的乘积\n",
    "        prod = []\n",
    "        \n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                prod.append(output[i,j,0] * output[i,j, 10:]) #bnd 1\n",
    "                prod.append(output[i,j,5] * output[i,j, 10:]) #bnd 2\n",
    "                \n",
    "        prod = np.array(prod) #98*20\n",
    "        prod = prod.T #20*98\n",
    "        \n",
    "        return prod            \n",
    "    \n",
    "    def _bbox(self , output):\n",
    "        #将output中的坐标还原为448*448坐标系中\n",
    "        def __bbox(bnd , grid):\n",
    "            target_x = bnd[0]\n",
    "            target_y = bnd[1]\n",
    "            target_w = bnd[2]\n",
    "            target_h = bnd[3]\n",
    "            \n",
    "            center_x = int( target_x * 64 + grid[0] )\n",
    "            center_y = int( target_y * 64 + grid[2] )\n",
    "            \n",
    "            w = int( target_w * 448 )\n",
    "            h = int( target_h * 448 )\n",
    "            \n",
    "            x1 = int( center_x - 0.5*w )\n",
    "            x2 = int( center_x + 0.5*w )\n",
    "            y1 = int( center_y - 0.5*h )\n",
    "            y2 = int( center_y + 0.5*h )\n",
    "            \n",
    "            return np.clip([x1,x2,y1,y2] , a_min=0 , a_max=448) #对于跨越边界的框进行clip\n",
    "        \n",
    "        bbox = []\n",
    "        \n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                bbox.append( __bbox(output[i,j,1:5] , self.grid[i][j]) ) #bnd 1\n",
    "                bbox.append( __bbox(output[i,j,6:10], self.grid[i][j]) ) #bnd 2\n",
    "    \n",
    "        bbox = np.array(bbox) #98*4\n",
    "        bbox = bbox.T #4*98\n",
    "        \n",
    "        return bbox\n",
    "        \n",
    "\n",
    "    def _nms(self , prod , bbox , des_idx , threshold_nms):\n",
    "        '''\n",
    "        prod已降序排列 bbox也对应降序 des_idx为在未降序的数组中的 降序索引(argsort)\n",
    "        '''\n",
    "        length = len(prod) #98\n",
    "        lost_flag = [1]*length #标记丢弃的框 0表示丢弃\n",
    "        \n",
    "        max_score_idx = 0 #记录当前最大score的idx\n",
    "        \n",
    "        #对于score为0的bnd box不必进行nms 直接丢弃\n",
    "        for i in range(length):\n",
    "            if prod[i] == 0.0:\n",
    "                lost_flag[i:] = [0] * (length - i) #因为prod已经降序 故出现0.0 后续全为0.0\n",
    "                break\n",
    "        \n",
    "        while max_score_idx < length:\n",
    "            max_score_rect = bbox[: , max_score_idx]\n",
    "            \n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1 and self._iou( max_score_rect , bbox[: , i] ) > threshold_nms: #大于阈值 丢弃\n",
    "                    lost_flag[i] = 0\n",
    "\n",
    "            max_score_idx_bak = max_score_idx #后续使用\n",
    "            \n",
    "            #让max_score_idx指向下一个没被丢弃的最大值\n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1:\n",
    "                    max_score_idx = i\n",
    "                    break\n",
    "            \n",
    "            #说明max_score_idx没有移动过 即后续的都被丢弃了 提前终止循环\n",
    "            if max_score_idx == max_score_idx_bak:\n",
    "                break\n",
    "            \n",
    "        nms_idx = [] #用来存放丢弃的bnd box!!!\n",
    "\n",
    "        for i in range(length):\n",
    "            if lost_flag[i] == 0:\n",
    "                nms_idx.append( des_idx[i] )\n",
    "                \n",
    "        return nms_idx\n",
    "    \n",
    "    \n",
    "    def _iou(self , bbox_a , bbox_b):\n",
    "        #计算bbox面积\n",
    "        def __area(bbox):\n",
    "            w = bbox[1] - bbox[0]\n",
    "            h = bbox[3] - bbox[2]\n",
    "\n",
    "            return w*h\n",
    "    \n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            union_area = __area(bbox_a) + __area(bbox_b) - area_inter\n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = YOLO_V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model/model.ckpt-290\n",
      "0 11.899965\n",
      "10 2.6669745\n",
      "20 19.913555\n",
      "30 11.7010765\n",
      "40 3.1835704\n",
      "50 29.869507\n",
      "60 3.508064\n",
      "70 5.7225046\n",
      "80 3.1015394\n",
      "90 4.790275\n",
      "100 5.5282784\n",
      "110 3.9910197\n",
      "120 27.844131\n",
      "130 5.255406\n",
      "140 2.4926865\n",
      "150 3.6026378\n",
      "160 6.209631\n",
      "170 18.191385\n",
      "180 4.6523376\n",
      "190 3.5999625\n",
      "200 4.7379174\n",
      "210 5.1759095\n",
      "220 2.6724927\n",
      "230 11.298651\n",
      "240 6.9037914\n",
      "250 3.919413\n",
      "260 9.728306\n",
      "270 3.6226234\n",
      "280 5.5427094\n",
      "290 9.907307\n"
     ]
    }
   ],
   "source": [
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testt = YOLO_V1(is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model/model.ckpt-290\n",
      "test image: ../../../tensorflow2/dataset/VOC2012test/JPEGImages\\2008_007489.jpg\n",
      "debug: (375, 500, 3) [10] [[95, 233, 178, 281]]\n"
     ]
    }
   ],
   "source": [
    "testt.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model/model.ckpt-290\n",
      "test image: ../../../tensorflow2/dataset/VOC2012test/JPEGImages\\2010_006259.jpg\n",
      "debug: (375, 500, 3) [5, 14, 3, 19, 10, 10, 15] [[-2, 17, 0, 129], [285, 304, 99, 114], [0, 0, 160, 160], [81, 261, 174, 285], [212, 372, 172, 272], [285, 285, 207, 220], [59, 225, 321, 321]]\n"
     ]
    }
   ],
   "source": [
    "testt.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.00819682,\n",
       "        0.        , 0.        ],\n",
       "       [0.06861994, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0195321 ],\n",
       "       [0.01040532, 0.        , 0.        , 0.        , 0.00409173,\n",
       "        0.        , 0.        ],\n",
       "       [0.06733071, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02720767, 0.        ],\n",
       "       [0.        , 0.        , 0.12342051, 0.        , 0.0597523 ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testt._output[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.01564434,\n",
       "        0.        , 0.        ],\n",
       "       [0.07016775, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.02026871],\n",
       "       [0.00974074, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.07869903, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02900382, 0.        ],\n",
       "       [0.        , 0.        , 0.13965729, 0.        , 0.07298322,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testt._output[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751921"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testt._output.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055052515"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testt._prod.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
