{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "#解析使用\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import imageio\n",
    "from skimage import transform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC #类别分类使用\n",
    "from sklearn.linear_model import Ridge #bounding-box回归\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "from ImageNet_classes import class_names #验证alexnet使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TEST_DATA_PATH = '../../../tensorflow2/dataset/VOC2012test/JPEGImages/'\n",
    "\n",
    "TRAIN_XML_PATH = '../../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'\n",
    "TEST_XML_PATH = '../../../tensorflow2/dataset/VOC2012test/Annotations/'\n",
    "\n",
    "CLASSES_NUM = 20\n",
    "\n",
    "STR = [\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}\n",
    "#STR2LABEL = {value:idx for idx , value in enumerate(STR)}\n",
    "\n",
    "STR2LABEL['none'] = 'none' #先不使用part部分 只进行naive目标检测\n",
    "\n",
    "#目标检测相关\n",
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "#SVM相关\n",
    "SVM_IoU_THRESHOLD = 0.3\n",
    "\n",
    "#NMS相关\n",
    "NMS_IoU_THRESHOLD = 0.3 #or ~0.5\n",
    "\n",
    "#bbox回归\n",
    "BBOX_REGRESS_IoU_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file_names_train = glob(TRAIN_XML_PATH + '*') #所有的xml文件 完整路径\n",
    "\n",
    "#从xml文件中读出图片相关的信息\n",
    "\n",
    "def xml_parse(xml_file):\n",
    "    '''\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "    xml文件中的shape格式为 (width height 3)\n",
    "    '''\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    \n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        #name\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        name_box = name_list[0].childNodes[0].data\n",
    "\n",
    "        #bounding box points\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        x1_list = bndbox[0].getElementsByTagName('xmin')\n",
    "        x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "        y1_list = bndbox[0].getElementsByTagName('ymin')\n",
    "        y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "        x2_list = bndbox[0].getElementsByTagName('xmax')\n",
    "        x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "        y2_list = bndbox[0].getElementsByTagName('ymax')\n",
    "        y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "        crop_box = [x1,x2,y1,y2]\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    #crop_box:[x1 x2 y1 y2]\n",
    "    return filename , name_boxes , np.array(crop_boxes) #filename调试使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xml_parse(xml_file_names_train[897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "    '''\n",
    "    图片的真实信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH+'*') #训练全路径信息\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        if not img_path_name:\n",
    "            img_path_name = np.random.choice(self.img_file_names_train) #随机选择一张图片\n",
    "            #img_path_idx = np.random.randint(0 , high = len(self.img_file_names_train)) #随机索引\n",
    "\n",
    "        img_arr = cv2.imread(img_path_name) #BGR height*width*chanel\n",
    "        \n",
    "        xml_file_name = TRAIN_XML_PATH + img_path_name[-15:-4] +  '.xml'\n",
    "        \n",
    "        _ , name_boxes , crop_boxes = xml_parse(xml_file_name)\n",
    "        \n",
    "        labels = [] #存储与bndbox对应的 label信息\n",
    "\n",
    "        for i in range(len(crop_boxes)): #多个object \n",
    "            labels.append(STR2LABEL.get(name_boxes[i] , 'none'))\n",
    "        \n",
    "        return img_arr , labels , crop_boxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Img_generator(object):\n",
    "    def __init__(self):\n",
    "        self.img_loader = Image()\n",
    "\n",
    "    #计算bbox面积\n",
    "    def bbox_area(self , bbox):\n",
    "        w = bbox[1] - bbox[0]\n",
    "        h = bbox[3] - bbox[2]\n",
    "        \n",
    "        return w*h\n",
    "    \n",
    "    #计算交并比\n",
    "    def IoU(self , bbox_a , bbox_b):\n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            union_area = self.bbox_area(bbox_a) + self.bbox_area(bbox_b) - area_inter\n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    \n",
    "    def map2new(self , img_shape , ground_truth_coord):\n",
    "        '''\n",
    "        坐标系映射至448*448坐标系中\n",
    "        '''\n",
    "        original_height = img_shape[0]\n",
    "        original_width = img_shape[1]\n",
    "        \n",
    "        ground_truth_coord[: , :2] = np.array( ground_truth_coord[: , :2] * (448/original_width) , dtype=int) #x1 x2\n",
    "        ground_truth_coord[: , 2:] = np.array( ground_truth_coord[: , 2:] * (448/original_height) , dtype=int) #y1 y2\n",
    "        \n",
    "        return ground_truth_coord\n",
    "        \n",
    "    \n",
    "    def get_train_proposal(self , labels , ground_truth_coord):\n",
    "        #get_train_proposal为关键函数\n",
    "        \n",
    "        def _center(gt):\n",
    "            '''\n",
    "            gt的中心坐标\n",
    "            '''\n",
    "            x = int( ( gt[0] + gt[1] ) / 2 )\n",
    "            y = int( ( gt[2] + gt[3] ) / 2 )\n",
    "        \n",
    "            return [x,y]\n",
    "        \n",
    "        def _is_in_grid(gt_center , grid):\n",
    "            '''\n",
    "            判断gt的中心是否在此grid cell中\n",
    "            '''\n",
    "            if (grid[0] <= gt_center[0] <= grid[1]) and (grid[2] <= gt_center[1] <= grid[3]):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "        def _target_gt(gt , grid):\n",
    "            '''\n",
    "            将gt变为target需要的格式\n",
    "            '''\n",
    "            center = _center(gt)\n",
    "            #gt中心坐标在对应的grid中的偏移\n",
    "            target_x = ( center[0] - grid[0] ) / 64\n",
    "            target_y = ( center[1] - grid[2] ) / 64\n",
    "            \n",
    "            target_w = ( gt[1]-gt[0] ) / 448\n",
    "            target_h = ( gt[3]-gt[2] ) / 448\n",
    "            \n",
    "            return [target_x , target_y , target_w , target_h]\n",
    "            \n",
    "        \n",
    "        '''下面操作在448*448坐标系中进行'''\n",
    "        \n",
    "        #S*S grid cells\n",
    "        x_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        y_slice = [ [64*i , 64*(i+1)] for i in [0,1,2,3,4,5,6] ]\n",
    "        \n",
    "        grid = np.zeros(shape=[7 , 7] , dtype=list)\n",
    "        \n",
    "        for x_idx , x in enumerate(x_slice):\n",
    "            for y_idx , y in enumerate(y_slice):\n",
    "                grid[x_idx][y_idx] = y + x\n",
    "        \n",
    "        #训练样本中的y\n",
    "        #[confidence x y w h]*2 + cls_score\n",
    "        target = np.zeros(shape=[7 , 7 , 30] , dtype=float)\n",
    "        \n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                for idx , gt in enumerate(ground_truth_coord):\n",
    "                    \n",
    "                    if _is_in_grid( _center(gt) , grid[i][j]):\n",
    "                        '''\n",
    "                        此gt的中心位于此grid cell中\n",
    "                        '''\n",
    "                        iou = self.IoU(gt , grid[i][j])\n",
    "                        \n",
    "                        #如果出现一个grid cell有多个gt对应 则只保留iou最高的前两个\n",
    "                        if target[i][j][0] > target[i][j][5]:\n",
    "                            if iou > target[i][j][5]:\n",
    "                                target[i][j][5] = iou\n",
    "                                target[i][j][6 : 10] = _target_gt(gt , grid[i][j])\n",
    "                                target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                        elif target[i][j][0] <= target[i][j][5]:\n",
    "                            if iou > target[i][j][0]:\n",
    "                                target[i][j][0] = iou\n",
    "                                target[i][j][1 : 5] = _target_gt(gt , grid[i][j])\n",
    "                                target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                        #并入上面\n",
    "                        #else:\n",
    "                        #    #先执行此处\n",
    "                        #    if iou > target[i][j][0]:\n",
    "                        #        #只要大于 随意选一个位置即可\n",
    "                        #        target[i][j][0] = iou\n",
    "                        #        target[i][j][1 : 5] = _target_gt(gt)\n",
    "                        #        target[i][j][ labels[idx] + 10 ] = 1.0\n",
    "                \n",
    "                #here\n",
    "                #处理完一个grid cell\n",
    "                #如果[i , j] grid只有一个gt与之对应 则将其翻倍（因为yolo v1一个grid对应两个bounding box）\n",
    "                #只有一个gt与之对应 则只会出现在target[i][j][0 1 2 3 4]处\n",
    "                if (target[i][j][0] != 0.0) and (target[i][j][5] == 0.0):\n",
    "                    target[i][j][5:10] = target[i][j][0:5]\n",
    "                    #cls_score是一样的 同一个位置\n",
    "                                                  \n",
    "        return np.array(target)\n",
    "    \n",
    "    \n",
    "    def load(self , img_path_name):\n",
    "        '''\n",
    "        img_path_name:绝对路径\n",
    "        '''\n",
    "        \n",
    "        #图片数据 ground truth具体数据 ground truth对应label ground truth坐标信息 图片文件名\n",
    "        img_arr , labels , ground_truth_coord = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        ground_truth_coord = self.map2new(img_arr.shape , ground_truth_coord) #将ground_truch坐标从原坐标系映射至448*448坐标系中\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (448 , 448))\n",
    "        img_arr = img_arr / 127.5 - 1 #对下面的get_train_proposal没有影响\n",
    "        \n",
    "        target = self.get_train_proposal(labels , ground_truth_coord)\n",
    "        \n",
    "        '''\n",
    "        resize 并 归一化像素值\n",
    "        img_arr 为 BGR形式\n",
    "        '''\n",
    "        \n",
    "        '''[R G B] [123.68 116.779 103.939]\n",
    "        减去每个通道的像素平均值 归一化'''\n",
    "        #img_arr[:,:,0] = img_arr[:,:,0] - 103.939\n",
    "        #img_arr[:,:,1] = img_arr[:,:,1] - 116.779\n",
    "        #img_arr[:,:,2] = img_arr[:,:,2] - 123.680\n",
    "        \n",
    "        #'''增加一维 batch维'''\n",
    "        return np.expand_dims(img_arr , axis=0) , target\n",
    "    \n",
    "    \n",
    "    def get_test_proposal(self , img_arr):\n",
    "        '''\n",
    "        return:rois\n",
    "        proposals_coord\n",
    "        '''\n",
    "        \n",
    "        h = img_arr.shape[0]\n",
    "        w = img_arr.shape[1]\n",
    "        \n",
    "        def bbox_trans(_rect):\n",
    "            rect = [-1,-1,-1,-1]\n",
    "            \n",
    "            rect[0] = int(_rect[0]*600 / w)\n",
    "            rect[1] = int(_rect[1]*600 / w)\n",
    "            rect[2] = int(_rect[2]*1000 / h)\n",
    "            rect[3] = int(_rect[3]*1000 / h)\n",
    "        \n",
    "            return rect\n",
    "        \n",
    "        anchors = [] #x1 x2 y1 y2 计算iou使用\n",
    "        \n",
    "        feature_map_height = 61\n",
    "        feature_map_width = 36\n",
    "        \n",
    "        scales = [128 , 256 , 512]\n",
    "        ratios = [[1,2] , [1,1] , [2,1]] #用scale除以即可 [height_ratio width_ratio]\n",
    "        \n",
    "        '''\n",
    "        x_0 y_0 为 feature map中的坐标\n",
    "        \n",
    "        x_0_coord y_0_coord 为原图中的坐标（中点坐标）\n",
    "        \n",
    "        跨越边界的anchor 进行截断\n",
    "        '''\n",
    "        \n",
    "        for x_0 in range(61): #height\n",
    "            for y_0 in range(36): #width\n",
    "                \n",
    "                x_0_coord = x_0 * 16\n",
    "                y_0_coord = y_0 * 16\n",
    "                \n",
    "                for scale in scales:\n",
    "                    for ratio in ratios:\n",
    "                        scale_height = int(scale / ratio[0])\n",
    "                        scale_width = int(scale / ratio[1])\n",
    "                    \n",
    "                        x_1_coord = int(x_0_coord - scale_width/2)\n",
    "                        y_1_coord = int(y_0_coord - scale_height/2)\n",
    "\n",
    "                        if x_1_coord < 0:\n",
    "                            x_1_coord = 0\n",
    "                            \n",
    "                        if y_1_coord < 0:\n",
    "                            y_1_coord = 0\n",
    "\n",
    "                        x_2_coord = int(x_0_coord + scale_width/2)\n",
    "                        y_2_coord = int(y_0_coord + scale_height/2)\n",
    "\n",
    "                        if x_2_coord > 600:\n",
    "                            x_2_coord = 600\n",
    "                            \n",
    "                        if y_2_coord > 1000:\n",
    "                            y_2_coord = 1000\n",
    "                        \n",
    "                        anchors.append( [x_1_coord , x_2_coord , y_1_coord , y_2_coord] )\n",
    "\n",
    "        return np.array(anchors)\n",
    "    \n",
    "    def load_test(self , img_path_name):\n",
    "        img_arr = cv2.imread(img_path_name)\n",
    "        \n",
    "        anchors = self.get_test_proposal(img_arr)\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (600 , 1000))\n",
    "        img_arr = img_arr / 127.5 - 1.0\n",
    "        \n",
    "        return np.expand_dims(img_arr , axis=0) , anchors\n",
    "\n",
    "# class Img_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        path = np.random.choice(self.img_file_names_train)\n",
    "        \n",
    "        x , target = self.img_generator.load(path)\n",
    "    \n",
    "        return x , target\n",
    "    \n",
    "    def get_batch_test(self , path):\n",
    "        \n",
    "        if not path:\n",
    "            #未指定path 从测试目录中随机选一张图片测试\n",
    "            path = np.random.choice(self.img_file_names_test)\n",
    "        \n",
    "        x , target = self.img_generator.load_test(path)\n",
    "        \n",
    "        return x , target\n",
    "    \n",
    "    \n",
    "    def target2coord(self , bbox_pred , img_arr , anchors):\n",
    "        img_height = img_arr.shape[0]\n",
    "        img_width = img_arr.shape[1]\n",
    "        \n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        def ot(target):\n",
    "            x_c = target[0]\n",
    "            y_c = target[1]\n",
    "            w = target[2]\n",
    "            h = target[3]\n",
    "            \n",
    "            x1 = 0.5*(2*x_c-w)\n",
    "            y1 = 0.5*(2*y_c-h)\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            \n",
    "            x1=int(round(x1))\n",
    "            y1=int(round(y1))\n",
    "            x2=int(round(x2))\n",
    "            y2=int(round(y2))\n",
    "            \n",
    "            if x1<0:\n",
    "                x1 = 0\n",
    "            if x2>img_width:\n",
    "                x2 = img_width\n",
    "            if y1<0:\n",
    "                y1 = 0\n",
    "            if y2>img_height:\n",
    "                y2 = img_height\n",
    "                            \n",
    "            return [x1 , x2 , y1 , y2]\n",
    "        \n",
    "        def target2rect(target_hat , P_box):\n",
    "            t_x = target_hat[0]\n",
    "            t_y = target_hat[1]\n",
    "            t_w = target_hat[2]\n",
    "            t_h = target_hat[3]\n",
    "            \n",
    "            P_x , P_y , P_w , P_h = to(P_box) #将P框转换为 中点坐标 宽 高 形式\n",
    "            \n",
    "            G_x_hat = P_w*t_x+P_x\n",
    "            G_y_hat = P_h*t_y+P_y\n",
    "            G_w_hat = P_w*np.exp(t_w)\n",
    "            G_h_hat = P_h*np.exp(t_h)\n",
    "            \n",
    "            return ot([G_x_hat , G_y_hat , G_w_hat , G_h_hat]) #ot还需要转化为(x1,x2,y1,y2)形式\n",
    "        \n",
    "        bbox_coord_pred = []\n",
    "        \n",
    "        for i in range(len(bbox_pred)):\n",
    "            bbox_coord_pred.append( target2rect(bbox_pred[i] , anchors[i]) )\n",
    "                \n",
    "        return bbox_coord_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Display(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def display(self , img_arr , labels , bbox , name):    \n",
    "        for i in range(len(labels)):\n",
    "            \n",
    "            x1 = bbox[i][0]\n",
    "            x2 = bbox[i][1]\n",
    "            y1 = bbox[i][2]\n",
    "            y2 = bbox[i][3]\n",
    "            \n",
    "            img_arr = cv2.rectangle(img_arr , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "            \n",
    "            img_arr = cv2.putText(img_arr , labels[i] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "        \n",
    "        #plt.imshow(meta_img) #图像查看\n",
    "        \n",
    "        plt.imsave(arr=img_arr[: , : ,[2,1,0]] , fname = 'result/%s.jpg' % name) #保存图像\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "#alexnet原始模型以及预训练参数导入\n",
    "class AlexNet_model(object):\n",
    "    def __init__(self , is_training=True):\n",
    "        \n",
    "        self.x = tf.placeholder(dtype=tf.float32 , shape=[1 , 448 , 448 , 3])        \n",
    "        \n",
    "        self.build(is_training) #构建网络产生输出\n",
    "        \n",
    "        if is_training:\n",
    "            self.target = tf.placeholder(dtype=tf.float32 , shape=[7 , 7 , 30])\n",
    "            self.loss()\n",
    "\n",
    "    def build(self , is_training):\n",
    "        #arch from paper\n",
    "        def _conv(_input , num_outputs , kernel_size , stride=1):\n",
    "            return slim.conv2d(_input , num_outputs=num_outputs , kernel_size=kernel_size , stride=stride , activation_fn=tf.nn.leaky_relu ,\n",
    "                             weights_initializer=tf.initializers.truncated_normal(stddev=0.01) ,\n",
    "                             biases_initializer=tf.initializers.constant(0.0))\n",
    "        \n",
    "        def _max_pool(_input , kernel_size=2 , stride=2):\n",
    "            return slim.max_pool2d(_input , kernel_size=kernel_size , stride=stride)\n",
    "        \n",
    "        def _conv_module_a(_input):\n",
    "            _output = _conv(_input , 256 , 1)\n",
    "            return _conv(_output , 512 , 3)\n",
    "        \n",
    "        def _conv_module_b(_input):\n",
    "            _output = _conv(_input , 512 , 1)\n",
    "            return _conv(_output , 1024 , 3)\n",
    "        \n",
    "        output = _conv(self.x , 64 , 7 , 2)\n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        output = _conv(output , 192 , 3)              \n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        output = _conv(output , 128 , 1)\n",
    "        output = _conv(output , 256 , 3)\n",
    "        output = _conv(output , 256 , 1)\n",
    "        output = _conv(output , 512 , 3)\n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        #4 times\n",
    "        output = _conv_module_a(output)\n",
    "        output = _conv_module_a(output)\n",
    "        output = _conv_module_a(output)\n",
    "        output = _conv_module_a(output)\n",
    "        \n",
    "        output = _conv(output , 512 , 1)\n",
    "        output = _conv(output , 1024 , 3)\n",
    "        output = _max_pool(output)\n",
    "        \n",
    "        #twice\n",
    "        output = _conv_module_b(output)\n",
    "        output = _conv_module_b(output)\n",
    "\n",
    "        output = _conv(output , 1024 , 3)\n",
    "        output = _conv(output , 1024 , 3 , 2)\n",
    "        \n",
    "        output = _conv(output , 1024 , 3)\n",
    "        output = _conv(output , 1024 , 3)\n",
    "        \n",
    "        output = slim.flatten(output)\n",
    "        \n",
    "        #paper中为4096 pc性能达不到\n",
    "        output = slim.fully_connected(inputs=output , num_outputs=1024 , activation_fn=tf.nn.leaky_relu ,\n",
    "                                     weights_initializer=tf.initializers.truncated_normal(stddev=0.01),\n",
    "                                     biases_initializer=tf.initializers.constant(0.0))\n",
    "        \n",
    "        #引入dropout\n",
    "        output = slim.dropout(output , keep_prob=0.5 , is_training=is_training)\n",
    "        \n",
    "        #tf.identity 使用线性激活函数 nan错误 使用leaky relu也会出错 换成relu\n",
    "        output = slim.fully_connected(inputs=output , num_outputs=7*7*30 , activation_fn=tf.nn.relu  ,\n",
    "                                     weights_initializer=tf.initializers.truncated_normal(stddev=0.01),\n",
    "                                     biases_initializer=tf.initializers.constant(0.0))\n",
    "        \n",
    "        self.output = tf.reshape(output , shape=[7 , 7 , 30]) #丢弃掉batch维 没用\n",
    "\n",
    "        \n",
    "    def loss(self):\n",
    "        lambda_coord = 5.0\n",
    "        lambda_noobj = 0.5\n",
    "        \n",
    "        #[:,:,0]\n",
    "        _mask = tf.cast( tf.greater( tf.slice(self.target,begin=[0,0,0],size=[7,7,1]) , np.zeros(shape=[7,7,1] , dtype=float) ) , dtype=tf.float32 )\n",
    "        mask = tf.tile(_mask , multiples=[1 , 1 , 2]) #7*7*2\n",
    "        #[:,:,[1,2]]\n",
    "        loss_coord = tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,1],size=[7,7,2]) - tf.slice(self.target,begin=[0,0,1],size=[7,7,2]) ) * mask ) )\n",
    "        #[:,:,[3,4]]\n",
    "        loss_coord += tf.reduce_sum( tf.square( (tf.sqrt( tf.slice(self.output,begin=[0,0,3],size=[7,7,2]) ) - tf.sqrt( tf.slice(self.target,begin=[0,0,3],size=[7,7,2]))) * mask ) )\n",
    "        \n",
    "        loss_coord = lambda_coord * loss_coord\n",
    "        \n",
    "        #[:,:,:[0,5]]\n",
    "        loss_iou = tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,0],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,0],size=[7,7,1])) * mask ) )\n",
    "        loss_iou += tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,5],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,5],size=[7,7,1])) * mask ) )\n",
    "        #[:,:,:[0,5]]\n",
    "        loss_iou += lambda_noobj * (tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,0],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,0],size=[7,7,1]) ) * (1.0-mask) ) ) +\\\n",
    "                                    tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,5],size=[7,7,1]) - tf.slice(self.target,begin=[0,0,5],size=[7,7,1]) ) * (1.0-mask) ) ))\n",
    "        \n",
    "        mask = tf.tile(_mask , multiples=[1,1,20]) #7*7*20 (因为20 classes)\n",
    "        #[:,:,10:]\n",
    "        loss_cls = tf.reduce_sum( tf.square( ( tf.slice(self.output,begin=[0,0,10],size=[7,7,20]) - tf.slice(self.target,begin=[0,0,10],size=[7,7,20]) ) * mask ) )\n",
    "        \n",
    "        self.total_loss = loss_coord + loss_iou + loss_cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "\n",
    "class YOLO_V1(object):\n",
    "    '''\n",
    "    完整模型\n",
    "    '''\n",
    "    \n",
    "    def __init__(self , is_training = True):      \n",
    "        self.dataset = Dataset()\n",
    "        self.display = Display()\n",
    "        \n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.filewriter_path = 'save/logs' #模型可视化\n",
    "        self.checkpoint_path = 'save/model/' #模型持久化\n",
    "                              \n",
    "        self.model = AlexNet_model(is_training)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        \n",
    "        if is_training:\n",
    "            '''训练参数'''\n",
    "            self.epoch = 100000\n",
    "            \n",
    "            self.global_step = tf.Variable(initial_value=0 , trainable=False)\n",
    "            \n",
    "            self.learning_rate = tf.train.exponential_decay(learning_rate=0.0001 , global_step=self.global_step,\n",
    "                                                            decay_steps=900 , decay_rate=0.8 , staircase=True)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.model.total_loss , global_step=self.global_step)\n",
    "        \n",
    "            '''引入滑动平均'''\n",
    "            self.ema = tf.train.ExponentialMovingAverage(decay=0.9) #滑动平均\n",
    "            self.average_op = self.ema.apply(tf.trainable_variables()) #给所有的可训练变量应用滑动平均\n",
    "            \n",
    "            with tf.control_dependencies([self.optimizer]):\n",
    "                self.train_op = tf.group(self.average_op)\n",
    "            \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        if is_training:\n",
    "            tf.summary.scalar('total_loss' , self.model.total_loss)\n",
    "            self.merged_summary = tf.summary.merge_all() #merge all summaries in the default graph\n",
    "            self.writer = tf.summary.FileWriter(self.filewriter_path , self.sess.graph) #可视化\n",
    "            \n",
    "        self.saver = tf.train.Saver(max_to_keep=2) #max_to_keep 最大保存5次模型  之后继续保存则会覆盖前面的模型\n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        if os.path.exists(self.checkpoint_path+'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path))\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer()) \n",
    "        \n",
    "        for i in range(100000):\n",
    "            x , target = self.dataset.get_batch()\n",
    "            \n",
    "            self.sess.run(self.train_op , feed_dict={self.model.x : x , self.model.target : target} )\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                self.saver.save(self.sess , self.checkpoint_path + 'model.ckpt' , global_step = i)\n",
    "                \n",
    "                total_loss , summary = self.sess.run([self.model.total_loss , self.merged_summary] , feed_dict={self.model.x : x , self.model.target : target})\n",
    "                \n",
    "                self.writer.add_summary(summary , global_step = i)\n",
    "                \n",
    "                print(i , total_loss)\n",
    "            \n",
    "        self.writer.close() #event to disk and close the file\n",
    "\n",
    "    def predict(self , path=None , scores_threshold = 0.1 , nms_iou_threshold = 0.7):\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path) )\n",
    "            \n",
    "            return self._predict(path , scores_threshold , nms_iou_threshold)\n",
    "            \n",
    "        else:\n",
    "            print('no model!!!')\n",
    "            return \n",
    "    \n",
    "    def _predict(self , path , scores_threshold , nms_iou_threshold):\n",
    "        x , rois , img_arr , proposals_coord = self.dataset.get_batch_test(path)\n",
    "        \n",
    "        cls_pred , bbox_pred = self.sess.run([self.model.cls_pred , self.model.bbox_pred] , feed_dict={self.x : x , self.rois : rois})\n",
    "        \n",
    "        #转换为原始图片中的坐标\n",
    "        bbox_coord_pred = self.dataset.target2coord(bbox_pred , img_arr , proposals_coord)\n",
    "        \n",
    "        '''\n",
    "        由target到原始坐标 在进行nms\n",
    "        '''\n",
    "        \n",
    "        scores_pred_f = [] #符合条件的概率值\n",
    "        bbox_coord_pred_f = [] #符合条件的框子坐标\n",
    "        \n",
    "        labels_pred_f = [] #label名字\n",
    "        \n",
    "        for i in range(len(cls_pred)):\n",
    "            if np.argmax(cls_pred[i]) != 0 and (np.max(cls_pred[i]) > scores_threshold):\n",
    "                scores_pred_f.append(np.max(cls_pred[i]))\n",
    "                \n",
    "                bbox_coord_pred_f.append(bbox_coord_pred[i])\n",
    "                \n",
    "                labels_pred_f.append(LABEL2STR[np.argmax(cls_pred[i])])\n",
    "        \n",
    "        scores_pred_f = np.array(scores_pred_f)\n",
    "        bbox_coord_pred_f = np.array(bbox_coord_pred_f)\n",
    "        labels_pred_f = np.array(labels_pred_f)\n",
    "        \n",
    "        #降序scores\n",
    "        sort_idx = np.argsort(- np.array(scores_pred_f) )\n",
    "        \n",
    "        scores_pred_f = scores_pred_f[sort_idx]\n",
    "        bbox_coord_pred_f = bbox_coord_pred_f[sort_idx]\n",
    "        labels_pred_f = labels_pred_f[sort_idx]\n",
    "                \n",
    "        final_idx = self._nms(scores_pred_f , bbox_coord_pred_f , nms_iou_threshold)\n",
    "                \n",
    "        #scores_pred_f = scores_pred_f[final_idx] #用不上\n",
    "        bbox_coord_pred_f = bbox_coord_pred_f[final_idx]\n",
    "        labels_pred_f = labels_pred_f[final_idx]\n",
    "                \n",
    "        # 绘制并保存\n",
    "        self.display.display(img_arr , labels_pred_f , bbox_coord_pred_f , 'first')\n",
    "        \n",
    "        return cls_pred , bbox_coord_pred , labels_pred_f , bbox_coord_pred_f\n",
    "        \n",
    "        \n",
    "    def _nms(self , probability_hat , rects_hat , nms_iou_threshold):\n",
    "        idx = []\n",
    "        \n",
    "        length = len(probability_hat)\n",
    "        lost_flag = [1]*length #标记丢弃的框 0表示丢弃\n",
    "        \n",
    "        max_score_idx = 0 #记录当前最大score的idx\n",
    "        \n",
    "        while max_score_idx < length:\n",
    "            max_score_rect = rects_hat[max_score_idx]\n",
    "            \n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1 and self.img_generator.IoU( max_score_rect , rects_hat[i] ) > nms_iou_threshold: #大于阈值 丢弃\n",
    "                    lost_flag[i] = 0\n",
    "\n",
    "            max_score_idx_bak = max_score_idx #后续使用\n",
    "            \n",
    "            #让max_score_idx指向下一个没被丢弃的最大值\n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1:\n",
    "                    max_score_idx = i\n",
    "                    break\n",
    "            \n",
    "            #说明max_score_idx没有移动过 即后续的都被丢弃了 终止循环\n",
    "            if max_score_idx == max_score_idx_bak:\n",
    "                break\n",
    "        \n",
    "        for i in range(length):\n",
    "            if lost_flag[i] == 1:\n",
    "                idx.append(i)\n",
    "                \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = YOLO_V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.909016\n",
      "10 5.7129765\n",
      "20 2.821789\n",
      "30 2.9340255\n",
      "40 2.0163012\n",
      "50 5.452017\n",
      "60 2.9741642\n",
      "70 14.488641\n",
      "80 1.3236729\n"
     ]
    }
   ],
   "source": [
    "test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
