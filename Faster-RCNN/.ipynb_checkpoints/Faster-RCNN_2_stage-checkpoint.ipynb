{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "#解析使用\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from skimage import transform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "# import selectivesearch as ss #候选框产生使用 RPN不使用此函数\n",
    "\n",
    "from ImageNet_classes import class_names #验证alexnet使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TEST_DATA_PATH = '../../tensorflow2/dataset/VOC2012test/JPEGImages/'\n",
    "\n",
    "TRAIN_XML_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'\n",
    "TEST_XML_PATH = '../../tensorflow2/dataset/VOC2012test/Annotations/'\n",
    "\n",
    "OBJECT_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/ImageSets/Main/' #SVM需要使用的训练数据（正负样本） 训练20个svm\n",
    "\n",
    "#pascal VOC数据集目标数量\n",
    "#目标的数目 还有一个背景\n",
    "CLASSES_NUM = 20+1\n",
    "\n",
    "STR = [\n",
    "    'background', #label=0\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}\n",
    "#STR2LABEL = {value:idx for idx , value in enumerate(STR)}\n",
    "\n",
    "\n",
    "STR2LABEL['none'] = 'none' #先不使用part部分 只进行naive目标检测\n",
    "\n",
    "#目标检测相关\n",
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "#NMS相关\n",
    "NMS_IoU_THRESHOLD = 0.3 #or ~0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file_names_train = glob(TRAIN_XML_PATH + '*') #所有的xml文件 完整路径\n",
    "\n",
    "#从xml文件中读出图片相关的信息\n",
    "\n",
    "def xml_parse(xml_file):\n",
    "    '''\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "    xml文件中的shape格式为 (width height 3)\n",
    "    '''\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    \n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    shape = (width , height , channel)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        #name\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        name_box = name_list[0].childNodes[0].data\n",
    "\n",
    "        #bounding box points\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        x1_list = bndbox[0].getElementsByTagName('xmin')\n",
    "        x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "        y1_list = bndbox[0].getElementsByTagName('ymin')\n",
    "        y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "        x2_list = bndbox[0].getElementsByTagName('xmax')\n",
    "        x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "        y2_list = bndbox[0].getElementsByTagName('ymax')\n",
    "        y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "        crop_box = [x1,x2,y1,y2]\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    #shape:[width height channel]\n",
    "    #crop_box:[x1 x2 y1 y2]\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "\n",
    "#xml_parse(xml_file_names_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xml_parse(xml_file_names_train[897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#不需要修改\n",
    "class Image(object):\n",
    "    '''\n",
    "    图片的真实信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH+'*') #训练全路径信息\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        '''\n",
    "        如果传入 传入完整路径信息\n",
    "        return img_arr , ground_truth_data , labels , crop_boxes , img_path_name[-15:-4]\n",
    "        img_arr的shape为 (height width 3) 与xml文件中区分\n",
    "        '''\n",
    "        if not img_path_name:\n",
    "            #没有指定文件名\n",
    "            img_path_name = np.random.choice(self.img_file_names_train) #随机选择一张图片\n",
    "            #img_path_idx = np.random.randint(0 , high = len(self.img_file_names_train)) #随机索引\n",
    "      \n",
    "        img_arr = cv2.imread(img_path_name) #BGR height*width*chanel\n",
    "        \n",
    "        xml_file_name = TRAIN_XML_PATH + img_path_name[-15:-4] +  '.xml'\n",
    "        \n",
    "        _ , _ , name_boxes , crop_boxes = xml_parse(xml_file_name)\n",
    "        \n",
    "        ground_truth_data = [] #存储bndbox的图像 数据信息\n",
    "        labels = [] #存储与bndbox对应的 label信息\n",
    "\n",
    "        for i in range(len(crop_boxes)): #多个object\n",
    "            x1 = crop_boxes[i][0]\n",
    "            x2 = crop_boxes[i][1]\n",
    "            y1 = crop_boxes[i][2]\n",
    "            y2 = crop_boxes[i][3]\n",
    "            \n",
    "            ground_truth_data.append(img_arr[y1:y2 , x1:x2 , :])\n",
    "            \n",
    "            labels.append(STR2LABEL.get(name_boxes[i] , 'none'))\n",
    "        \n",
    "        #图片数据 ground truth具体数据 bndbox对应label bndbox坐标信息 图片文件名\n",
    "        \n",
    "        return img_arr , ground_truth_data , labels , crop_boxes , img_path_name[-15:-4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Img_generator(object):\n",
    "    def __init__(self):\n",
    "        self.img_loader = Image()\n",
    "\n",
    "    #计算bbox面积\n",
    "    def bbox_area(self , bbox):\n",
    "        w = bbox[1] - bbox[0]\n",
    "        h = bbox[3] - bbox[2]\n",
    "        \n",
    "        return w*h\n",
    "    \n",
    "    #计算交并比\n",
    "    def IoU(self , bbox_a , bbox_b):\n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            if area_inter <= 0.0:\n",
    "                return 0.0\n",
    "            \n",
    "            if self.bbox_area(bbox_a) <= 0.0 or self.bbox_area(bbox_b) <= 0.0:\n",
    "                return 0.0\n",
    "            \n",
    "            union_area = self.bbox_area(bbox_a) + self.bbox_area(bbox_b) - area_inter\n",
    "            \n",
    "            if union_area <= 0.0:\n",
    "                return 0.0            \n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    #转换为 位置参数\n",
    "    def __to_t(self , G_box , P_box):\n",
    "        #print(G_box , P_box) #debug\n",
    "        \n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        G_x , G_y , G_w , G_h = to(G_box)\n",
    "        P_x , P_y , P_w , P_h = to(P_box)\n",
    "        \n",
    "        t_x = (G_x-P_x)/P_w\n",
    "        t_y = (G_y-P_y)/P_h\n",
    "        t_w = np.log(G_w/P_w)\n",
    "        t_h = np.log(G_h/P_h)\n",
    "        \n",
    "        return t_x , t_y , t_w , t_h\n",
    "    \n",
    "    def get_train_proposal(self , img_arr , labels , ground_truth_coord):\n",
    "        \n",
    "        anchors = np.zeros(shape=[61,36,9,7] , dtype=float) #保存非位置参数 直观的的坐标 所有的计算在此进行\n",
    "        anchors_aux = np.zeros(shape=[61,36,9,7] , dtype=float) #保存位置参数 不参与计算 只进行保存\n",
    "        \n",
    "        feature_map_height = 61\n",
    "        feature_map_width = 36\n",
    "        \n",
    "        scales = [128 , 256 , 512]\n",
    "        ratios = [[1,2] , [1,1] , [2,1]] #用scale除以即可 [height_ratio width_ratio]\n",
    "        \n",
    "        '''\n",
    "        跑出图片边界的anchor丢弃\n",
    "        '''\n",
    "        \n",
    "        #x_0 y_0 为 feature map中的坐标\n",
    "        for x_0 in range(61): #width\n",
    "            for y_0 in range(36): #height\n",
    "                #x_0_coord y_0_coord 为原图中的坐标（中点坐标）\n",
    "                x_0_coord = x_0 * 16\n",
    "                y_0_coord = y_0 * 16\n",
    "                \n",
    "                for scale_idx , scale in enumerate(scales):\n",
    "                    for ratio_idx , ratio in enumerate(ratios):\n",
    "                        scale_height = int(scale / ratio[0])\n",
    "                        scale_width = int(scale / ratio[1])\n",
    "                    \n",
    "                        x_1_coord = int(x_0_coord - scale_width/2)\n",
    "                        y_1_coord = int(y_0_coord - scale_height/2)\n",
    "\n",
    "                        if x_1_coord < 0 or y_1_coord < 0:\n",
    "                            anchors[x_0 , y_0 , scale_idx*3+ratio_idx][0] = -1 #不参与训练的样本 丢弃 标记为-1\n",
    "                            anchors_aux[x_0 , y_0 , scale_idx*3+ratio_idx][0] = -1\n",
    "                            continue\n",
    "\n",
    "                        x_2_coord = int(x_0_coord + scale_width/2)\n",
    "                        y_2_coord = int(y_0_coord + scale_height/2)\n",
    "\n",
    "                        if x_2_coord > 600 or y_2_coord > 1000:\n",
    "                            anchors[x_0 , y_0 , scale_idx*3+ratio_idx][0] = -1 #不参与训练的样本 丢弃 标记为-1\n",
    "                            anchors_aux[x_0 , y_0 , scale_idx*3+ratio_idx][0] = -1\n",
    "                            continue\n",
    "                        \n",
    "                        #基本的anchors 不出边界 图片内部\n",
    "                        anchors[x_0 , y_0 , scale_idx*3+ratio_idx][2 : 6] = [x_1_coord , x_2_coord , y_1_coord , y_2_coord]\n",
    "\n",
    "        '''\n",
    "        对ground truth进行放缩\n",
    "        '''\n",
    "        img_h = img_arr.shape[0]\n",
    "        img_w = img_arr.shape[1]\n",
    "        \n",
    "        def bbox_trans(_rect):\n",
    "            rect = [-1,-1,-1,-1]\n",
    "            \n",
    "            rect[0] = int(_rect[0]*600 / img_w)\n",
    "            rect[1] = int(_rect[1]*600 / img_w)\n",
    "            rect[2] = int(_rect[2]*1000 / img_h)\n",
    "            rect[3] = int(_rect[3]*1000 / img_h)\n",
    "        \n",
    "            return rect\n",
    "                \n",
    "        '''\n",
    "        每个gt iou最大的anchor作为正样本\n",
    "        '''\n",
    "        \n",
    "        for j in range(len(ground_truth_coord)):\n",
    "            max_iou = 0.0\n",
    "            max_iou_idx = [0,0,0]\n",
    "            \n",
    "            gt_coord_trans = bbox_trans( ground_truth_coord[j] )\n",
    "            \n",
    "            for w in range(61): #width\n",
    "                for h in range(36): #height\n",
    "                    for anchor_idx in range(9):\n",
    "                        if anchors[w , h , anchor_idx][0] != -1:\n",
    "                            #不等于-1参与训练\n",
    "                            iou = self.IoU(gt_coord_trans , anchors[w,h,anchor_idx][2:6])\n",
    "                            \n",
    "                            if iou > max_iou:\n",
    "                                max_iou = iou\n",
    "                                max_iou_idx = [w,h,anchor_idx]\n",
    "              \n",
    "            if anchors[max_iou_idx[0] , max_iou_idx[1] , max_iou_idx[2]][0] != -1:\n",
    "                #判断 max_iou_idx没有被更新过 一直是[0 0 0]\n",
    "                #如果[0 0 0]对应的标识不是-1 即参与训练\n",
    "                anchors_aux[max_iou_idx[0] , max_iou_idx[1] , max_iou_idx[2]][1] = 1\n",
    "                anchors_aux[max_iou_idx[0] , max_iou_idx[1] , max_iou_idx[2]][2:6] = self.__to_t(gt_coord_trans , anchors[max_iou_idx[0] , max_iou_idx[1] , max_iou_idx[2]][2:6])\n",
    "                anchors_aux[max_iou_idx[0] , max_iou_idx[1] , max_iou_idx[2]][6] = labels[j]\n",
    "            #else:\n",
    "            #    continue\n",
    "        \n",
    "        '''\n",
    "        寻找剩余的正负样本(训练集)\n",
    "        '''\n",
    "        for w in range(61): #width\n",
    "            for h in range(36): #height\n",
    "                for anchor_idx in range(9):\n",
    "                    if anchors[w,h,anchor_idx][0] != -1:\n",
    "                        #不等于-1参与训练\n",
    "                        negative_count = 0 #产生负样本计数器\n",
    "\n",
    "                        for j in range(len(ground_truth_coord)):\n",
    "\n",
    "                            gt_coord_trans = bbox_trans( ground_truth_coord[j] )\n",
    "\n",
    "                            iou = self.IoU(gt_coord_trans , anchors[w,h,anchor_idx][2:6])\n",
    "\n",
    "                            if iou > 0.7: \n",
    "                                #正样本\n",
    "                                #每一个正样本anchor只可能对应一个ground truth\n",
    "                                #print(iou , gt_coord_trans , anchors[w,h,anchor_idx][2:6])\n",
    "                                anchors_aux[w,h,anchor_idx][1] = 1\n",
    "                                anchors_aux[w,h,anchor_idx][2:6] = self.__to_t(gt_coord_trans , anchors[w,h,anchor_idx][2:6])\n",
    "                                anchors_aux[w,h,anchor_idx][6] = labels[j]\n",
    "                                \n",
    "                                break #为当前的正样本anchor找到了ground truth\n",
    "\n",
    "                            elif iou < 0.3:\n",
    "                                negative_count = negative_count + 1\n",
    "                            else:\n",
    "                                #此处的样本不参与训练\n",
    "                                anchors_aux[w,h,anchor_idx][0] = -1\n",
    "\n",
    "                            if negative_count == len(ground_truth_coord):\n",
    "                                #与所有的ground truth的iou均小于0.3 则为负样本\n",
    "                                anchors_aux[w,h,anchor_idx][0] = 1\n",
    "                                \n",
    "                                break\n",
    "        \n",
    "        anchors_aux = np.reshape(anchors_aux , newshape=[-1 , 7])\n",
    "        \n",
    "        return anchors_aux\n",
    "    \n",
    "    \n",
    "    def load(self , img_path_name):\n",
    "        '''\n",
    "        img_path_name:绝对路径\n",
    "        '''\n",
    "        \n",
    "        #图片数据 ground truth具体数据 ground truth对应label ground truth坐标信息 图片文件名\n",
    "        img_arr , _ , labels , ground_truth_coord , _ = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        anchors = self.get_train_proposal(img_arr , labels , ground_truth_coord)\n",
    "        \n",
    "        '''\n",
    "        resize 并 归一化像素值\n",
    "        img_arr 为 BGR形式\n",
    "        '''\n",
    "        img_arr = cv2.resize(img_arr , (600 , 1000))\n",
    "        '''[R G B] [123.68 116.779 103.939]\n",
    "        减去每个通道的像素平均值 归一化'''\n",
    "        #img_arr[:,:,0] = img_arr[:,:,0] - 103.939\n",
    "        #img_arr[:,:,1] = img_arr[:,:,1] - 116.779\n",
    "        #img_arr[:,:,2] = img_arr[:,:,2] - 123.680\n",
    "        \n",
    "        img_arr = img_arr / 127.5 - 1\n",
    "        \n",
    "        #'''增加一维 batch_size维'''\n",
    "        return np.expand_dims(img_arr , axis=0) , anchors\n",
    "    \n",
    "    def get_test_proposal(self , img_arr):\n",
    "        '''\n",
    "        return:rois\n",
    "        proposals_coord\n",
    "        '''\n",
    "        \n",
    "        img_h = img_arr.shape[0]\n",
    "        img_w = img_arr.shape[1]\n",
    "        \n",
    "        def bbox_trans(_rect):\n",
    "            rect = [-1,-1,-1,-1]\n",
    "            \n",
    "            rect[0] = int(_rect[0]*600 / w)\n",
    "            rect[1] = int(_rect[1]*600 / w)\n",
    "            rect[2] = int(_rect[2]*1000 / h)\n",
    "            rect[3] = int(_rect[3]*1000 / h)\n",
    "        \n",
    "            return rect\n",
    "        \n",
    "        anchors = np.zeros(shape=[61,36,9,4] , dtype=float)\n",
    "        \n",
    "        feature_map_height = 61\n",
    "        feature_map_width = 36\n",
    "        \n",
    "        scales = [128 , 256 , 512]\n",
    "        ratios = [[1,2] , [1,1] , [2,1]] #用scale除以即可 [height_ratio width_ratio]\n",
    "        \n",
    "        #x_0 y_0 为 feature map中的坐标\n",
    "        for x_0 in range(61): #height\n",
    "            for y_0 in range(36): #width\n",
    "                #x_0_coord y_0_coord 为原图中的坐标（中点坐标）\n",
    "                x_0_coord = x_0 * 16\n",
    "                y_0_coord = y_0 * 16\n",
    "                \n",
    "                for scale_idx , scale in enumerate(scales):\n",
    "                    for ratio_idx , ratio in enumerate(ratios):\n",
    "                        \n",
    "                        scale_height = int(scale / ratio[0])\n",
    "                        scale_width = int(scale / ratio[1])\n",
    "                    \n",
    "                        x_1_coord = int(x_0_coord - scale_width/2)\n",
    "                        y_1_coord = int(y_0_coord - scale_height/2)\n",
    "                        #跨越边界的anchor 进行截断\n",
    "                        if x_1_coord < 0:\n",
    "                            x_1_coord = 0\n",
    "                            \n",
    "                        if y_1_coord < 0:\n",
    "                            y_1_coord = 0\n",
    "\n",
    "                        x_2_coord = int(x_0_coord + scale_width/2)\n",
    "                        y_2_coord = int(y_0_coord + scale_height/2)\n",
    "\n",
    "                        if x_2_coord > 600:\n",
    "                            x_2_coord = 600\n",
    "                            \n",
    "                        if y_2_coord > 1000:\n",
    "                            y_2_coord = 1000\n",
    "                        \n",
    "                        anchors[x_0 , y_0 , scale_idx*3+ratio_idx] = [x_1_coord , x_2_coord , y_1_coord , y_2_coord]\n",
    "\n",
    "        return np.array(anchors)\n",
    "    \n",
    "    def load_test(self , img_path_name):\n",
    "        img_arr = cv2.imread(img_path_name)\n",
    "        \n",
    "        anchors = self.get_test_proposal(img_arr)\n",
    "                \n",
    "        img_arr = cv2.resize(img_arr , (600 , 1000))\n",
    "        img_arr = img_arr / 127.5 - 1.0\n",
    "        \n",
    "        return np.expand_dims(img_arr , axis=0) , anchors\n",
    "\n",
    "# class Img_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "    \n",
    "    def get_batch(self):\n",
    "        path = np.random.choice(self.img_file_names_train)\n",
    "        \n",
    "        x , anchors = self.img_generator.load(path)\n",
    "        \n",
    "        return x , anchors\n",
    "    \n",
    "    def get_batch_test(self , path):\n",
    "        '''\n",
    "        返回图片的真实img_arr 未resize 未归一化\n",
    "        注意cv2打开图片通道为BGR\n",
    "        '''\n",
    "        if not path:\n",
    "            #未指定path 从测试目录中随机选一张图片测试\n",
    "            path = np.random.choice(self.img_file_names_test)\n",
    "        \n",
    "        '''resize & norm/anchors/原图 '''\n",
    "        x , anchors = self.img_generator.load_test(path)\n",
    "        \n",
    "        return x , anchors\n",
    "    \n",
    "    \n",
    "    def target2coord(self , bbox_pred , img_arr , anchors):\n",
    "        img_height = img_arr.shape[0]\n",
    "        img_width = img_arr.shape[1]\n",
    "        \n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        def ot(target):\n",
    "            x_c = target[0]\n",
    "            y_c = target[1]\n",
    "            w = target[2]\n",
    "            h = target[3]\n",
    "            \n",
    "            x1 = 0.5*(2*x_c-w)\n",
    "            y1 = 0.5*(2*y_c-h)\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            \n",
    "            x1=int(round(x1))\n",
    "            y1=int(round(y1))\n",
    "            x2=int(round(x2))\n",
    "            y2=int(round(y2))\n",
    "            \n",
    "            if x1<0:\n",
    "                x1 = 0\n",
    "            if x2>img_width:\n",
    "                x2 = img_width\n",
    "            if y1<0:\n",
    "                y1 = 0\n",
    "            if y2>img_height:\n",
    "                y2 = img_height\n",
    "                            \n",
    "            return [x1 , x2 , y1 , y2]\n",
    "        \n",
    "        def target2rect(target_hat , P_box):\n",
    "            t_x = target_hat[0]\n",
    "            t_y = target_hat[1]\n",
    "            t_w = target_hat[2]\n",
    "            t_h = target_hat[3]\n",
    "            \n",
    "            P_x , P_y , P_w , P_h = to(P_box) #将P框转换为 中点坐标 宽 高 形式\n",
    "            \n",
    "            G_x_hat = P_w*t_x+P_x\n",
    "            G_y_hat = P_h*t_y+P_y\n",
    "            G_w_hat = P_w*np.exp(t_w)\n",
    "            G_h_hat = P_h*np.exp(t_h)\n",
    "            \n",
    "            return ot([G_x_hat , G_y_hat , G_w_hat , G_h_hat]) #ot还需要转化为(x1,x2,y1,y2)形式\n",
    "        \n",
    "        bbox_coord_pred = np.zeros(shape=[61,36,9,4] , dtype=float)\n",
    "        \n",
    "        for w in range(61):\n",
    "            for h in range(36):\n",
    "                for anchor_idx in range(9):\n",
    "                    bbox_coord_pred[w,h,anchor_idx] = target2rect(bbox_pred[w,h,anchor_idx] , anchors[w,h,anchor_idx])\n",
    "                \n",
    "        return bbox_coord_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet_model_RPN(object):\n",
    "    '''\n",
    "    构建RPN\n",
    "    替代selective search算法\n",
    "    这个网络输出proposals\n",
    "    并入FRCN中\n",
    "    '''\n",
    "    def __init__(self , is_training=True):\n",
    "        '''\n",
    "        x:[batch 1000 600 channel] #or batch 600 1000 channel\n",
    "        anchors:2 class score  4 rois coord 规定2 class score 第0位表示背景 第1位表示前景 (一个基本元素)\n",
    "        '''\n",
    "        self.x = tf.placeholder(tf.float32 , shape=[1 , 1000 , 600 , 3])\n",
    "        self.anchors = tf.placeholder(tf.float32 , shape=[19764 , 2 + 4 + 1])\n",
    "                \n",
    "        self.load_parameter()\n",
    "    \n",
    "        self.build()\n",
    "        \n",
    "        if is_training:\n",
    "            self.loss_layer()\n",
    "    \n",
    "    def load_parameter(self , trainable = False):\n",
    "        '''\n",
    "        卷积结构不进行训练\n",
    "        '''\n",
    "        parameter = np.load('bvlc_alexnet.npy' , encoding='bytes').item()\n",
    "        \n",
    "        self.conv1_w = tf.Variable(parameter['conv1'][0] , trainable = trainable)\n",
    "        self.conv1_b = tf.Variable(parameter['conv1'][1] , trainable = trainable)\n",
    "        \n",
    "        self.conv2_w = tf.Variable(parameter['conv2'][0] , trainable = trainable)\n",
    "        self.conv2_b = tf.Variable(parameter['conv2'][1] , trainable = trainable)\n",
    "        \n",
    "        self.conv3_w = tf.Variable(parameter['conv3'][0] , trainable = trainable)\n",
    "        self.conv3_b = tf.Variable(parameter['conv3'][1] , trainable = trainable)\n",
    "        \n",
    "        self.conv4_w = tf.Variable(parameter['conv4'][0] , trainable = trainable)\n",
    "        self.conv4_b = tf.Variable(parameter['conv4'][1] , trainable = trainable)\n",
    "        \n",
    "        self.conv5_w = tf.Variable(parameter['conv5'][0] , trainable = trainable)\n",
    "        self.conv5_b = tf.Variable(parameter['conv5'][1] , trainable = trainable)\n",
    "    \n",
    "    def group_conv(self , x , kernel, strides, padding='SAME'):\n",
    "        x_splits = tf.split(x , num_or_size_splits=2 , axis=3)\n",
    "        kernel_splits = tf.split(kernel , num_or_size_splits=2 , axis=3)\n",
    "        \n",
    "        conv_splits_1 = tf.nn.conv2d(x_splits[0] , kernel_splits[0] , strides , padding)\n",
    "        conv_splits_2 = tf.nn.conv2d(x_splits[1] , kernel_splits[1] , strides , padding)\n",
    "        \n",
    "        return tf.concat([conv_splits_1 , conv_splits_2] , axis=3)\n",
    "\n",
    "    def build(self):\n",
    "        conv1 = tf.nn.conv2d(self.x , self.conv1_w , strides=[1,4,4,1] , padding='SAME')\n",
    "        conv1 = tf.nn.bias_add(conv1 , self.conv1_b)\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        lrn1 = tf.nn.local_response_normalization(conv1 , depth_radius=5 , alpha=0.0001 , beta=0.75 , bias=1.0)\n",
    "        pool1 = tf.nn.max_pool(lrn1 , ksize=(1,3,3,1) , strides=(1,2,2,1) , padding='VALID')\n",
    "        \n",
    "        conv2 = self.group_conv(pool1 , self.conv2_w , strides=[1,1,1,1] , padding='SAME')\n",
    "        conv2 = tf.nn.bias_add(conv2 , self.conv2_b)\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        lrn2 = tf.nn.local_response_normalization(conv2 , depth_radius=5 , alpha=0.0001 , beta=0.75 , bias=1.0)\n",
    "        pool2 = tf.nn.max_pool(lrn2 , ksize=(1,3,3,1) , strides=(1,2,2,1) , padding='VALID')\n",
    "        \n",
    "        conv3 = tf.nn.conv2d(pool2 , self.conv3_w , strides=[1,1,1,1] , padding='SAME')\n",
    "        conv3 = tf.nn.bias_add(conv3 , self.conv3_b)\n",
    "        conv3 = tf.nn.relu(conv3)\n",
    "        \n",
    "        conv4 = self.group_conv(conv3 , self.conv4_w , strides=[1,1,1,1] , padding='SAME')\n",
    "        conv4 = tf.nn.bias_add(conv4 , self.conv4_b)\n",
    "        conv4 = tf.nn.relu(conv4)\n",
    "        \n",
    "        conv5 = self.group_conv(conv4 , self.conv5_w , strides=[1,1,1,1] , padding='SAME')\n",
    "        conv5 = tf.nn.bias_add(conv5 , self.conv5_b)\n",
    "        conv5 = tf.nn.relu(conv5)\n",
    "        \n",
    "        '''\n",
    "        上面为迁移alexnet(zf/vgg16)\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        RPN 增加的3*3 conv\n",
    "        '''  \n",
    "        conv6 = slim.conv2d(conv5 , num_outputs=conv5.get_shape().as_list()[-1] , kernel_size=[3 , 3] , stride=[1,1] , padding='SAME')\n",
    "        \n",
    "        '''\n",
    "        ZF channel 256-d\n",
    "        VGG16 channel 512-d\n",
    "        '''\n",
    "        '''\n",
    "        self.conv6's shape [1 61 36 256]\n",
    "        '''\n",
    "        # pool6 = slim.max_pool2d(conv6 , kernel_size=[3 , 3] , stride=[1 , 1] , padding='SAME')\n",
    "        '''\n",
    "        cls layer\n",
    "        '''\n",
    "        cls = slim.conv2d(conv6 , num_outputs=9*2 , kernel_size=[1,1] , stride=[1,1] , padding='VALID' , activation_fn=None) #[1 61 36 9*2]\n",
    "        cls = tf.reshape(cls , shape=(-1 , 2))  #[19764 2]\n",
    "        \n",
    "        self.cls = tf.nn.softmax(cls)\n",
    "        \n",
    "        '''\n",
    "        reg layer\n",
    "        '''\n",
    "        reg = slim.conv2d(conv6 , num_outputs=9*4 , kernel_size=[1,1] , stride=[1,1] , padding='VALID' , activation_fn=None) #[1 61 36 9*4]\n",
    "        reg = tf.reshape(reg , shape=(-1 , 4)) #[19764 4]\n",
    "        \n",
    "        self.reg = reg\n",
    "            \n",
    "    def loss_layer(self):\n",
    "        '''\n",
    "        self.anchors: [19764 2+4+1] [softmax_score coord label]\n",
    "        '''\n",
    "        '''\n",
    "        正负样本的不平衡 需要使用损失权重 loss_weight\n",
    "        因为正样本的数量少 较大权重值\n",
    "        负样本较小权重值\n",
    "        '''\n",
    "        #为-1的 不参与训练\n",
    "        \n",
    "        '''\n",
    "        分类损失\n",
    "        '''     \n",
    "        cls_true = self.anchors[: , :2] #whether object probs [19764 2]\n",
    "        bbox_true = self.anchors[: , 2:6] #rois coord [19764 4]\n",
    "        \n",
    "        mask_cls = tf.tile( tf.cast( tf.not_equal( tf.reshape(cls_true[: , 0] , shape=[-1,1]) , -1*np.ones(shape=[cls_true.shape[0] , 1])) , dtype=tf.float32) , multiples=[1,2])\n",
    "        \n",
    "        cross_entropy = - tf.reduce_sum( cls_true * tf.log(self.cls) * mask_cls , axis=1)\n",
    "        cls_loss = tf.reduce_mean(cross_entropy)\n",
    "                \n",
    "        '''\n",
    "        回归损失\n",
    "        '''\n",
    "        #回归损失中 标记为-1 和 背景 均不参与训练\n",
    "        mask_back = tf.tile( tf.reshape( cls_true[: , 1] , shape=[-1 , 1] ) , multiples=[1 , 4]) #重复4次 是否为前景\n",
    "        mask_box  = tf.tile( tf.cast( tf.not_equal( tf.reshape(cls_true[: , 0] , shape=[-1,1]) , -1*np.ones(shape=[cls_true.shape[0] , 1])) , dtype=tf.float32) , multiples=[1,4])\n",
    "        \n",
    "        reg_loss = tf.reduce_sum( tf.square( mask_back * mask_box * (bbox_true - self.reg) ) )\n",
    "        \n",
    "        # reg_loss = tf.div(reg_loss , tf.reduce_sum(cls_true[: , 1]) ) #计算平均损失\n",
    "        \n",
    "        self.RPN_loss = cls_loss + reg_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RPN(object):    \n",
    "    def __init__(self , is_training = True):      \n",
    "        self.dataset = Dataset()\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.filewriter_path = 'save/RPN/logs' #模型可视化\n",
    "        self.checkpoint_path = 'save/RPN/model/' #模型持久化\n",
    "                                        \n",
    "        self.model = AlexNet_model_RPN(is_training)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver(max_to_keep=2) #max_to_keep 最大保存5次模型  之后继续保存则会覆盖前面的模型\n",
    "\n",
    "        if is_training:\n",
    "            '''训练参数'''\n",
    "            self.epoch = 100000\n",
    "            \n",
    "            self.global_step = tf.Variable(initial_value=0 , trainable=False)\n",
    "            \n",
    "            self.learning_rate = tf.train.exponential_decay(learning_rate=0.00001 , global_step=self.global_step,\n",
    "                                                            decay_steps=900 , decay_rate=0.8 , staircase=True)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.model.RPN_loss , global_step=self.global_step)\n",
    "        \n",
    "            #引入滑动平均\n",
    "            self.ema = tf.train.ExponentialMovingAverage(decay=0.9) #滑动平均\n",
    "            self.average_op = self.ema.apply(tf.trainable_variables()) #给所有的可训练变量应用滑动平均\n",
    "            \n",
    "            with tf.control_dependencies([self.optimizer]):\n",
    "                self.train_op = tf.group(self.average_op)\n",
    "            \n",
    "            '''可视化'''\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            tf.summary.scalar('RPN_loss' , self.model.RPN_loss)\n",
    "            self.merged_summary = tf.summary.merge_all() #merge all summaries in the default graph\n",
    "            self.writer = tf.summary.FileWriter(self.filewriter_path , self.sess.graph) #可视化\n",
    "\n",
    "    def train(self):\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path))\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "       \n",
    "        for i in range(100):\n",
    "            x , anchors = self.dataset.get_batch()\n",
    "                        \n",
    "            self.sess.run(self.train_op , feed_dict={self.model.x : x , self.model.anchors : anchors} )\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                self.saver.save(self.sess , self.checkpoint_path + 'model.ckpt' , global_step = i)\n",
    "                \n",
    "                RPN_loss , summary = self.sess.run([self.model.RPN_loss , self.merged_summary] , feed_dict={self.model.x : x , self.model.anchors : anchors})\n",
    "                \n",
    "                self.writer.add_summary(summary , global_step = i)\n",
    "                \n",
    "                print(i , RPN_loss)\n",
    "        \n",
    "        self.writer.close() #event to disk and close the file\n",
    "\n",
    "    def predict(self , path=None , scores_threshold = 0.5 , nms_iou_threshold = 0.7 , top_N = 2000):\n",
    "        '''返回的坐标是在(1000 600)坐标系中'''\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path) )\n",
    "            \n",
    "            return self._predict(path , scores_threshold , nms_iou_threshold)\n",
    "            \n",
    "        else:\n",
    "            print('no model!!!')\n",
    "            return \n",
    "    \n",
    "    def _predict(self , path , scores_threshold , nms_iou_threshold , top_N):\n",
    "        '''返回的坐标是在(1000 600)坐标系中'''\n",
    "        x , anchors = self.dataset.get_batch_test(path)\n",
    "                   #bbox_pred\n",
    "        cls_pred , reg_pred = self.sess.run([self.model.cls , self.model.reg] , feed_dict={self.model.x : x})\n",
    "        \n",
    "        cls_pred = np.reshape(cls_pred , newshape=[61 , 36 , 9 , 2])\n",
    "        reg_pred = np.reshape(reg_pred , newshape=[61 , 36 , 9 , 4])\n",
    "        \n",
    "        '''转换为原始图片中的坐标'''\n",
    "        '''\n",
    "        超出边界的进行截断\n",
    "        '''\n",
    "        bbox_coord_pred = self.dataset.target2coord(reg_pred , x[0] , anchors)\n",
    "                \n",
    "        scores_pred_f = [] #符合条件的概率值\n",
    "        bbox_coord_pred_f = [] #符合条件的框子坐标\n",
    "        \n",
    "        for w in range(61):\n",
    "            for h in range(36):\n",
    "                for anchor_idx in range(9):\n",
    "                    if cls_pred[w,h,anchor_idx][0] < cls_pred[w,h,anchor_idx][1] and cls_pred[w,h,anchor_idx][1] > scores_threshold:\n",
    "                        scores_pred_f.append(cls_pred[w,h,anchor_idx][1]) #保存 score\n",
    "                        \n",
    "                        bbox_coord_pred_f.append(bbox_coord_pred[w,h,anchor_idx]) #保存位置参数\n",
    "        \n",
    "        scores_pred_f = np.array(scores_pred_f)\n",
    "        bbox_coord_pred_f = np.array(bbox_coord_pred_f)\n",
    "        \n",
    "        #降序scores\n",
    "        sort_idx = np.argsort(- np.array(scores_pred_f) )\n",
    "        \n",
    "        scores_pred_f = scores_pred_f[sort_idx]\n",
    "        bbox_coord_pred_f = bbox_coord_pred_f[sort_idx]\n",
    "                \n",
    "        final_idx = self._nms(scores_pred_f , bbox_coord_pred_f , nms_iou_threshold)\n",
    "                \n",
    "        bbox_coord_pred_f = bbox_coord_pred_f[final_idx]\n",
    "        \n",
    "        return bbox_coord_pred_f\n",
    "    \n",
    "        #返回 top-N 的proposals(根据scores)\n",
    "        #if len(bbox_coord_pred_f) <= top_N: #小于或等于top_N 全部返回即可\n",
    "        #    return bbox_coord_pred_f\n",
    "       \n",
    "        #scores_pred_f = scores_pred_f[final_idx]\n",
    "        #top_N_idx = np.argsort(-1*scores_pred_f)\n",
    "        #\n",
    "        #return bbox_coord_pred_f[top_N_idx]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _nms(self , probability_hat , rects_hat , nms_iou_threshold):\n",
    "        idx = []\n",
    "        \n",
    "        length = len(probability_hat)\n",
    "        lost_flag = [1]*length #标记丢弃的框 0表示丢弃\n",
    "        \n",
    "        max_score_idx = 0 #记录当前最大score的idx\n",
    "        \n",
    "        while max_score_idx < length:\n",
    "            max_score_rect = rects_hat[max_score_idx]\n",
    "            \n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1 and (self.img_generator.IoU( max_score_rect , rects_hat[i] ) > nms_iou_threshold): #大于阈值 丢弃\n",
    "                    lost_flag[i] = 0\n",
    "\n",
    "            max_score_idx_bak = max_score_idx #后续使用\n",
    "            \n",
    "            #让max_score_idx指向下一个没被丢弃的最大值\n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1:\n",
    "                    max_score_idx = i\n",
    "                    break\n",
    "            \n",
    "            #说明max_score_idx没有移动过 即后续的都被丢弃了 终止循环\n",
    "            if max_score_idx == max_score_idx_bak:\n",
    "                break\n",
    "        \n",
    "        for i in range(length):\n",
    "            if lost_flag[i] == 1:\n",
    "                idx.append(i)\n",
    "                \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpn = RPN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.20317003\n",
      "10 4.509024\n",
      "20 0.19229999\n",
      "30 0.20175572\n",
      "40 0.20087923\n",
      "50 0.18708783\n",
      "60 1.8425518\n",
      "70 3.2151296\n",
      "80 0.18926746\n",
      "90 0.18095013\n"
     ]
    }
   ],
   "source": [
    "rpn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpnn = RPN(is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=rpnn.predict(path='4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roi_coord(rect):\n",
    "    '''\n",
    "    由原图中的roi坐标向conv5的feature map映射\n",
    "    feature map中的坐标\n",
    "    ''' \n",
    "    rect[1:] = (rect[1:] - (11-1)//2 ) // 4\n",
    "    rect[1:] = (rect[1:] - (3-1)//2 ) // 2\n",
    "    rect[1:] = (rect[1:] - (3-1)//2 ) // 2\n",
    "    \n",
    "    '''-1修正'''\n",
    "    #rect[2] = rect[2] - 1\n",
    "    #rect[3] = rect[3] - 1\n",
    "    \n",
    "    #224*224 经过conv之后 变为13*13\n",
    "    return np.concatenate( (rect[0:1] , np.clip(rect[1:] , a_min=0 , a_max=12) ) , axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RPN_SS(object):\n",
    "    def __init__(self):\n",
    "        self.img_loader = Image()\n",
    "        self.rpn = RPN()\n",
    "\n",
    "    #计算bbox面积\n",
    "    def bbox_area(self , bbox):\n",
    "        w = bbox[1] - bbox[0]\n",
    "        h = bbox[3] - bbox[2]\n",
    "        \n",
    "        return w*h\n",
    "    \n",
    "    #计算交并比\n",
    "    def IoU(self , bbox_a , bbox_b):\n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            union_area = self.bbox_area(bbox_a) + self.bbox_area(bbox_b) - area_inter\n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    #ground truth coord and proposal coord计算bb回归使用的标签\n",
    "    def __to_t(self , G_box , P_box):\n",
    "        \n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        G_x , G_y , G_w , G_h = to(G_box)\n",
    "        P_x , P_y , P_w , P_h = to(P_box)\n",
    "        \n",
    "        t_x = (G_x-P_x)/P_w\n",
    "        t_y = (G_y-P_y)/P_h\n",
    "        t_w = np.log(G_w/P_w)\n",
    "        t_h = np.log(G_h/P_h)\n",
    "        \n",
    "        return t_x , t_y , t_w , t_h\n",
    "    \n",
    "    def clip(self , img_arr , img_path_name):\n",
    "        proposals = self.rpn.predict(img_path_name) #1000*600坐标系中\n",
    "                \n",
    "        '''\n",
    "        转换上面到img_arr同坐标系中坐标\n",
    "        '''\n",
    "        h = img_arr.shape[0]\n",
    "        w = img_arr.shape[1]\n",
    "        \n",
    "        def bbox_trans(_rect):\n",
    "            rect = [-1 , -1 , -1 , -1]\n",
    "            rect[0] = int(_rect[0]*w / 600)\n",
    "            rect[1] = int(_rect[1]*w / 600)\n",
    "            rect[2] = int(_rect[2]*h / 1000)\n",
    "            rect[3] = int(_rect[3]*h / 1000)\n",
    "        \n",
    "            return rect\n",
    "        \n",
    "        for i in range(len(proposals)):\n",
    "            proposals[i] = bbox_trans(proposals[i])\n",
    "        \n",
    "        return np.array(proposals)\n",
    "    \n",
    "    def get_train_proposal(self , img_arr , labels , ground_truth_coord , img_path_name):\n",
    "        #下面使用的img_arr必须是原始的图 没有resize 也没有归一化到-1 1\n",
    "        proposals_coord = self.clip(img_arr , img_path_name) #RPN产生的bbox\n",
    "        \n",
    "        h = img_arr.shape[0]\n",
    "        w = img_arr.shape[1]\n",
    "                \n",
    "        def bbox_trans_roi(_rect):\n",
    "            rect = [_rect[0] , -1 , -1 , -1 , -1]\n",
    "            rect[1] = int(_rect[1]*224 / w)\n",
    "            rect[2] = int(_rect[2]*224 / w)\n",
    "            rect[3] = int(_rect[3]*224 / h)\n",
    "            rect[4] = int(_rect[4]*224 / h)\n",
    "        \n",
    "            return np.array(rect)\n",
    "                        \n",
    "        rois = []\n",
    "        y = []\n",
    "                        \n",
    "        for j in range(len(proposals_coord)):\n",
    "            for i in range(len(ground_truth_coord)):\n",
    "            \n",
    "        #for i in range(len(ground_truth_coord)):\n",
    "            #for j in range(len(proposals_coord)):\n",
    "                \n",
    "                label = np.zeros(shape=CLASSES_NUM + 4 ) #one-hot + 4 coords #21+4 elements\n",
    "                \n",
    "                #第一个元素为0 因为一次一张图片 见tf.crop_and_resize函数\n",
    "                roi = [0 , proposals_coord[j][0] , proposals_coord[j][1] , proposals_coord[j][2] ,  proposals_coord[j][3]]\n",
    "                \n",
    "                roi = np.array(roi)\n",
    "                \n",
    "                roi = bbox_trans_roi(roi) #转换为resize之后的图中的坐标\n",
    "                \n",
    "                roi = roi_coord(roi) #向conv5 feature map中映射\n",
    "                \n",
    "                iou = self.IoU(ground_truth_coord[i] , proposals_coord[j])\n",
    "                if iou < IoU_THRESHOLD and iou >= 0.1 : #0.5\n",
    "                    #背景\n",
    "                    label[0] = 1\n",
    "                    \n",
    "                    #==============\n",
    "                    if np.random.random() > 0.8:\n",
    "                        '''\n",
    "                        概率性增加负样本\n",
    "                        '''\n",
    "                        rois.append(roi)\n",
    "                        y.append(label)\n",
    "                    #==============\n",
    "                                                            \n",
    "                elif iou >= 0.5 :\n",
    "                    #前景\n",
    "                    label[labels[i]] = 1\n",
    "                    \n",
    "                    target = self.__to_t(ground_truth_coord[i] , proposals_coord[j])\n",
    "                    \n",
    "                    label[CLASSES_NUM + 0] = target[0]\n",
    "                    label[CLASSES_NUM + 1] = target[1]\n",
    "                    label[CLASSES_NUM + 2] = target[2]\n",
    "                    label[CLASSES_NUM + 3] = target[3]\n",
    "                    \n",
    "                    rois.append(roi)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    #========\n",
    "                    '''\n",
    "                    增加正样本数量\n",
    "                    '''\n",
    "                    rois.append(roi)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    rois.append(roi)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    rois.append(roi)\n",
    "                    y.append(label)\n",
    "                    #========\n",
    "                    \n",
    "                    '''\n",
    "                    两种写法 效果一样 正样本相同 负样本有差异 \n",
    "                    '''\n",
    "                    break\n",
    "                \n",
    "                #else:\n",
    "                    #ios<0.1 情况\n",
    "                      \n",
    "        return np.array(rois) , np.array(y)\n",
    "        \n",
    "          \n",
    "    def load(self , img_path_name):\n",
    "        #图片数据 ground truth具体数据 ground truth对应label ground truth坐标信息 图片文件名\n",
    "        img_arr , _ , labels , ground_truth_coord , _ = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        rois , y = self.get_train_proposal(img_arr , labels , ground_truth_coord , img_path_name)\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (224 , 224))\n",
    "        img_arr = img_arr/127.5-1.0\n",
    "\n",
    "        #'''增加一维 batch_size维'''\n",
    "        return np.expand_dims(img_arr , axis=0) , rois , y\n",
    "    \n",
    "    \n",
    "    def get_test_proposal(self , img_arr):\n",
    "        '''\n",
    "        return:rois\n",
    "        proposals_coord\n",
    "        '''\n",
    "        proposals_coord = self.pr_generator.clip(img_arr)\n",
    "        \n",
    "        h = img_arr.shape[0]\n",
    "        w = img_arr.shape[1]\n",
    "        \n",
    "        def bbox_trans_roi(_rect):\n",
    "            '''0:idx'''\n",
    "            rect = [_rect[0] , -1 , -1 , -1 , -1]\n",
    "            rect[1] = int(_rect[1]*224 / w)\n",
    "            rect[2] = int(_rect[2]*224 / w)\n",
    "            rect[3] = int(_rect[3]*224 / h)\n",
    "            rect[4] = int(_rect[4]*224 / h)\n",
    "        \n",
    "            return rect\n",
    "        \n",
    "        rois = []\n",
    "        \n",
    "        for i in range(len(proposals_coord)):\n",
    "            roi = [0 , proposals_coord[i][0] , proposals_coord[i][1] , proposals_coord[i][2] , proposals_coord[i][3]]\n",
    "            \n",
    "            roi = np.array(roi)\n",
    "            \n",
    "            roi = bbox_trans_roi(roi) #转换到224*224坐标系中\n",
    "            \n",
    "            roi = roi_coord(roi) #向conv5 feature map中映射\n",
    "            \n",
    "            rois.append(roi)\n",
    "            \n",
    "        return rois , proposals_coord\n",
    "    \n",
    "    \n",
    "    def load_test(self , img_path_name):\n",
    "        img_arr = cv2.imread(img_path_name)\n",
    "        \n",
    "        rois , proposals_coord = self.get_test_proposal(img_arr)\n",
    "        \n",
    "        img_arr_resize = cv2.resize(img_arr , (224 , 224))\n",
    "        img_arr_resize_norm = img_arr_resize / 127.5 - 1.0\n",
    "        \n",
    "        return np.expand_dims(img_arr_resize_norm , axis=0) , rois , img_arr , proposals_coord\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#不需要修改\n",
    "class RPN_Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = RPN_SS()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "        \n",
    "    def get_batch(self):\n",
    "        path = np.random.choice(self.img_file_names_train)\n",
    "        \n",
    "        x , rois , y = self.img_generator.load(path)\n",
    "        \n",
    "        return x , rois , y\n",
    "    \n",
    "    def get_batch_test(self , path):\n",
    "        '''\n",
    "        返回图片的真实img_arr 未resize 未归一化\n",
    "        注意cv2打开图片通道为BGR\n",
    "        '''\n",
    "        if not path:\n",
    "            #未指定path 从测试目录中随机选一张图片测试\n",
    "            path = np.random.choice(self.img_file_names_test)\n",
    "        \n",
    "        img_arr_resize_norm , rois , img_arr , porposals_coord = self.img_generator.load_test(path)\n",
    "        \n",
    "        return img_arr_resize_norm , rois , img_arr , porposals_coord\n",
    "    \n",
    "    \n",
    "    def target2coord(self , bbox_pred , img_arr , proposals_coord):\n",
    "        img_height = img_arr.shape[0]\n",
    "        img_width = img_arr.shape[1]\n",
    "        \n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        def ot(target):\n",
    "            x_c = target[0]\n",
    "            y_c = target[1]\n",
    "            w = target[2]\n",
    "            h = target[3]\n",
    "            \n",
    "            x1 = 0.5*(2*x_c-w)\n",
    "            y1 = 0.5*(2*y_c-h)\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            \n",
    "            x1=int(round(x1))\n",
    "            y1=int(round(y1))\n",
    "            x2=int(round(x2))\n",
    "            y2=int(round(y2))\n",
    "            \n",
    "            if x1<0:\n",
    "                x1 = 0\n",
    "            if x2>img_width:\n",
    "                x2 = img_width\n",
    "            if y1<0:\n",
    "                y1 = 0\n",
    "            if y2>img_height:\n",
    "                y2 = img_height\n",
    "            \n",
    "            return [x1 , x2 , y1 , y2]\n",
    "        \n",
    "        def target2rect(target_hat , P_box):\n",
    "            t_x = target_hat[0]\n",
    "            t_y = target_hat[1]\n",
    "            t_w = target_hat[2]\n",
    "            t_h = target_hat[3]\n",
    "            \n",
    "            P_x , P_y , P_w , P_h = to(P_box) #将P框转换为 中点坐标 宽 高 形式\n",
    "            \n",
    "            G_x_hat = P_w*t_x+P_x\n",
    "            G_y_hat = P_h*t_y+P_y\n",
    "            G_w_hat = P_w*np.exp(t_w)\n",
    "            G_h_hat = P_h*np.exp(t_h)\n",
    "            \n",
    "            return ot([G_x_hat , G_y_hat , G_w_hat , G_h_hat]) #ot还需要转化为(x1,x2,y1,y2)形式\n",
    "        \n",
    "        bbox_coord_pred = []\n",
    "        \n",
    "        for i in range(len(bbox_pred)):\n",
    "            bbox_coord_pred.append( target2rect(bbox_pred[i] , proposals_coord[i]) )\n",
    "        \n",
    "        return bbox_coord_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roi_pooling(conv5 , rois , pool_height , pool_width):\n",
    "        '''\n",
    "        conv5:[batch height width channel]\n",
    "        roi-idx upper-left bottom-right\n",
    "        rois中的坐标是在feature map中的坐标\n",
    "        '''\n",
    "\n",
    "        conv5_height = 13\n",
    "        conv5_width = 13\n",
    "        \n",
    "        rois_ind = tf.cast(rois[: , 0] , tf.int32) #如果只有一张图片 则rois_ind都为0\n",
    "        \n",
    "        rois = tf.cast(rois , tf.float32)\n",
    "\n",
    "        rois_coord = rois[: , 1:] #[x1 x2 y1 y2]\n",
    "\n",
    "        normalization = tf.cast(tf.stack([ conv5_width , conv5_width , conv5_height , conv5_height ],axis=-1) , dtype=tf.float32)\n",
    "        rois_coord = tf.div(rois_coord , normalization)\n",
    "\n",
    "        rois_coord = tf.stack([rois_coord[: , 2] , rois_coord[: , 0] , rois_coord[: , 3] , rois_coord[: , 1] ] , axis=1)\n",
    "        #box_ind参数为图片的索引 对第几张图片进行crop and resize\n",
    "        #只有一张图片 则box_ind中全为0\n",
    "        rois_conv5_feature = tf.image.crop_and_resize(conv5 , boxes=rois_coord , box_ind=rois_ind , crop_size=[12 , 12] )\n",
    "\n",
    "        rois_pooling_feature = slim.max_pool2d(rois_conv5_feature , kernel_size=[2 , 2 ] , stride=[2 , 2 ] , padding='SAME')\n",
    "\n",
    "        return rois_pooling_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "#alexnet原始模型以及预训练参数导入\n",
    "class AlexNet_model(object):\n",
    "    def __init__(self , is_training=True):\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32 , shape=[None , 224 , 224 , 3])\n",
    "        self.rois = tf.placeholder(tf.int32 , shape=[None , 5])\n",
    "                     \n",
    "        self.load_parameter()\n",
    "        \n",
    "        self.build(is_training)\n",
    "        \n",
    "        if is_training:\n",
    "            self.y = tf.placeholder(tf.float32 , shape=[None , CLASSES_NUM + 4])\n",
    "            \n",
    "            self.loss_layer()\n",
    "            \n",
    "            \n",
    "    def group_conv(self , x , kernel , strides):\n",
    "        #2 GPUs\n",
    "        #原始alexnet配置\n",
    "        group_x = tf.split(x , num_or_size_splits=2 , axis=3)\n",
    "        group_kernel = tf.split(kernel , num_or_size_splits=2 , axis=3)\n",
    "\n",
    "        group_conv0 = tf.nn.conv2d(group_x[0] , group_kernel[0] , strides=strides , padding='SAME')\n",
    "        group_conv1 = tf.nn.conv2d(group_x[1] , group_kernel[1] , strides=strides , padding='SAME')\n",
    "\n",
    "        group_conv = tf.concat((group_conv0 , group_conv1) , axis=3)\n",
    "\n",
    "        return group_conv\n",
    "    \n",
    "    def load_parameter(self):\n",
    "        #=======\n",
    "        #加载预训练权重\n",
    "        #获取预训练参数\n",
    "        net_data = np.load('bvlc_alexnet.npy' , encoding='bytes').item() #不加encoding='bytes' 死机\n",
    "        \n",
    "        self.conv1w = tf.Variable(net_data[\"conv1\"][0] , trainable=False)\n",
    "        self.conv1b = tf.Variable(net_data[\"conv1\"][1] , trainable=False)\n",
    "\n",
    "        self.conv2w = tf.Variable(net_data[\"conv2\"][0] , trainable=False)\n",
    "        self.conv2b = tf.Variable(net_data[\"conv2\"][1] , trainable=False)\n",
    "\n",
    "        self.conv3w = tf.Variable(net_data[\"conv3\"][0] , trainable=False)\n",
    "        self.conv3b = tf.Variable(net_data[\"conv3\"][1] , trainable=False)\n",
    "\n",
    "        self.conv4w = tf.Variable(net_data[\"conv4\"][0] , trainable=False)\n",
    "        self.conv4b = tf.Variable(net_data[\"conv4\"][1] , trainable=False)\n",
    "\n",
    "        self.conv5w = tf.Variable(net_data[\"conv5\"][0] , trainable=False)\n",
    "        self.conv5b = tf.Variable(net_data[\"conv5\"][1] , trainable=False)\n",
    "    \n",
    "    \n",
    "    def build(self , is_training=True , keep_prob=0.5):\n",
    "        conv1 = tf.nn.conv2d(self.x , self.conv1w , strides=(1,4,4,1) , padding='SAME')\n",
    "        conv1 = tf.nn.bias_add(conv1 , self.conv1b)\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        lrn1 = tf.nn.local_response_normalization(conv1 , depth_radius=5 , alpha=0.0001 , beta=0.75 , bias=1.0)\n",
    "        maxpool1 = tf.nn.max_pool(lrn1 , ksize=(1,3,3,1) , strides=(1,2,2,1) , padding='VALID')\n",
    "\n",
    "        conv2 = self.group_conv(maxpool1 , self.conv2w , strides=(1,1,1,1))\n",
    "        conv2 = tf.nn.bias_add(conv2 , self.conv2b)\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        lrn2 = tf.nn.local_response_normalization(conv2 , depth_radius=5 , alpha=0.0001 , beta=0.75 , bias=1.0)\n",
    "        maxpool2 = tf.nn.max_pool(lrn2 , ksize=(1,3,3,1) , strides=(1,2,2,1) , padding='VALID')\n",
    "\n",
    "        conv3 = tf.nn.conv2d(maxpool2 , self.conv3w , strides=(1,1,1,1) , padding='SAME')\n",
    "        conv3 = tf.nn.bias_add(conv3 , self.conv3b)\n",
    "        conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "        conv4 = self.group_conv(conv3 , self.conv4w , strides=(1,1,1,1))\n",
    "        conv4 = tf.nn.bias_add(conv4 , self.conv4b)\n",
    "        conv4 = tf.nn.relu(conv4)\n",
    "\n",
    "        conv5 = self.group_conv(conv4 , self.conv5w , strides=(1,1,1,1))\n",
    "        conv5 = tf.nn.bias_add(conv5 , self.conv5b)\n",
    "        conv5 = tf.nn.relu(conv5)\n",
    "        \n",
    "        roi_pool5 = roi_pooling(conv5 , self.rois , pool_height = 6 , pool_width = 6)\n",
    "   \n",
    "        flatten = tf.layers.flatten(roi_pool5)\n",
    "        \n",
    "        fc6 = slim.fully_connected(flatten , num_outputs=1024)\n",
    "        fc6 = slim.dropout(fc6 , keep_prob=keep_prob , is_training=is_training)\n",
    "        \n",
    "        fc7 = slim.fully_connected(fc6 , num_outputs=1024)\n",
    "        fc7 = slim.dropout(fc7 , keep_prob=keep_prob , is_training=is_training)\n",
    "\n",
    "        self.cls_pred = slim.fully_connected(fc7 , num_outputs=CLASSES_NUM , activation_fn=tf.nn.softmax) #batch 21\n",
    "        self.bbox_pred = slim.fully_connected(fc7 , num_outputs=4 , activation_fn=None , weights_initializer=tf.initializers.truncated_normal(mean=0.0 , stddev=0.001))\n",
    "        \n",
    "        \n",
    "    def loss_layer(self):\n",
    "        cls_true = self.y[: , : CLASSES_NUM]\n",
    "        bbox_true = self.y[: , CLASSES_NUM :]\n",
    "        \n",
    "        cross_entropy = - tf.reduce_sum( cls_true * tf.log(self.cls_pred) )\n",
    "        cls_loss = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "        mask = tf.tile( tf.reshape(cls_true[ : , 0] , [-1 , 1]) , multiples=[1 , 4]) #1 和 4 分别是在相应的维度重复的次数 不能是0次 \n",
    "        bbox_loss = tf.reduce_mean( tf.reduce_sum( tf.square( (1-mask) * (bbox_true - self.bbox_pred) ) ) )\n",
    "    \n",
    "        self.total_loss = cls_loss + bbox_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def display(img_arr , labels , bbox , name):    \n",
    "    for i in range(len(labels)):\n",
    "\n",
    "        x1 = bbox[i][0]\n",
    "        x2 = bbox[i][1]\n",
    "        y1 = bbox[i][2]\n",
    "        y2 = bbox[i][3]\n",
    "\n",
    "        img_arr = cv2.rectangle(img_arr , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "\n",
    "        img_arr = cv2.putText(img_arr , labels[i] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "\n",
    "    #plt.imshow(meta_img) #图像查看\n",
    "\n",
    "    plt.imsave(arr=img_arr[: , : ,[2,1,0]] , fname = 'result/%s.jpg' % name) #保存图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "\n",
    "class FRCN(object):\n",
    "    '''\n",
    "    完整模型\n",
    "    '''\n",
    "    \n",
    "    def __init__(self , is_training = True):      \n",
    "        self.dataset = RPN_Dataset()\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.filewriter_path = 'save/FRCN/logs' #模型可视化\n",
    "        self.checkpoint_path = 'save/FRCN/model/' #模型持久化\n",
    "                                        \n",
    "        self.model = AlexNet_model(is_training)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        self.saver = tf.train.Saver(max_to_keep=2) #max_to_keep 最大保存5次模型  之后继续保存则会覆盖前面的模型\n",
    "        \n",
    "        if is_training:\n",
    "            '''训练参数'''\n",
    "            self.epoch = 100000\n",
    "            \n",
    "            self.global_step = tf.Variable(initial_value=0 , trainable=False)\n",
    "            \n",
    "            self.learning_rate = tf.train.exponential_decay(learning_rate=0.00001 , global_step=self.global_step,\n",
    "                                                            decay_steps=900 , decay_rate=0.8 , staircase=True)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.model.total_loss , global_step=self.global_step)\n",
    "        \n",
    "            #引入滑动平均\n",
    "            self.ema = tf.train.ExponentialMovingAverage(decay=0.9) #滑动平均\n",
    "            self.average_op = self.ema.apply(tf.trainable_variables()) #给所有的可训练变量应用滑动平均\n",
    "            \n",
    "            with tf.control_dependencies([self.optimizer]):\n",
    "                self.train_op = tf.group(self.average_op)\n",
    "            \n",
    "            '''可视化'''\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            tf.summary.scalar('total_loss' , self.model.total_loss)\n",
    "            self.merged_summary = tf.summary.merge_all() #merge all summaries in the default graph\n",
    "            self.writer = tf.summary.FileWriter(self.filewriter_path , self.sess.graph) #可视化\n",
    "            \n",
    "            \n",
    "    def train(self):\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path))\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for i in range(30):\n",
    "            x , rois , y = self.dataset.get_batch()\n",
    "                        \n",
    "            if len(rois) == 0:\n",
    "                continue\n",
    "            \n",
    "            feed_dict={self.model.x : x , self.model.rois : rois , self.model.y : y}\n",
    "            \n",
    "            self.sess.run(self.train_op , feed_dict=feed_dict)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                self.saver.save(self.sess , self.checkpoint_path + 'model.ckpt' , global_step = i)\n",
    "                \n",
    "                total_loss , summary = self.sess.run([self.model.total_loss , self.merged_summary] , feed_dict=feed_dict)\n",
    "                \n",
    "                self.writer.add_summary(summary , global_step = i)\n",
    "                \n",
    "                print(i , total_loss)\n",
    "            \n",
    "        self.writer.close() #event to disk and close the file\n",
    "\n",
    "    def predict(self , path=None , scores_threshold = 0.5 , nms_iou_threshold = 0.7):\n",
    "        if os.path.exists(self.checkpoint_path + 'checkpoint'):\n",
    "            self.saver.restore(self.sess , tf.train.latest_checkpoint(self.checkpoint_path) )\n",
    "            \n",
    "            self._predict(path , scores_threshold , nms_iou_threshold)\n",
    "            \n",
    "        else:\n",
    "            print('no model!!!')\n",
    "            return \n",
    "    \n",
    "    def _predict(self , path , scores_threshold , nms_iou_threshold):\n",
    "        #proposals_coord 为由rpn产生的rois在10000*600(h*w)坐标系中的坐标\n",
    "        x , rois , img_arr , proposals_coord = self.dataset.get_batch_test(path)\n",
    "        \n",
    "        feed_dict = {self.model.x : x , self.model.rois : rois}\n",
    "        cls_pred , bbox_pred = self.sess.run([self.model.cls_pred , self.model.bbox_pred] , feed_dict=feed_dict)\n",
    "        \n",
    "        #转换为原始图片中的坐标\n",
    "        bbox_coord_pred = self.dataset.target2coord(bbox_pred , img_arr , proposals_coord)\n",
    "        \n",
    "        '''\n",
    "        由target到原始坐标 在进行nms\n",
    "        '''\n",
    "        scores_pred_f = [] #符合条件的概率值\n",
    "        bbox_coord_pred_f = [] #符合条件的框子坐标\n",
    "        \n",
    "        labels_pred_f = [] #label名字\n",
    "        \n",
    "        for i in range(len(cls_pred)):\n",
    "            if np.argmax(cls_pred[i]) != 0 and (np.max(cls_pred[i]) > scores_threshold):\n",
    "                scores_pred_f.append(np.max(cls_pred[i]))\n",
    "                \n",
    "                bbox_coord_pred_f.append(bbox_coord_pred[i])\n",
    "                \n",
    "                labels_pred_f.append(LABEL2STR[np.argmax(cls_pred[i])])\n",
    "        \n",
    "        scores_pred_f = np.array(scores_pred_f)\n",
    "        bbox_coord_pred_f = np.array(bbox_coord_pred_f)\n",
    "        labels_pred_f = np.array(labels_pred_f)\n",
    "        \n",
    "        #降序scores\n",
    "        sort_idx = np.argsort(- np.array(scores_pred_f) )\n",
    "        \n",
    "        scores_pred_f = scores_pred_f[sort_idx]\n",
    "        bbox_coord_pred_f = bbox_coord_pred_f[sort_idx]\n",
    "        labels_pred_f = labels_pred_f[sort_idx]\n",
    "                \n",
    "        final_idx = self._nms(scores_pred_f , bbox_coord_pred_f , nms_iou_threshold)\n",
    "                \n",
    "        #scores_pred_f = scores_pred_f[final_idx] #用不上\n",
    "        bbox_coord_pred_f = bbox_coord_pred_f[final_idx]\n",
    "        labels_pred_f = labels_pred_f[final_idx]\n",
    "                \n",
    "        # 绘制并保存\n",
    "        display(img_arr , labels_pred_f , bbox_coord_pred_f , 'first')\n",
    "                \n",
    "        \n",
    "    def _nms(self , probability_hat , rects_hat , nms_iou_threshold):\n",
    "        idx = []\n",
    "        \n",
    "        length = len(probability_hat)\n",
    "        lost_flag = [1]*length #标记丢弃的框 0表示丢弃\n",
    "        \n",
    "        max_score_idx = 0 #记录当前最大score的idx\n",
    "        \n",
    "        while max_score_idx < length:\n",
    "            max_score_rect = rects_hat[max_score_idx]\n",
    "            \n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1 and self.img_generator.IoU( max_score_rect , rects_hat[i] ) > nms_iou_threshold: #大于阈值 丢弃\n",
    "                    lost_flag[i] = 0\n",
    "\n",
    "            max_score_idx_bak = max_score_idx #后续使用\n",
    "            \n",
    "            #让max_score_idx指向下一个没被丢弃的最大值\n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1:\n",
    "                    max_score_idx = i\n",
    "                    break\n",
    "            \n",
    "            #说明max_score_idx没有移动过 即后续的都被丢弃了 终止循环\n",
    "            if max_score_idx == max_score_idx_bak:\n",
    "                break\n",
    "        \n",
    "        for i in range(length):\n",
    "            if lost_flag[i] == 1:\n",
    "                idx.append(i)\n",
    "                \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frcn = FRCN(is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/RPN/model/model.ckpt-90\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [19764,7]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[19764,7], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: Reshape/_151 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_281_Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_1', defined at:\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-608-fe4845503517>\", line 1, in <module>\n    frcn = FRCN(is_training=True)\n  File \"<ipython-input-606-cb177f995579>\", line 9, in __init__\n    self.dataset = RPN_Dataset()\n  File \"<ipython-input-595-8c21b653dcec>\", line 4, in __init__\n    self.img_generator = RPN_SS()\n  File \"<ipython-input-594-08fb231bc7a3>\", line 4, in __init__\n    self.rpn = RPN()\n  File \"<ipython-input-466-03583547254c>\", line 9, in __init__\n    self.model = AlexNet_model_RPN(is_training)\n  File \"<ipython-input-459-76405fb525cf>\", line 14, in __init__\n    self.anchors = tf.placeholder(tf.float32 , shape=[19764 , 2 + 4 + 1])\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [19764,7]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[19764,7], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: Reshape/_151 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_281_Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [19764,7]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[19764,7], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: Reshape/_151 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_281_Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-609-8f37d2efcfe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrcn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-606-cb177f995579>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'model.ckpt'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[0mtotal_loss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerged_summary\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [19764,7]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[19764,7], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: Reshape/_151 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_281_Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_1', defined at:\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-608-fe4845503517>\", line 1, in <module>\n    frcn = FRCN(is_training=True)\n  File \"<ipython-input-606-cb177f995579>\", line 9, in __init__\n    self.dataset = RPN_Dataset()\n  File \"<ipython-input-595-8c21b653dcec>\", line 4, in __init__\n    self.img_generator = RPN_SS()\n  File \"<ipython-input-594-08fb231bc7a3>\", line 4, in __init__\n    self.rpn = RPN()\n  File \"<ipython-input-466-03583547254c>\", line 9, in __init__\n    self.model = AlexNet_model_RPN(is_training)\n  File \"<ipython-input-459-76405fb525cf>\", line 14, in __init__\n    self.anchors = tf.placeholder(tf.float32 , shape=[19764 , 2 + 4 + 1])\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [19764,7]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[19764,7], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[Node: Reshape/_151 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_281_Reshape\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "frcn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
