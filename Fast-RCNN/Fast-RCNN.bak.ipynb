{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import gc\n",
    "\n",
    "#解析使用\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import imageio\n",
    "from skimage import transform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC #类别分类使用\n",
    "from sklearn.linear_model import Ridge #bounding-box回归\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import selectivesearch as ss #候选框产生使用\n",
    "\n",
    "from ImageNet_classes import class_names #验证alexnet使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 1 #一次一张图像 切勿修改\n",
    "\n",
    "PROPOSAL_SIZE_POSITIVE = 32 #finetune 正样本\n",
    "PROPOSAL_SIZE_NEGATIVE = 96 #finetune 负样本\n",
    "PROPOSAL_SIZE = PROPOSAL_SIZE_POSITIVE+PROPOSAL_SIZE_NEGATIVE #128\n",
    "\n",
    "#应该是224 224 3\n",
    "#使用预训练的alexnet 58% 或者vgg16 66%\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "CHANNEL = 3\n",
    "\n",
    "IMG_SHAPE = (HEIGHT , WIDTH , CHANNEL)\n",
    "\n",
    "TRAIN_DATA_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TEST_DATA_PATH = '../../tensorflow2/dataset/VOC2012test/JPEGImages/'\n",
    "\n",
    "TRAIN_XML_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'\n",
    "TEST_XML_PATH = '../../tensorflow2/dataset/VOC2012test/Annotations/'\n",
    "\n",
    "OBJECT_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/ImageSets/Main/' #SVM需要使用的训练数据（正负样本） 训练20个svm\n",
    "\n",
    "#pascal VOC数据集目标数量\n",
    "#目标的数目 还有一个背景\n",
    "CLASSES_NUM = 20+1\n",
    "\n",
    "STR = [\n",
    "    'background', #label=0\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}\n",
    "\n",
    "STR2LABEL['none'] = 'none' #先不使用part部分 只进行naive目标检测\n",
    "\n",
    "#目标检测相关\n",
    "IoU_THRESHOLD = 0.5\n",
    "\n",
    "#SVM相关\n",
    "SVM_IoU_THRESHOLD = 0.3\n",
    "\n",
    "#NMS相关\n",
    "NMS_IoU_THRESHOLD = 0.3 #or ~0.5\n",
    "\n",
    "#bbox回归\n",
    "BBOX_REGRESS_IoU_THRESHOLD = 0.6\n",
    "\n",
    "#roi尺寸为6\n",
    "ROI_BINS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def spatial_pyramid_pool(conv5 , pyramid_bins): #[8 6 4]\n",
    "    '''\n",
    "    spp已经拉成向量\n",
    "    一共batch_size个向量\n",
    "    '''\n",
    "    batch_size = conv5.get_shape().as_list()[0] #batch_size\n",
    "    conv5_height = conv5.get_shape().as_list()[1] #feature map height\n",
    "    conv5_width = conv5.get_shape().as_list()[2] #feature map width\n",
    "    \n",
    "    #channel = conv5.get_shape().as_list()[3]\n",
    "\n",
    "    for i in range(len(pyramid_bins)):\n",
    "        pooling_height = np.ceil(conv5_height / pyramid_bins[i])\n",
    "        stride_height = np.ceil(conv5_height / pyramid_bins[i]) #floor\n",
    "        \n",
    "        pooling_width = np.ceil(conv5_width / pyramid_bins[i])\n",
    "        stride_width = np.ceil(conv5_width / pyramid_bins[i]) #floor\n",
    "        \n",
    "        padding_height = int(pyramid_bins[i] * pooling_height - conv5_height)\n",
    "        padding_width = int(pyramid_bins[i] * pooling_width - conv5_width)\n",
    "        \n",
    "        conv5_padding = tf.pad(conv5 , tf.constant([[0,0] , [0,padding_height] , [0,padding_width] ,[0,0]]))\n",
    "        \n",
    "        #max_pooling = tf.layers.max_pooling2d(conv5_padding , [pooling_height , pooling_width] , [stride_height , stride_width] , padding='same')\n",
    "        max_pooling = tf.nn.max_pool(conv5_padding , ksize=[1,pooling_height,pooling_width,1] , strides=[1,stride_height,stride_width,1] , padding='SAME')\n",
    "        \n",
    "        if i==0:\n",
    "            spp = tf.reshape(max_pooling , shape=(batch_size , -1))\n",
    "        else:\n",
    "            spp = tf.concat(values=[spp , tf.reshape(max_pooling , shape=(batch_size , -1)) ] , axis=-1)\n",
    "            \n",
    "    return spp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file_names_train = glob(TRAIN_XML_PATH + '*') #所有的xml文件 完整路径\n",
    "\n",
    "#从xml文件中读出图片相关的信息\n",
    "\n",
    "def xml_parse(xml_file):\n",
    "    '''\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "    xml文件中的shape格式为 (width height 3)\n",
    "    '''\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    \n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    shape = (width , height , channel)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        #name\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        name_box = name_list[0].childNodes[0].data\n",
    "\n",
    "        #bounding box points\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        x1_list = bndbox[0].getElementsByTagName('xmin')\n",
    "        x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "        y1_list = bndbox[0].getElementsByTagName('ymin')\n",
    "        y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "        x2_list = bndbox[0].getElementsByTagName('xmax')\n",
    "        x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "        y2_list = bndbox[0].getElementsByTagName('ymax')\n",
    "        y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "        crop_box = [x1,x2,y1,y2]\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    #shape:[width height channel]\n",
    "    #crop_box:[x1 x2 y1 y2]\n",
    "    return filename , shape , name_boxes , crop_boxes\n",
    "\n",
    "#xml_parse(xml_file_names_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2008_000281.jpg',\n",
       " (500, 455, 3),\n",
       " ['car', 'car', 'person'],\n",
       " [[106, 186, 377, 419], [194, 283, 396, 444], [413, 429, 399, 444]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_parse(xml_file_names_train[897])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image(object):\n",
    "    '''\n",
    "    图片的真实信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH+'*') #训练全路径信息\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        '''\n",
    "        如果传入 传入完整路径信息\n",
    "        return img_arr , ground_truth_data , labels , crop_boxes , img_path_name[-15:-4]\n",
    "        img_arr的shape为 (height width 3) 与xml文件中区分\n",
    "        '''\n",
    "        if not img_path_name:\n",
    "            #没有指定文件名\n",
    "            img_path_name = np.random.choice(self.img_file_names_train) #随机选择一张图片\n",
    "            #img_path_idx = np.random.randint(0 , high = len(self.img_file_names_train)) #随机索引\n",
    "        \n",
    "        #else\n",
    "            #svm和bndbox回归时使用 需要指定图片的路径信息\n",
    "            #完整路径信息\n",
    "        \n",
    "        #img_arr = imageio.imread(img_name) #使用此函数打开 导致迁移失败 RGB height*width*channel\n",
    "        img_arr = cv2.imread(img_path_name) #BGR height*width*chanel\n",
    "        \n",
    "        xml_file_name = TRAIN_XML_PATH + img_path_name[-15:-4] +  '.xml'\n",
    "        \n",
    "        _ , _ , name_boxes , crop_boxes = xml_parse(xml_file_name)\n",
    "        \n",
    "        ground_truth_data = [] #存储bndbox的图像 数据信息\n",
    "        labels = [] #存储与bndbox对应的 label信息\n",
    "\n",
    "        for i in range(len(crop_boxes)): #多个object\n",
    "            x1 = crop_boxes[i][0]\n",
    "            x2 = crop_boxes[i][1]\n",
    "            y1 = crop_boxes[i][2]\n",
    "            y2 = crop_boxes[i][3]\n",
    "            \n",
    "            ground_truth_data.append(img_arr[y1:y2 , x1:x2 , :])\n",
    "            \n",
    "            labels.append(STR2LABEL.get(name_boxes[i] , 'none'))\n",
    "        \n",
    "        #图片数据 ground truth具体数据 bndbox对应label bndbox坐标信息 图片文件名\n",
    "        \n",
    "        return img_arr , ground_truth_data , labels , crop_boxes , img_path_name[-15:-4]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#候选区域的产生\n",
    "class Clip(object):\n",
    "    '''\n",
    "    selectivesearch 产生与图片相关的信息 候选信息\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.size_threshold = 220 #ss算法产生过小的bbox略去\n",
    "\n",
    "    #单张图像裁剪函数 产生~2k的候选区域\n",
    "    #返回值：候选区域的位置坐标\n",
    "    def clip(self , img_arr):\n",
    "        '''\n",
    "        由ss算法对img_arr产生~2K proposals\n",
    "        '''\n",
    "        #传入图片张量\n",
    "        #关键函数\n",
    "        #return rects\n",
    "        _ , regions = ss.selective_search(img_arr , 500 , 0.9 , 50) #可以调整ss算法的参数 _为ss算法产生的labels\n",
    "        \n",
    "        rects = []\n",
    "        \n",
    "        no_repeat = set() #保证候选框不重复出现\n",
    "        \n",
    "        for r in regions:\n",
    "            if r['rect'] in no_repeat:\n",
    "                # 已经存在了\n",
    "                continue\n",
    "            \n",
    "            if r['size'] < self.size_threshold:\n",
    "                # 小于指定size\n",
    "                continue\n",
    "            \n",
    "            x , y , w , h = r['rect']\n",
    "            \n",
    "            if w == 0 or h == 0:\n",
    "                continue\n",
    "            \n",
    "            #img_arr的shape为 height width channel\n",
    "            d0 , d1 , d2 = img_arr[y:y+h , x:x+w , :].shape\n",
    "            \n",
    "            if d0 == 0 or d1 == 0 or d2 == 0:\n",
    "                continue\n",
    "                \n",
    "            no_repeat.add(r['rect'])\n",
    "            \n",
    "            rects.append([x , x+w , y , y+h]) #x1 x2 y1 y2形式\n",
    "        \n",
    "        return rects\n",
    "    \n",
    "    #def _preprocess(self , img_arr):\n",
    "    #    \n",
    "    #    #TODO\n",
    "    #    #对ss产生的候选区域进行预处理\n",
    "    #    #例如 resize\n",
    "    #    \n",
    "    #    img_arr = cv2.resize(img_arr , (HEIGHT , WIDTH))\n",
    "    #    \n",
    "    #    img_arr = img_arr/127.5-1.0\n",
    "    #    \n",
    "    #    return img_arr\n",
    "    #\n",
    "    ##返回数组表示候选区域的具体数据信息\n",
    "    #def clip_region(self , img_arr , rects = None):\n",
    "    #    '''\n",
    "    #    return rects_region 具体数据信息\n",
    "    #    rects_region的shape为(height width 3)\n",
    "    #    '''\n",
    "    #    if not rects:\n",
    "    #        rects = self.clip(img_arr)\n",
    "    #    \n",
    "    #    rects_region = []\n",
    "    #    \n",
    "    #    for x1 , x2 , y1 , y2 in rects:\n",
    "    #        rects_region.append( self._preprocess(img_arr[y1:y2 , x1:x2 , :]) ) #正确的切片格式\n",
    "    #        \n",
    "    #        #预处理函数可以进行数据增强 故换为+\n",
    "    #        #rects_region += ( self._preprocess(img_arr[y1:y2 , x1:x2 , :]) )\n",
    "    #\n",
    "    #    return rects_region\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def roi_coord(rect):\n",
    "    '''\n",
    "    由原图中的roi坐标向conv5的feature map映射\n",
    "    feature map中的坐标\n",
    "    '''    \n",
    "    rect[1:] = (rect[1:] - (11-1)//2 ) // 4\n",
    "    rect[1:] = (rect[1:] - (3-1)//2 ) // 2\n",
    "    rect[1:] = (rect[1:] - (3-1)//2 ) // 2\n",
    "    \n",
    "    '''-1修正'''\n",
    "    #rect[2] = rect[2] - 1\n",
    "    #rect[3] = rect[3] - 1\n",
    "    \n",
    "    #224*224 经过conv之后 变为13*13\n",
    "    return np.concatenate( (rect[0:1] , np.clip(rect[1:] , a_min=0 , a_max=12) ) , axis=0)\n",
    "\n",
    "class Img_generator(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.pr_generator = Clip()\n",
    "        self.img_loader = Image()\n",
    "\n",
    "    #计算bbox面积\n",
    "    def bbox_area(self , bbox):\n",
    "        w = bbox[1] - bbox[0]\n",
    "        h = bbox[3] - bbox[2]\n",
    "        \n",
    "        return w*h\n",
    "    \n",
    "    #计算交并比\n",
    "    def IoU(self , bbox_a , bbox_b):\n",
    "        xmin_a = bbox_a[0]\n",
    "        xmax_a = bbox_a[1]\n",
    "        ymin_a = bbox_a[2]\n",
    "        ymax_a = bbox_a[3]\n",
    "        \n",
    "        xmin_b = bbox_b[0]\n",
    "        xmax_b = bbox_b[1]\n",
    "        ymin_b = bbox_b[2]\n",
    "        ymax_b = bbox_b[3]\n",
    "        \n",
    "        if   xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "            flag = True\n",
    "        elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "            flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        \n",
    "        if flag:\n",
    "            x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "            y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "            \n",
    "            x_intersect_w = x_sorted_list[2] - x_sorted_list[1] #0 1 2 3\n",
    "            y_intersect_h = y_sorted_list[2] - y_sorted_list[1] #0 1 2 3\n",
    "            \n",
    "            area_inter = x_intersect_w * y_intersect_h #计算重合面积\n",
    "            \n",
    "            union_area = self.bbox_area(bbox_a) + self.bbox_area(bbox_b) - area_inter\n",
    "            \n",
    "            return area_inter/union_area\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    #ground truth coord and proposal coord计算bb回归使用的标签\n",
    "    def __to_t(self , G_box , P_box):\n",
    "        #print(G_box , P_box)\n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        G_x , G_y , G_w , G_h = to(G_box)\n",
    "        P_x , P_y , P_w , P_h = to(P_box)\n",
    "        \n",
    "        t_x = (G_x-P_x)/P_w\n",
    "        t_y = (G_y-P_y)/P_h\n",
    "        t_w = np.log(G_w/P_w)\n",
    "        t_h = np.log(G_h/P_h)\n",
    "        \n",
    "        return t_x , t_y , t_w , t_h\n",
    "    \n",
    "    def get_train_proposal(self , img_arr , labels , ground_truth_coord):\n",
    "        '''\n",
    "        labels与ground_truth_coord相对应\n",
    "        一张图片中所有可能的labels\n",
    "        '''\n",
    "        #下面使用的img_arr必须是原始的图 没有resize 也没有归一化到-1 1\n",
    "        proposals_coord = self.pr_generator.clip(img_arr) #ss算法产生的bbox\n",
    "        \n",
    "        '''\n",
    "        需要对ss算法产生的框子进行修正\n",
    "        因为对原图进行了resize ss算法产生的框子也要发生变化\n",
    "        \n",
    "        对ground truth也要进行修正 修正后才可以与proposals计算iou\n",
    "        '''\n",
    "        h = img_arr.shape[0]\n",
    "        w = img_arr.shape[1]\n",
    "        \n",
    "        trans_h = 224\n",
    "        trans_w = 224\n",
    "        \n",
    "        def bbox_trans(rect):\n",
    "            '''0:idx'''\n",
    "            rect[1] = int(rect[1]*trans_w / w)\n",
    "            rect[2] = int(rect[2]*trans_w / w)\n",
    "            rect[3] = int(rect[3]*trans_h / h)\n",
    "            rect[4] = int(rect[4]*trans_h / h)\n",
    "        \n",
    "            return rect\n",
    "        \n",
    "        #def bbox_retrans(rect):\n",
    "        #推理中使用 再转换为原图中的坐标\n",
    "        #    pass\n",
    "        \n",
    "        rois = []\n",
    "        y = []\n",
    "                        \n",
    "        for j in range(len(proposals_coord)):\n",
    "            for i in range(len(ground_truth_coord)):\n",
    "            \n",
    "        #for i in range(len(ground_truth_coord)):\n",
    "            #for j in range(len(proposals_coord)):\n",
    "                \n",
    "                label = np.zeros(shape=CLASSES_NUM + 4 ) #one-hot + 20 coords #21+80 elements\n",
    "                \n",
    "                '''proposal coord'''\n",
    "                roi = [0 , proposals_coord[j][0] , proposals_coord[j][1] , proposals_coord[j][2] ,  proposals_coord[j][3]]\n",
    "                \n",
    "                roi = np.array(roi)\n",
    "                \n",
    "                roi = bbox_trans(roi) #转换为resize之后的图中的坐标\n",
    "                \n",
    "                roi = roi_coord(roi) #向conv5 feature map中映射\n",
    "                \n",
    "                iou = self.IoU(ground_truth_coord[i] , proposals_coord[j])\n",
    "                if iou < IoU_THRESHOLD and iou >= 0.0 : #0.5\n",
    "                    #背景\n",
    "                    label[0] = 1\n",
    "                    \n",
    "                    rois.append(roi)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                                        \n",
    "                elif iou >= 0.5 :\n",
    "                    #前景\n",
    "                    label[labels[i]] = 1\n",
    "                    \n",
    "                    target = self.__to_t(ground_truth_coord[i] , proposals_coord[j])\n",
    "                    \n",
    "                    label[CLASSES_NUM + 0] = target[0]\n",
    "                    label[CLASSES_NUM + 1] = target[1]\n",
    "                    label[CLASSES_NUM + 2] = target[2]\n",
    "                    label[CLASSES_NUM + 3] = target[3]\n",
    "                    \n",
    "                    rois.append(roi)\n",
    "                    y.append(label)\n",
    "                    \n",
    "                    \n",
    "                    '''\n",
    "                    两种写法 效果一样 正样本相同 负样本有差异 \n",
    "                    '''\n",
    "                    break\n",
    "                      \n",
    "        return np.array(rois) , np.array(y)\n",
    "                \n",
    "    def load(self , img_path_name = None):\n",
    "        '''\n",
    "        img_path_name:绝对路径\n",
    "        '''\n",
    "        \n",
    "        #图片数据 ground truth具体数据 ground truth对应label ground truth坐标信息 图片文件名\n",
    "        img_arr , _ , labels , ground_truth_coord , _ = self.img_loader.load(img_path_name)\n",
    "        \n",
    "        rois , y = self.get_train_proposal(img_arr , labels , ground_truth_coord)\n",
    "        \n",
    "        img_arr = cv2.resize(img_arr , (224 , 224))\n",
    "        img_arr = img_arr/127.5-1.0\n",
    "\n",
    "        #'''增加一维 batch_size维'''\n",
    "        return img_arr , rois , y\n",
    "    \n",
    "    #============\n",
    "    #============\n",
    "    '''推理阶段使用'''\n",
    "    \n",
    "    #Alexnet_finetune demo 和 SVM_set中使用\n",
    "    def one_img_rect_region(self , path): \n",
    "        '''\n",
    "        返回指定的图像由ss算法产生的proposals信息\n",
    "        '''\n",
    "        img_arr = cv2.imread(path) #BGR height*width*chanel\n",
    "        \n",
    "        proposals = self.pr_generator.clip(img_arr) #proposal*4(x1,x2,y1,y2) selectivesearch算法产生\n",
    "        proposals_region = self.pr_generator.clip_region(img_arr , proposals) #proposal*224*224*3\n",
    "        \n",
    "        return img_arr , proposals , proposals_region\n",
    "    \n",
    "    #svm使用\n",
    "    def one_img_rect_region_label_svm(self , path , label):\n",
    "        '''\n",
    "        返回ground truth信息 给svm使用\n",
    "        一个类别训练一个svm使用 ovr形式\n",
    "        返回与参数label相同的数据供训练svm\n",
    "        '''\n",
    "        #proposals\n",
    "        img_arr , ground_truth_data , _labels , crop_boxes , _ = self.img_loader.load(path)\n",
    "        #rects rects_region\n",
    "        _ , proposals , proposals_region = self.one_img_rect_region(path)\n",
    "        \n",
    "        crop_boxes_x = [] #人工标定的框与参数中label对应的\n",
    "        \n",
    "        #训练一个类别的svm使用的数据集\n",
    "        proposals_region_x = [] #候选区域数据\n",
    "        labels = [] #标记\n",
    "        \n",
    "        #寻找与指定label相同的ground truth\n",
    "        for i in range(len(_labels)):\n",
    "            if _labels[i] == label:\n",
    "                crop_boxes_x.append(crop_boxes[i])\n",
    "        \n",
    "        #svm训练负样本\n",
    "        #与人工标定框iou小于0.3的为负样本\n",
    "        for i in range(len(crop_boxes_x)): #一幅图的与label相对应的人工标定bbox proposal\n",
    "            for j in range(len(proposals)): #一幅图的ss产生的bbox\n",
    "                \n",
    "                if self.IoU(crop_boxes_x[i] , proposals[j]) < SVM_IoU_THRESHOLD: #0.3\n",
    "                    labels.append(0)\n",
    "                \n",
    "                    proposals_region_x.append(proposals_region[j])\n",
    "        \n",
    "        #svm训练正样本\n",
    "        #与label对应的人工标定框的图像数据\n",
    "        crop_boxes_x_region = self.pr_generator.clip_region(img_arr , crop_boxes_x) #proposal*227*227*3\n",
    "        \n",
    "        for i in range(len(crop_boxes_x)):\n",
    "            labels.append(label)\n",
    "            \n",
    "            proposals_region_x.append(crop_boxes_x_region[i])\n",
    "                \n",
    "        return np.array(proposals_region_x) , labels\n",
    "    \n",
    "    #bbox回归使用\n",
    "    \n",
    "    '''\n",
    "    bbox回归使用\n",
    "    '''\n",
    "    def one_img_rect_region_label_bnd(self , path , label):\n",
    "        '''\n",
    "        bbox回归使用 每一个类别一个bbox回归器\n",
    "        '''\n",
    "        \n",
    "        img_arr , ground_truth_data , _labels , crop_boxes , _ = self.img_loader.load(path)\n",
    "        \n",
    "        _ , proposals , proposals_region = self.one_img_rect_region(path)\n",
    "        \n",
    "        crop_boxes_x = [] #人工标定的框\n",
    "        \n",
    "        proposals_region_x = [] #候选区域数据\n",
    "        targets = [] #bbox回归使用的训练数据中的y\n",
    "        \n",
    "        for i in range(len(_labels)):\n",
    "            if _labels[i] == label:\n",
    "                crop_boxes_x.append(crop_boxes[i])\n",
    "            \n",
    "        for i in range(len(crop_boxes_x)): #一幅图的人工标定bbox proposal\n",
    "            for j in range(len(proposals)): #一幅图的ss产生的bbox\n",
    "                \n",
    "                if self.IoU(crop_boxes_x[i] , proposals[j]) > BBOX_REGRESS_IoU_THRESHOLD: #0.6\n",
    "                    target = self.__to_t(crop_boxes_x[i] , proposals[j])\n",
    "                    \n",
    "                    targets.append(target)\n",
    "                    proposals_region_x.append(proposals_region[j])\n",
    "                \n",
    "        return np.array(proposals_region_x) , targets #区域具体数据和t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg=Img_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_arr , a , b = gg.load('../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000284.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 101)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c , d = gg.one_img_rect_region_label_bnd('../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000278.jpg' , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self):\n",
    "        self.img_generator = Img_generator()\n",
    "        \n",
    "        self.img_loader = Image()\n",
    "        \n",
    "        self.img_file_names_train = glob(TRAIN_DATA_PATH + '*')\n",
    "        self.img_file_names_test = glob(TEST_DATA_PATH + '*')\n",
    "        \n",
    "        self._train_data()\n",
    "        #self._test_data()\n",
    "    \n",
    "    def train_data(self):\n",
    "        return self.iterator_train\n",
    "    \n",
    "    def test_data(self):\n",
    "        return self.iterator_test\n",
    "        \n",
    "    def _train_data(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.img_file_names_train))\n",
    "        dataset = dataset.map(lambda filename : tuple( tf.py_func(self._map_train , [filename] , [tf.float32 , tf.int16 , tf.float32]) ) )\n",
    "        dataset = dataset.shuffle(buffer_size = 10).batch(1).repeat(1) #一次一张图片 重复1次\n",
    "        \n",
    "        self.iterator_train = dataset.make_initializable_iterator()\n",
    "        \n",
    "    def _test_data(self):\n",
    "        '''测试集没有y'''\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.img_file_names_test))\n",
    "        dataset = dataset.map(lambda filename : tuple( tf.py_func(self._map_test , [filename] , [tf.float32 , tf.int16]) ))\n",
    "        dataset = dataset.shuffle(buffer_size = 10).batch(1).repeat(1)\n",
    "        \n",
    "        self.iterator_test = dataset.make_initializable_iterator()\n",
    "            \n",
    "        #iterator = tf.data.Iterator.from_structure(dataset.output_types)\n",
    "        #init_op = iterator.make_initializer(dataset)\n",
    "        \n",
    "        #x , rois = iterator.get_next() #使用之前 对init_op进行sess.run\n",
    "        \n",
    "        #return x , rois , init_op\n",
    "    \n",
    "    def _map_train(self , filename):\n",
    "        '''\n",
    "        x:img_arr\n",
    "        rois:rois [idx coord coord]\n",
    "        y:one-hot label targets\n",
    "        '''\n",
    "        x , rois , y = self.img_generator.load(filename)\n",
    "        \n",
    "        return x , rois , y\n",
    "    \n",
    "    def _map_test(self , filename):\n",
    "        x , rois = self.img_generator.xxx(filename)\n",
    "        \n",
    "        return x , rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "#alexnet原始模型以及预训练参数导入\n",
    "\n",
    "def roi_pooling(conv5 , rois , pool_height , pool_width):\n",
    "    '''\n",
    "    conv5:[batch height width channel]\n",
    "    roi-idx upper-left bottom-right\n",
    "    rois中的坐标是在feature map中的坐标\n",
    "    '''\n",
    "    \n",
    "    #conv5_height = conv5.get_shape().as_list()[1]\n",
    "    #conv5_width = conv5.get_shape().as_list()[2]\n",
    "    \n",
    "    conv5_height = 13\n",
    "    conv5_width = 13\n",
    "    \n",
    "    rois_idx = tf.cast(rois[: , 0] , tf.int32)\n",
    "                    \n",
    "    rois = tf.cast(rois , tf.float32)\n",
    "        \n",
    "    rois_coord = rois[: , 1:] #[x1 x2 y1 y2]\n",
    "    \n",
    "    normalization = tf.cast(tf.stack([ conv5_width , conv5_width , conv5_height , conv5_height ],axis=-1) , dtype=tf.float32)\n",
    "    rois_coord = tf.div(rois_coord , normalization)\n",
    "    \n",
    "    rois_coord = tf.stack([rois_coord[: , 2] , rois_coord[: , 0] , rois_coord[: , 3] , rois_coord[: , 1] ] , axis=1)\n",
    "    \n",
    "    rois_conv5_feature = tf.image.crop_and_resize(conv5 , boxes=rois_coord , box_ind=rois_idx , crop_size=[12 , 12] )\n",
    "    \n",
    "    rois_pooling_feature = slim.max_pool2d(rois_conv5_feature , kernel_size=[2 , 2 ] , stride=[2 , 2 ] , padding='SAME')\n",
    "    \n",
    "    return rois_pooling_feature\n",
    "    \n",
    "    #def _roi_pooling(_rois):\n",
    "    #    for (i , roi) in enumerate(rois):\n",
    "    #        roi_new = roi_coord(roi[1:])\n",
    "\n",
    "    #        roi_new_height = roi_new[3] - roi_new[2]\n",
    "    #        roi_new_width = roi_new[1] - roi_new[0]\n",
    "\n",
    "    #        roi_new_pool_height = int( np.ceil(roi_new_height / pool_height) )\n",
    "    #        roi_new_pool_width = int( np.ceil(roi_new_width / pool_width) )\n",
    "\n",
    "    #        conv5_roi = tf.slice(conv5 , begin=[0 , roi_new[2] , roi_new[0] , 0] , size=[1 , roi_new[3] - roi_new[2] , roi_new[1] - roi_new[0] , -1])\n",
    "\n",
    "    #        print(conv5_roi.get_shape())\n",
    "\n",
    "    #        if i == 0:\n",
    "    #            '''第一次运行'''\n",
    "    #            pool5_roi = slim.max_pool2d(conv5_roi , kernel_size=[roi_new_pool_height , roi_new_pool_width] , stride=[roi_new_pool_height , roi_new_pool_width] , padding='SAME')\n",
    "    #        else:\n",
    "    #            pool5_roi = tf.concat(values=[pool5_roi , slim.max_pool2d(conv5_roi , kernel_size=[roi_new_pool_height , roi_new_pool_width] , stride=[roi_new_pool_height , roi_new_pool_width] , padding='SAME')] , axis=0)\n",
    "\n",
    "    #    return pool5_roi\n",
    "    '''tf.map_fn is a good function'''\n",
    "\n",
    "\n",
    "\n",
    "class AlexNet_model(object):\n",
    "    def __init__(self ,x , rois , y , is_training=True):\n",
    "        \n",
    "        self.x = x\n",
    "        self.rois = rois\n",
    "        self.y = y\n",
    "                        \n",
    "        self.load_paramter()\n",
    "        \n",
    "        self.cls_pred , self.bbox_pred = self.model(is_training)\n",
    "        \n",
    "        if is_training:\n",
    "            self.loss_layer(self.cls_pred , self.bbox_pred , self.y)\n",
    "            self.total_loss = tf.losses.get_total_loss(add_regularization_losses=False) #cls_loss bbox_loss\n",
    "        \n",
    "    def group_conv(self , x , kernel , strides):\n",
    "        #2 GPUs\n",
    "        #原始alexnet配置\n",
    "        group_x = tf.split(x , num_or_size_splits=2 , axis=3)\n",
    "        group_kernel = tf.split(kernel , num_or_size_splits=2 , axis=3)\n",
    "\n",
    "        group_conv0 = tf.nn.conv2d(group_x[0] , group_kernel[0] , strides=strides , padding='SAME')\n",
    "        group_conv1 = tf.nn.conv2d(group_x[1] , group_kernel[1] , strides=strides , padding='SAME')\n",
    "\n",
    "        group_conv = tf.concat((group_conv0 , group_conv1) , axis=3)\n",
    "\n",
    "        return group_conv\n",
    "    \n",
    "    def load_paramter(self):\n",
    "        #=======\n",
    "        #加载预训练权重\n",
    "        #获取预训练参数\n",
    "        net_data = np.load('bvlc_alexnet.npy' , encoding='bytes').item() #不加encoding='bytes' 死机\n",
    "        \n",
    "        self.conv1w = tf.Variable(net_data[\"conv1\"][0] , trainable=False)\n",
    "        self.conv1b = tf.Variable(net_data[\"conv1\"][1] , trainable=False)\n",
    "\n",
    "        self.conv2w = tf.Variable(net_data[\"conv2\"][0] , trainable=False)\n",
    "        self.conv2b = tf.Variable(net_data[\"conv2\"][1] , trainable=False)\n",
    "\n",
    "        self.conv3w = tf.Variable(net_data[\"conv3\"][0] , trainable=False)\n",
    "        self.conv3b = tf.Variable(net_data[\"conv3\"][1] , trainable=False)\n",
    "\n",
    "        self.conv4w = tf.Variable(net_data[\"conv4\"][0] , trainable=False)\n",
    "        self.conv4b = tf.Variable(net_data[\"conv4\"][1] , trainable=False)\n",
    "\n",
    "        self.conv5w = tf.Variable(net_data[\"conv5\"][0] , trainable=False)\n",
    "        self.conv5b = tf.Variable(net_data[\"conv5\"][1] , trainable=False)\n",
    "    \n",
    "    #构建alexnet模型\n",
    "    def model(self , is_training=True , keep_prob=0.5):\n",
    "        conv1 = tf.nn.conv2d(self.x , self.conv1w , strides=(1,4,4,1) , padding='SAME')\n",
    "        conv1 = tf.nn.bias_add(conv1 , self.conv1b)\n",
    "        conv1 = tf.nn.relu(conv1)\n",
    "        lrn1 = tf.nn.local_response_normalization(conv1 , depth_radius=5 , alpha=0.0001 , beta=0.75 , bias=1.0)\n",
    "        maxpool1 = tf.nn.max_pool(lrn1 , ksize=(1,3,3,1) , strides=(1,2,2,1) , padding='VALID')\n",
    "\n",
    "        conv2 = self.group_conv(maxpool1 , self.conv2w , strides=(1,1,1,1))\n",
    "        conv2 = tf.nn.bias_add(conv2 , self.conv2b)\n",
    "        conv2 = tf.nn.relu(conv2)\n",
    "        lrn2 = tf.nn.local_response_normalization(conv2 , depth_radius=5 , alpha=0.0001 , beta=0.75 , bias=1.0)\n",
    "        maxpool2 = tf.nn.max_pool(lrn2 , ksize=(1,3,3,1) , strides=(1,2,2,1) , padding='VALID')\n",
    "\n",
    "        conv3 = tf.nn.conv2d(maxpool2 , self.conv3w , strides=(1,1,1,1) , padding='SAME')\n",
    "        conv3 = tf.nn.bias_add(conv3 , self.conv3b)\n",
    "        conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "        conv4 = self.group_conv(conv3 , self.conv4w , strides=(1,1,1,1))\n",
    "        conv4 = tf.nn.bias_add(conv4 , self.conv4b)\n",
    "        conv4 = tf.nn.relu(conv4)\n",
    "\n",
    "        conv5 = self.group_conv(conv4 , self.conv5w , strides=(1,1,1,1))\n",
    "        conv5 = tf.nn.bias_add(conv5 , self.conv5b)\n",
    "        conv5 = tf.nn.relu(conv5)\n",
    "        \n",
    "        roi_pool5 = roi_pooling(conv5 , self.rois , pool_height = ROI_BINS , pool_width = ROI_BINS)\n",
    "        \n",
    "        flatten = slim.flatten(roi_pool5)    \n",
    "        \n",
    "        fc6 = slim.fully_connected(flatten , num_outputs=1024)\n",
    "        fc6 = slim.dropout(fc6 , keep_prob=keep_prob , is_training=is_training)\n",
    "        \n",
    "        fc7 = slim.fully_connected(fc6 , num_outputs=1024)\n",
    "        fc7 = slim.dropout(fc7 , keep_prob=keep_prob , is_training=is_training)\n",
    "\n",
    "        cls = slim.fully_connected(fc7 , num_outputs=CLASSES_NUM , activation_fn=tf.nn.softmax) #batch 21\n",
    "        '''batch 80 20个坐标信息'''\n",
    "        '''线性激活y=x'''\n",
    "        bbox = slim.fully_connected(fc7 , num_outputs=4 , activation_fn=None , weights_initializer=tf.initializers.truncated_normal(mean=0.0 , stddev=0.001))\n",
    "        \n",
    "        return cls , bbox\n",
    "        \n",
    "    def loss_layer(self , cls_pred , bbox_pred , labels):\n",
    "        cls_true = labels[: , : CLASSES_NUM]\n",
    "        bbox_true = labels[: , CLASSES_NUM :]\n",
    "        \n",
    "        cross_entropy = - tf.reduce_sum( cls_true * tf.log(cls_pred) )\n",
    "        cls_loss = tf.reduce_mean(cross_entropy)\n",
    "        \n",
    "        mask = tf.tile( tf.reshape(cls_true[ : , 0] , [-1 , 1]) , multiples=[1 , 4]) #先扩展第一列\n",
    "                \n",
    "        bbox_loss = tf.reduce_mean( tf.reduce_sum( tf.square( (1-mask) * (bbox_pred - bbox_true) ) ) )\n",
    "        \n",
    "        tf.losses.add_loss(cls_loss)\n",
    "        tf.losses.add_loss(bbox_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#refer:https://blog.csdn.net/two_vv/article/details/76769860\n",
    "\n",
    "class FRCN(object):\n",
    "    '''\n",
    "    完整模型\n",
    "    '''\n",
    "    \n",
    "    def __init__(self , is_training = True):      \n",
    "        self.dataset = Dataset()\n",
    "        \n",
    "        #self.filewriter_path = 'qp/image' #tensorboard\n",
    "        #self.checkpoint_path = 'qp/finetune_alexnet' #模型持久化\n",
    "        \n",
    "        if is_training:\n",
    "            '''构造训练集'''\n",
    "            self.iterator_train = self.dataset.train_data()\n",
    "            \n",
    "            self.x = self.iterator_train.get_next()[0]\n",
    "            self.rois = self.iterator_train.get_next()[1]\n",
    "            self.y = self.iterator_train.get_next()[2]\n",
    "        else:\n",
    "            '''构造测试集'''\n",
    "            self.iterator_test = self.dataset.test_data()\n",
    "            \n",
    "            self.x = self.iterator_test.get_next()[0]\n",
    "            self.rois = self.iterator_test.get_next()[1]\n",
    "            self.y = None\n",
    "                        \n",
    "        self.model = AlexNet_model(self.x , self.rois , self.y , is_training)\n",
    "\n",
    "        if is_training:\n",
    "            '''训练参数'''\n",
    "            self.epoch = 100000\n",
    "            \n",
    "            self.global_step = tf.Variable(initial_value=0 , trainable=False)\n",
    "            \n",
    "            self.learning_rate = tf.train.exponential_decay(learning_rate=0.00001 , global_step=self.global_step,\n",
    "                                                            decay_steps=900 , decay_rate=0.8 , staircase=True)\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.model.total_loss , global_step=self.global_step)\n",
    "        \n",
    "            '''引入滑动平均'''\n",
    "            self.ema = tf.train.ExponentialMovingAverage(decay=0.9) #滑动平均\n",
    "            self.average_op = self.ema.apply(tf.trainable_variables()) #给所有的可训练变量应用滑动平均\n",
    "            \n",
    "            with tf.control_dependencies([self.optimizer]):\n",
    "                self.train_op = tf.group(self.average_op)\n",
    "        \n",
    "        '''new'''\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "                \n",
    "        #self.merged_summary = tf.summary.merge_all()\n",
    "        #self.writer = tf.summary.FileWriter(logdir = self.filewriter_path ) #qp/image\n",
    "        \n",
    "        #self.saver = tf.train.Saver()\n",
    "\n",
    "    def train(self):\n",
    "        count = 0\n",
    "        \n",
    "        self.sess.run(self.iterator_train.initializer)\n",
    "        \n",
    "        for i in range(1):\n",
    "            print(i , end=',')\n",
    "            \n",
    "            try:\n",
    "                while True:                    \n",
    "                    _ , total_loss = self.sess.run([self.train_op , self.model.total_loss] )\n",
    "                    \n",
    "                    print(count , total_loss)\n",
    "                    count += 1\n",
    "                    \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                #重置迭代器\n",
    "                self.sess.run(self.iterator_train.initializer)\n",
    "                count = 0\n",
    "            \n",
    "    def predict(self , path):\n",
    "        self.sess.run(self.iterator_test.initializer)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def train(self):\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            if os.path.exists('qp/finetune_alexnet/checkpoint'):\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                self.saver.restore(sess , tf.train.latest_checkpoint('qp/finetune_alexnet/')) #读取模型\n",
    "               \n",
    "                #计算图放到tensorboard中\n",
    "                self.writer.add_graph(sess.graph)\n",
    "            \n",
    "                merge_summary = sess.run(self.merged_summary , {self.x:train_images_batch , self.y:train_labels_batch , self.keep_prob:1.0 })\n",
    "                self.writer.add_summary(merge_summary , i) #写入tenorboard\n",
    "\n",
    "                checkpoint_name = os.path.join(self.checkpoint_path , 'model_epoch.ckpt')\n",
    "                save_path = self.saver.save(sess , checkpoint_name)\n",
    "                \n",
    "        #self.writer.close()\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frcn = FRCN(is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT16, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: fully_connected_6/Softmax/_47 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_629_fully_connected_6/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-fe4845503517>\", line 1, in <module>\n    frcn = FRCN(is_training=True)\n  File \"<ipython-input-12-c8c039c02137>\", line 18, in __init__\n    self.x = self.iterator_train.get_next()[0]\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 370, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1495, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT16, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: fully_connected_6/Softmax/_47 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_629_fully_connected_6/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT16, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: fully_connected_6/Softmax/_47 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_629_fully_connected_6/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8f37d2efcfe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrcn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-ec71f82c0306>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT16, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: fully_connected_6/Softmax/_47 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_629_fully_connected_6/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-fe4845503517>\", line 1, in <module>\n    frcn = FRCN(is_training=True)\n  File \"<ipython-input-12-c8c039c02137>\", line 18, in __init__\n    self.x = self.iterator_train.get_next()[0]\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 370, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1495, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_FLOAT, DT_INT16, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: fully_connected_6/Softmax/_47 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_629_fully_connected_6/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "frcn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练svm与bounding回归使用\n",
    "class Object_load(object):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        object_path:训练svm的每一个类别使用\n",
    "        '''\n",
    "        self.object_path = [OBJECT_PATH+LABEL2STR[i]+'_train.txt' for i in range(1 , len(LABEL2STR))]\n",
    "        self.img_generator = Img_generator()\n",
    "    \n",
    "    \n",
    "    def load(self , label): #label为load的数据类型 1-20\n",
    "        '''\n",
    "        label先减1\n",
    "        object_path从0开始\n",
    "        '''\n",
    "        imgs_path = []\n",
    "        \n",
    "        for line in open(self.object_path[label-1]).readlines(): #需要减1 list下标从0开始\n",
    "            line = line.rstrip('\\n') #去掉末尾的\\n\n",
    "            \n",
    "            line_split = line.split(' ')\n",
    "            \n",
    "            if line_split[-1] == '1':\n",
    "                #正样本\n",
    "                imgs_path.append(TRAIN_DATA_PATH+line_split[0]+'.jpg')\n",
    "    \n",
    "        return imgs_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ol = Object_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000008.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000023.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000036.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000041.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000096.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000109.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000128.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000132.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000141.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000142.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000143.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000144.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000176.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000191.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000199.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000202.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000207.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000217.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000226.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000235.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000236.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000237.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000252.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000255.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000259.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000260.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000266.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000275.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000283.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000284.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000289.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000290.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000297.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000311.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000313.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000316.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000330.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000338.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000342.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000343.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000346.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000364.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000365.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000371.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000380.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000392.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000393.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000415.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000416.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000421.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000422.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000426.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000432.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000435.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000436.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000442.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000443.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000445.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000447.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000448.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000455.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000461.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000480.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000493.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000499.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000514.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000527.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000531.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000540.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000544.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000545.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000548.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000552.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000561.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000563.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000572.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000578.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000583.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000584.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000588.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000607.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000613.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000615.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000628.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000636.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000645.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000646.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000648.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000650.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000655.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000672.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000674.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000683.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000689.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000694.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000704.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000719.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000723.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000726.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000729.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000732.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000733.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000742.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000753.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000758.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000764.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000775.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000777.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000778.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000787.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000792.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000801.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000814.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000815.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000829.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000833.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000841.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000842.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000844.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000847.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000851.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000854.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000867.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000870.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000873.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000875.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000881.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000887.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000899.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000902.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000908.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000924.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000928.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000941.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000944.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000953.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000959.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000970.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000979.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000981.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000985.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_000987.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001021.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001022.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001023.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001026.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001031.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001035.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001036.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001039.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001048.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001052.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001054.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001057.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001073.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001081.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001083.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001104.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001106.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001112.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001115.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001119.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001134.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001147.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001158.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001171.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001182.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001188.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001189.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001190.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001196.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001202.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001206.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001215.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001219.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001223.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001230.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001235.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001245.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001263.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001272.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001294.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001299.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001302.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001307.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001310.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001312.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001325.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001329.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001346.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001351.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001358.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001359.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001373.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001375.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001382.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001383.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001385.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001390.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001402.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001408.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001413.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001419.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001420.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001431.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001434.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001440.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001444.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001454.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001455.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001461.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001462.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001464.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001467.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001482.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001488.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001493.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001501.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001510.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001523.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001525.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001533.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001538.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001550.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001563.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001566.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001576.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001577.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001582.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001591.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001609.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001615.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001617.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001620.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001631.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001643.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001645.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001652.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001661.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001666.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001670.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001673.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001690.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001692.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001699.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001706.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001709.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001710.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001724.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001729.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001735.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001737.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001746.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001751.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001758.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001761.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001775.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001789.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001791.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001796.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001797.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001811.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001832.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001834.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001837.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001842.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001845.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001852.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001854.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001856.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001860.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001881.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001882.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001888.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001894.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001903.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001911.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001929.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001937.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001947.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001955.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001957.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001967.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001970.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001977.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001980.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001982.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_001986.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002001.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002002.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002009.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002023.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002032.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002056.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002058.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002061.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002067.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002079.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002080.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002093.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002094.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002096.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002103.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002112.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002117.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002123.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002129.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002131.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002145.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002148.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002150.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002156.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002162.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002181.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002206.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002210.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002220.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002236.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002243.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002244.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002247.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002248.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002251.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002262.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002280.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002296.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002299.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002304.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002311.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002317.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002325.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002331.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002340.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002344.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002357.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002361.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002362.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002365.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002377.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002405.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002411.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002418.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002422.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002425.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002434.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002448.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002457.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002458.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002459.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002482.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002484.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002487.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002491.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002501.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002506.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002514.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002524.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002533.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002541.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002543.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002549.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002555.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002562.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002566.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002568.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002574.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002575.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002578.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002601.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002613.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002621.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002622.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002634.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002638.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002641.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002648.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002649.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002662.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002665.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002666.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002674.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002675.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002676.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002679.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002712.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002718.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002728.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002730.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002733.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002736.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002741.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002750.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002758.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002760.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002762.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002774.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002776.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002787.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002791.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002794.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002804.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002808.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002813.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002823.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002842.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002848.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002854.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002856.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002857.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002866.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002868.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002873.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002880.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002885.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002887.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002892.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002894.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002917.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002922.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002930.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002931.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002951.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002954.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002955.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002960.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002966.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002984.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002985.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002988.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_002997.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003013.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003015.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003017.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003018.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003025.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003039.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003043.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003061.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003065.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003075.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003079.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003081.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003093.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003094.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003099.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003120.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003122.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003127.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003128.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003134.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003140.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003143.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003146.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003151.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003154.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003157.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003182.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003191.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003203.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003208.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003209.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003224.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003231.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003242.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003248.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003251.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003265.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003266.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003277.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003283.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003287.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003288.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003290.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003304.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003311.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003313.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003318.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003329.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003335.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003338.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003342.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003393.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003406.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003409.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003414.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003417.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003418.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003429.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003437.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003448.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003452.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003463.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003469.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003478.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003488.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003496.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003507.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003510.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003515.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003521.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003522.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003523.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003533.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003534.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003544.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003560.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003578.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003587.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003596.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003608.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003611.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003617.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003626.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003629.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003635.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003653.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003667.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003674.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003675.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003677.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003682.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003685.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003689.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003697.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003706.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003707.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003712.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003732.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003748.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003761.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003762.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003764.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003769.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003773.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003779.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003781.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003791.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003796.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003802.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003815.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003819.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003842.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003847.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003854.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003864.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003866.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003871.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003882.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003883.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003888.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003891.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003892.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003908.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003914.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003916.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003920.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003925.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003947.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003956.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003966.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003967.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003978.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003984.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003985.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_003995.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004017.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004036.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004037.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004044.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004053.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004055.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004066.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004077.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004084.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004092.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004102.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004113.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004130.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004134.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004148.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004161.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004176.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004195.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004196.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004201.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004208.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004217.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004231.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004246.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004247.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004269.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004274.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004287.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004288.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004301.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004307.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004314.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004321.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004325.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004328.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004331.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004342.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004353.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004358.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004365.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004372.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004376.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004380.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004387.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004398.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004403.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004418.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004435.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004436.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004439.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004441.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004457.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004492.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004493.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004499.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004506.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004512.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004513.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004515.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004518.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004519.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004544.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004567.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004568.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004574.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004602.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004603.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004611.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004616.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004636.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004649.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004666.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004677.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004678.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004679.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004692.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004703.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004707.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004713.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004749.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004764.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004770.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004781.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004807.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004834.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004841.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004844.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004849.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004858.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004868.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004872.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004874.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004892.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004903.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004937.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004938.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004950.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004961.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004966.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004976.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004983.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_004991.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005000.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005016.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005033.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005040.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005045.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005055.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005066.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005090.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005094.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005101.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005133.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005146.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005150.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005168.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005171.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005172.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005178.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005201.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005213.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005218.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005231.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005236.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005271.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005294.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005295.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005297.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005315.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005324.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005336.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005365.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005395.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005408.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005412.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005414.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005429.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005484.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005494.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005500.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005519.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005527.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005549.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005558.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005567.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005570.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005600.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005609.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005610.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005616.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005625.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005641.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005650.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005682.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005698.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005707.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005737.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005742.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005758.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005761.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005791.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005794.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005832.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005850.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005855.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005867.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005902.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005921.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005923.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005937.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005972.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005976.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_005991.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006032.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006039.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006064.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006076.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006078.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006096.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006102.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006121.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006124.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006129.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006135.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006145.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006152.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006181.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006188.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006195.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006215.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006235.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006250.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006253.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006256.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006257.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006265.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006272.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006273.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006289.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006295.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006317.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006331.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006370.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006390.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006404.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006410.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006421.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006433.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006448.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006491.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006496.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006497.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006549.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006567.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006570.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006610.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006613.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006625.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006650.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006663.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006692.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006705.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006730.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006733.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006750.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006807.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006818.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006820.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006834.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006847.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006857.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006864.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006872.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006879.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006881.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006933.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006953.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006960.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_006969.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007038.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007043.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007058.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007061.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007090.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007097.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007101.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007129.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007138.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007146.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007147.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007168.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007169.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007185.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007218.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007223.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007237.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007242.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007254.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007280.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007281.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007286.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007291.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007325.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007356.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007375.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007410.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007421.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007443.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007470.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007485.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007509.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007510.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007524.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007537.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007556.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007565.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007576.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007584.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007593.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007625.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007646.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007648.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007653.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007660.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007665.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007675.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007682.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007692.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007696.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007701.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007710.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007717.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007742.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007746.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007759.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007761.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007770.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007789.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007833.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007837.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007843.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007852.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007861.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007864.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007882.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007895.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007904.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007913.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007918.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007928.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007950.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007962.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_007990.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008021.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008034.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008058.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008064.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008072.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008083.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008095.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008097.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008098.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008112.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008116.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008122.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008147.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008154.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008162.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008184.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008212.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008218.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008229.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008237.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008262.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008266.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008275.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008288.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008315.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008319.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008325.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008343.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008364.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008366.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008368.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008382.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008391.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008403.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008410.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008416.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008431.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008440.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008479.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008487.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008511.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008517.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008522.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008526.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008528.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008530.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008547.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008549.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008550.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008567.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008572.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008579.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008591.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008593.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008600.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008618.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008624.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008637.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008641.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008649.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008671.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008691.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008697.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008701.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008717.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008725.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008744.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008745.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2008_008757.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000010.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000021.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000054.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000056.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000058.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000059.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000085.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000119.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000128.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000132.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000140.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000141.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000145.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000164.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000168.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000197.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000223.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000237.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000239.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000248.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000253.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000277.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000280.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000290.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000322.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000340.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000343.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000375.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000379.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000405.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000408.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000449.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000463.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000464.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000474.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000476.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000505.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000522.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000525.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000529.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000539.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000544.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000546.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000547.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000565.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000575.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000577.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000595.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000604.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000617.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000642.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000653.jpg',\n",
       " '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/2009_000686.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol.load(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#20个SVM分类\n",
    "class SVM_set(object):\n",
    "    def __init__(self):\n",
    "        self.classes_num = CLASSES_NUM #21\n",
    "        \n",
    "        self.img_generator = Img_generator() #IoU\n",
    "        self.object_load = Object_load()\n",
    "        self.alexnet = Alexnet_finetune()\n",
    "        \n",
    "        self.svms = [] #svm集合 20个类别 就有20个svm\n",
    "        \n",
    "        #防止显存溢出添加\n",
    "        self.resource_threshold_shape_0 = 800 #候选框超过800 将其拆分为两块处理 #1000还是有点大\n",
    "        \n",
    "        #self.train_all_svm() #自调\n",
    "        \n",
    "    def train_svm_with_label(self , label):\n",
    "        if os.path.exists('qp/svm_model/svm_%d.m' % label):\n",
    "            #模型已经存在 载入即可\n",
    "            print('exist,loading......')\n",
    "            self.svms.append(joblib.load('qp/svm_model/svm_%d.m' % label))\n",
    "            \n",
    "            print('finish loading')\n",
    "            return \n",
    "        \n",
    "        imgs_path = self.object_load.load(label)\n",
    "        \n",
    "        '''\n",
    "        自平衡训练数据\n",
    "        概率项设为True 概率值供后续nms使用\n",
    "        '''\n",
    "        svm = SVC(probability = True , class_weight='balanced') #为True能输出类别的概率值 自动平衡训练数据\n",
    "        \n",
    "        #没有model的保存数据就先训练\n",
    "        if not os.path.exists('qp/finetune_alexnet/checkpoint'):\n",
    "            self.alexnet.train() \n",
    "            \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            self.alexnet.saver.restore(sess , tf.train.latest_checkpoint('qp/finetune_alexnet/')) #读取模型整个model的模型参数\n",
    "            \n",
    "            scores = 0.0 #debug\n",
    "            count = 0 #debug\n",
    "            \n",
    "            images_count = len(imgs_path) #debug\n",
    "            step = 0 #debug\n",
    "            \n",
    "            for path in imgs_path:\n",
    "                print('No.%d/%d' % (step , images_count)) #debug\n",
    "                step = step+1 #debug\n",
    "                \n",
    "                #每次使用label类型的一张图片进行训练\n",
    "                #将所有的label对应的图片全部训练完\n",
    "                regions , labels = self.img_generator.one_img_rect_region_label_svm(path , label)\n",
    "                \n",
    "                if np.sum(labels) == label*len(labels) or np.sum(labels) == 0:\n",
    "                    #说明所有的label都一样 那就不训练了 而且fit函数报错\n",
    "                    continue\n",
    "                \n",
    "                #显存太小 不得不增加判断逻辑 这会增加运行时间\n",
    "                \n",
    "                '''\n",
    "                if regions.shape[0] > self.resource_threshold_shape_0:\n",
    "                    #拆开运行训练\n",
    "                    for idx in range(regions.shape[0] // self.resource_threshold_shape_0):\n",
    "                        labels_sum = np.sum(labels[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0])\n",
    "                        \n",
    "                        if labels_sum == label*self.resource_threshold_shape_0 or labels_sum == 0:\n",
    "                            #所有的label全部一样 sklearn中svm报错\n",
    "                            continue\n",
    "                        \n",
    "                        regions_cnn_features_block = sess.run(self.alexnet.features , feed_dict={self.alexnet.x : regions[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0] , self.alexnet.keep_prob:1.0})\n",
    "                        svm.fit(regions_cnn_features_block , labels[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0])\n",
    "\n",
    "                        scores = scores + svm.score(regions_cnn_features_block , labels[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0])\n",
    "                        count = count+1\n",
    "                    \n",
    "                    #余下的部分（不是整的）\n",
    "                    labels_sum = np.sum(labels[(idx+1)*self.resource_threshold_shape_0:])\n",
    "                    if labels_sum == label*len(labels[(idx+1)*self.resource_threshold_shape_0:]) or labels_sum == 0:\n",
    "                        continue\n",
    "                            \n",
    "                    regions_cnn_features_extra = sess.run(self.alexnet.features , feed_dict={self.alexnet.x : regions[(idx+1)*self.resource_threshold_shape_0:] , self.alexnet.keep_prob:1.0})\n",
    "                    svm.fit(regions_cnn_features_extra , labels[(idx+1)*self.resource_threshold_shape_0:])\n",
    "                    \n",
    "                    scores = scores + svm.score(regions_cnn_features_extra , labels[(idx+1)*self.resource_threshold_shape_0:])\n",
    "                    count = count+1\n",
    "                \n",
    "                else:\n",
    "                    regions_cnn_features = sess.run(self.alexnet.features , feed_dict={self.alexnet.x : regions , self.alexnet.keep_prob:1.0})\n",
    "                    svm.fit(regions_cnn_features , labels)\n",
    "\n",
    "                    scores = scores + svm.score(regions_cnn_features , labels)\n",
    "                    count = count+1\n",
    "                '''\n",
    "                \n",
    "                '''batch数量 先限制在128'''\n",
    "                if regions.shape[0] >= 128:\n",
    "                    '''\n",
    "                    svm要求数据集中类别不能一样\n",
    "                    '''\n",
    "                    if np.sum(labels[: 128]) == 128*label or np.sum(labels[: 128]) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    regions_cnn_features = sess.run(self.alexnet.features , feed_dict={self.alexnet.x : regions[ : 128] , self.alexnet.keep_prob:1.0})\n",
    "                    \n",
    "                    svm.fit(regions_cnn_features , labels[: 128])\n",
    "\n",
    "                    count = count + 1\n",
    "                else:\n",
    "                    '''\n",
    "                    svm要求数据集中类别不能一样\n",
    "                    '''\n",
    "                    \n",
    "                    if np.sum(labels) == 128*label or np.sum(labels) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    \n",
    "                    regions_bak = np.copy(regions)\n",
    "                    labels_bak = np.copy(labels)\n",
    "                    \n",
    "                    _add_count = int( np.floor(128 / regions.shape[0]) )\n",
    "                    \n",
    "                    for i in range(_add_count):\n",
    "                        regions = np.concatenate((regions , regions))\n",
    "                        \n",
    "                        labels = np.concatenate((labels , labels))\n",
    "                    \n",
    "                    \n",
    "                    regions_cnn_features = sess.run(self.alexnet.features , feed_dict={self.alexnet.x : regions[ : 128] , self.alexnet.keep_prob:1.0})\n",
    "\n",
    "                    svm.fit(regions_cnn_features , labels[: 128])\n",
    "\n",
    "                    count = count + 1\n",
    "                    \n",
    "                \n",
    "                #np.copy() #不需要重新拷贝回去 因为重新赋值了\n",
    "                \n",
    "        try:\n",
    "            print('label:%s average_score:%f' % (LABEL2STR[label] , scores/count)) #debug\n",
    "        except ZeroDivisionError:\n",
    "            pass #这里不会被执行到\n",
    "\n",
    "        #先存到变量中 再保存至磁盘\n",
    "        self.svms.append(svm)\n",
    "        joblib.dump(svm , 'qp/svm_model/svm_%d.m' % label) #将svm保存起来\n",
    "\n",
    "    \n",
    "    def train_all_svm(self):\n",
    "        svms_path = glob('qp/svm_model/*.m')\n",
    "        \n",
    "        if len(svms_path) == len(LABEL2STR) - 1: #==20\n",
    "            #存在已经训练好的模型 就不再训练了 直接读取训练好的模型即可\n",
    "            print('loading all model......')\n",
    "            \n",
    "            for label in range(1 , len(LABEL2STR)):\n",
    "                path = 'qp/svm_model\\svm_%d.m' % label\n",
    "                print('loading %s model ......' % path)\n",
    "                self.svms.append(joblib.load(path))\n",
    "                \n",
    "            print('finish loading')\n",
    "            return \n",
    "        \n",
    "        for label in range(1 , len(LABEL2STR)):\n",
    "            self.train_svm_with_label(label)\n",
    "    \n",
    "    '''\n",
    "    推理阶段使用\n",
    "    '''\n",
    "    def nms(self , rects_hat , probability_hat): #已降序处理\n",
    "        #非极大值抑制 #在同一个label之间进行抑制\n",
    "        final_rects_hat = []\n",
    "        final_probability_hat = [] #应该用不上了\n",
    "        \n",
    "        length = len(probability_hat)\n",
    "        lost_flag = [1]*length #标记丢弃的框\n",
    "        \n",
    "        max_score_idx = 0 #记录当前最大score的idx\n",
    "        \n",
    "        while max_score_idx < length:\n",
    "            max_score_rect = rects_hat[max_score_idx]\n",
    "            \n",
    "            for i in range(max_score_idx+1 , length): #rects_hat[max_score_idx:]:\n",
    "                if lost_flag[i] == 1 and self.img_generator.IoU( max_score_rect , rects_hat[i] ) > NMS_IoU_THRESHOLD: #大于阈值 丢弃\n",
    "                    lost_flag[i] = 0\n",
    "\n",
    "            max_score_idx_bak = max_score_idx #后续使用\n",
    "            \n",
    "            #让max_score_idx指向下一个没被丢弃的最大值\n",
    "            for i in range(max_score_idx+1 , length):\n",
    "                if lost_flag[i] == 1:\n",
    "                    max_score_idx = i\n",
    "                    break\n",
    "            \n",
    "            #说明max_score_idx没有移动过 即后续的都被丢弃了\n",
    "            if max_score_idx == max_score_idx_bak:\n",
    "                break\n",
    "        \n",
    "        for i in range(length):\n",
    "            if lost_flag[i] == 1:\n",
    "                final_rects_hat.append(rects_hat[i])\n",
    "                final_probability_hat.append(probability_hat[i])\n",
    "                \n",
    "        return np.array(final_rects_hat) , np.array(final_probability_hat)\n",
    "    \n",
    "    def __meta_predict(self , regions_cnn_features , svm , rects): #proposal*4096\n",
    "        labels = svm.predict(regions_cnn_features) #预言的labels 含有背景和object\n",
    "        \n",
    "        #print(labels) #debug\n",
    "        \n",
    "        probability = svm.predict_proba(regions_cnn_features) #概率信息 为NMS做准备\n",
    "        \n",
    "        #print(probability) #debug\n",
    "        \n",
    "        rects_hat = [] #label对应不是背景的标记框 才予以显示和bbox回归 label是背景的候选框不需要进行bbox回归\n",
    "        probability_hat = [] #label对应不是背景的概率值 NMS score需要\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] != 0: #不是背景\n",
    "                rects_hat.append(rects[i])\n",
    "                probability_hat.append(np.max(probability[i]))\n",
    "        \n",
    "        rects_hat = np.array(rects_hat)\n",
    "        probability_hat = np.array(probability_hat)\n",
    "        \n",
    "        if len(probability_hat) != 0:\n",
    "            sorted_idx = np.argsort(probability_hat) #对概率进行升序排列 NMS score使用\n",
    "            #框坐标和概率score都升序\n",
    "            rects_hat = rects_hat[sorted_idx][::-1] #降序\n",
    "            probability_hat = probability_hat[sorted_idx][::-1] #降序\n",
    "        \n",
    "        return rects_hat , probability_hat #返回非背景的候选框 每个候选框的概率值\n",
    "\n",
    "    def predict(self , path):\n",
    "        #rects regions\n",
    "        img_arr , proposals , proposals_region = self.img_generator.one_img_rect_region(path) #原图像数据 候选框坐标 候选框数据\n",
    "        regions_cnn_features = self.alexnet.extract_feature(proposals_region)\n",
    "        \n",
    "        all_rects_hat_and_proba_and_labels = [] #框坐标 标记 概率值\n",
    "        \n",
    "        #使用所有的svm\n",
    "        for label in range(1 , len(LABEL2STR)): #20\n",
    "            rects_hat , probability_hat = self.__meta_predict(regions_cnn_features , self.svms[label-1] , proposals)\n",
    "            \n",
    "            nms_rects_hat , nms_probability_hat = self.nms(rects_hat , probability_hat)\n",
    "            '''\n",
    "            nms_probability_hat暂无用\n",
    "            可以显示在预测的框子角 显示概率值\n",
    "            '''\n",
    "            \n",
    "            #每一个元素是label对用的 一堆框子坐标 一堆框子对应的概率 一个label\n",
    "            all_rects_hat_and_proba_and_labels.append( (nms_rects_hat , nms_probability_hat , label ) )\n",
    "            \n",
    "        return all_rects_hat_and_proba_and_labels , img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_set = SVM_set()\n",
    "#display_demo = Display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from qp/finetune_alexnet/model_epoch.ckpt\n",
      "No.0/1994\n",
      "No.1/1994\n",
      "No.2/1994\n",
      "No.3/1994\n",
      "No.4/1994\n",
      "No.5/1994\n",
      "No.6/1994\n",
      "No.7/1994\n",
      "No.8/1994\n",
      "No.9/1994\n",
      "No.10/1994\n",
      "No.11/1994\n",
      "No.12/1994\n",
      "No.13/1994\n",
      "No.14/1994\n",
      "No.15/1994\n",
      "No.16/1994\n",
      "No.17/1994\n",
      "No.18/1994\n",
      "No.19/1994\n",
      "No.20/1994\n",
      "No.21/1994\n",
      "No.22/1994\n",
      "No.23/1994\n",
      "No.24/1994\n",
      "No.25/1994\n",
      "No.26/1994\n",
      "No.27/1994\n",
      "No.28/1994\n",
      "No.29/1994\n",
      "No.30/1994\n",
      "No.31/1994\n",
      "No.32/1994\n",
      "No.33/1994\n",
      "No.34/1994\n",
      "No.35/1994\n",
      "No.36/1994\n",
      "No.37/1994\n",
      "No.38/1994\n",
      "No.39/1994\n",
      "No.40/1994\n",
      "No.41/1994\n",
      "No.42/1994\n"
     ]
    }
   ],
   "source": [
    "s_set.train_all_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n"
     ]
    }
   ],
   "source": [
    "all_rects_hat_and_proba_and_labels , img_arr = s_set.predict('person.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([], dtype=float64), array([], dtype=float64), 1),\n",
       " (array([], dtype=float64), array([], dtype=float64), 2),\n",
       " (array([], dtype=float64), array([], dtype=float64), 3),\n",
       " (array([], dtype=float64), array([], dtype=float64), 4),\n",
       " (array([], dtype=float64), array([], dtype=float64), 5),\n",
       " (array([], dtype=float64), array([], dtype=float64), 6),\n",
       " (array([], dtype=float64), array([], dtype=float64), 7),\n",
       " (array([], dtype=float64), array([], dtype=float64), 8),\n",
       " (array([], dtype=float64), array([], dtype=float64), 9),\n",
       " (array([], dtype=float64), array([], dtype=float64), 10),\n",
       " (array([], dtype=float64), array([], dtype=float64), 11),\n",
       " (array([], dtype=float64), array([], dtype=float64), 12),\n",
       " (array([], dtype=float64), array([], dtype=float64), 13),\n",
       " (array([], dtype=float64), array([], dtype=float64), 14),\n",
       " (array([], dtype=float64), array([], dtype=float64), 15),\n",
       " (array([], dtype=float64), array([], dtype=float64), 16),\n",
       " (array([], dtype=float64), array([], dtype=float64), 17),\n",
       " (array([], dtype=float64), array([], dtype=float64), 18),\n",
       " (array([], dtype=float64), array([], dtype=float64), 19),\n",
       " (array([], dtype=float64), array([], dtype=float64), 20)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rects_hat_and_proba_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_demo = Display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_demo.display_svm(img_arr , all_rects_hat_and_proba_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bounding-box回归\n",
    "class Bbox_regression(object):\n",
    "    def __init__(self):\n",
    "        self.ridges = [] #pascal voc 20类别就使用20个线性回归\n",
    "        \n",
    "        self.object_load = Object_load()\n",
    "        self.img_generator = Img_generator()\n",
    "        self.svm_set = SVM_set()\n",
    "        #self.alexnet = Alexnet_finetune()\n",
    "        self.pr_generator = Clip()\n",
    "        \n",
    "        self.resource_threshold_shape_0 = 800 #同svm类\n",
    "        \n",
    "        self.train_all_ridge() #自调\n",
    "        \n",
    "    def train_ridge_with_label(self , label):\n",
    "        ##if os.path.exists('../RCNN/qp/linear_model/ridge_%d.m' % label):\n",
    "        ##    #模型已经存在 载入即可\n",
    "        ##    print('exist,loading......')\n",
    "        ##    self.ridges.append(joblib.load('../RCNN/qp/linear_model/ridge_%d.m' % label))\n",
    "        ##    \n",
    "        ##    print('finish loading')\n",
    "        ##    return \n",
    "        \n",
    "        imgs_path = self.object_load.load(label)\n",
    "        \n",
    "        ridge = Ridge(alpha=1000) #正则参数为1000\n",
    "        \n",
    "        #没有model的保存数据就先训练\n",
    "        if not os.path.exists('qp/finetune_alexnet/checkpoint'):\n",
    "            self.svm_set.alexnet.train() \n",
    "            \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            self.svm_set.alexnet.saver.restore(sess , tf.train.latest_checkpoint('qp/finetune_alexnet/')) #读取模型整个model的模型参数\n",
    "\n",
    "            scores = 0.0 #debug\n",
    "            count = 0 #debug\n",
    "            \n",
    "            images_count = len(imgs_path) #debug\n",
    "            step = 0 #debug\n",
    "            \n",
    "            for path in imgs_path:\n",
    "                print('No.%d/%d' % (step , images_count)) #debug\n",
    "                step = step+1 #debug\n",
    "                #regions\n",
    "                proposals_region , targets = self.img_generator.one_img_rect_region_label_bnd(path , label)\n",
    "                \n",
    "                if len(proposals_region) == 0:\n",
    "                    #没有数据\n",
    "                    continue\n",
    "                \n",
    "                #显存太小 不得不增加判断逻辑 这会增加运行时间\n",
    "                if proposals_region.shape[0] > self.resource_threshold_shape_0:\n",
    "                    #拆开运行训练\n",
    "                    for idx in range(proposals_region.shape[0] // self.resource_threshold_shape_0):\n",
    "                        regions_cnn_features_block = sess.run(self.svm_set.alexnet.features , feed_dict={self.svm_set.alexnet.x : proposals_region[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0] , self.svm_set.alexnet.keep_prob:1.0})\n",
    "                        \n",
    "                        ridge.fit(regions_cnn_features_block , targets[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0])\n",
    "                        scores = scores + ridge.score(regions_cnn_features_block , targets[idx*self.resource_threshold_shape_0 : (idx+1)*self.resource_threshold_shape_0])\n",
    "                        \n",
    "                        count = count+1\n",
    "                    \n",
    "                    #余下的部分（不是整的） \n",
    "                    regions_cnn_features_extra = sess.run(self.svm_set.alexnet.features , feed_dict={self.svm_set.alexnet.x : proposals_region[(idx+1)*self.resource_threshold_shape_0:] , self.svm_set.alexnet.keep_prob:1.0})\n",
    "                    ridge.fit(regions_cnn_features_extra , targets[(idx+1)*self.resource_threshold_shape_0:])\n",
    "                    scores = scores + ridge.score(regions_cnn_features_extra , targets[(idx+1)*self.resource_threshold_shape_0:])\n",
    "                    \n",
    "                    count = count+1\n",
    "                \n",
    "                else:\n",
    "                    regions_cnn_features = sess.run(self.svm_set.alexnet.features , feed_dict={self.svm_set.alexnet.x : proposals_region , self.svm_set.alexnet.keep_prob:1.0})\n",
    "                    ridge.fit(regions_cnn_features , targets)\n",
    "                    scores = scores + ridge.score(regions_cnn_features , targets)\n",
    "\n",
    "                    count = count+1\n",
    "                    \n",
    "        try:\n",
    "            print('label:%s average_score:%f' % (LABEL2STR[label] , scores/count)) #debug\n",
    "        except ZeroDivisionError:\n",
    "            pass #这里不会被执行到    \n",
    "        \n",
    "        self.ridges.append(ridge)\n",
    "        \n",
    "        joblib.dump(ridge , 'qp/linear_model/ridge_%d.m' % label) #将ridge保存起来\n",
    "    \n",
    "    def train_all_ridge(self):\n",
    "        ridges_path = glob('qp/linear_model/*.m')\n",
    "        \n",
    "        if len(ridges_path) == len(LABEL2STR) - 1:\n",
    "            #存在已经训练好的模型 就不再训练了 直接读取训练好的模型即可\n",
    "            print('loading all model......')\n",
    "            \n",
    "            for label in range(1 , len(LABEL2STR)):\n",
    "                path = 'qp/linear_model/ridge_%d.m' % label\n",
    "                print('loading %s model ......' % path)\n",
    "                self.ridges.append(joblib.load(path))\n",
    "                \n",
    "            print('finish loading')\n",
    "            return \n",
    "        \n",
    "        for label in range(1 , len(LABEL2STR)):\n",
    "            self.train_ridge_with_label(label)\n",
    "    \n",
    "    '''\n",
    "    推理阶段使用\n",
    "    '''\n",
    "    def __meta_predict(self , regions_cnn_features , rects , ridge):\n",
    "        def to(rect):\n",
    "            x1 = rect[0]\n",
    "            x2 = rect[1]\n",
    "            y1 = rect[2]\n",
    "            y2 = rect[3]\n",
    "            \n",
    "            w = x2-x1\n",
    "            h = y2-y1\n",
    "            \n",
    "            x_c = (x1+x2)//2\n",
    "            y_c = (y1+y2)//2\n",
    "            \n",
    "            return x_c , y_c , w , h\n",
    "        \n",
    "        def ot(target):\n",
    "            x_c = target[0]\n",
    "            y_c = target[1]\n",
    "            w = target[2]\n",
    "            h = target[3]\n",
    "            \n",
    "            x1 = 0.5*(2*x_c-w)\n",
    "            y1 = 0.5*(2*y_c-h)\n",
    "            x2 = x1+w\n",
    "            y2 = y1+h\n",
    "            \n",
    "            x1=int(round(x1))\n",
    "            y1=int(round(y1))\n",
    "            x2=int(round(x2))\n",
    "            y2=int(round(y2))\n",
    "            \n",
    "            if x1<0:\n",
    "                x1 = 0\n",
    "            if x2>WIDTH:\n",
    "                x2 = WIDTH\n",
    "            if y1<0:\n",
    "                y1 = 0\n",
    "            if y2>HEIGHT:\n",
    "                y2 = HEIGHT\n",
    "            \n",
    "        \n",
    "            return [x1 , x2 , y1 , y2]\n",
    "        \n",
    "        def target2rect(target_hat , P_box):\n",
    "            t_x = target_hat[0]\n",
    "            t_y = target_hat[1]\n",
    "            t_w = target_hat[2]\n",
    "            t_h = target_hat[3]\n",
    "            \n",
    "            P_x , P_y , P_w , P_h = to(P_box)\n",
    "            \n",
    "            G_x_hat = P_w*t_x+P_x\n",
    "            G_y_hat = P_h*t_y+P_y\n",
    "            G_w_hat = P_w*np.exp(t_w)\n",
    "            G_h_hat = P_h*np.exp(t_h)\n",
    "            \n",
    "            return ot([G_x_hat , G_y_hat , G_w_hat , G_h_hat]) #ot还需要转化为(x1,x2,y1,y2)形式\n",
    "        \n",
    "        #由每一个 与label对应的ridge 预测的结果\n",
    "        target_hat = ridge.predict(regions_cnn_features)\n",
    "        rect_hat = []\n",
    "        \n",
    "        #使用预测结果对框子进行调整\n",
    "        for i in range(len(target_hat)):\n",
    "            rect_hat.append(target2rect(target_hat[i] , rects[i]))\n",
    "            \n",
    "        return np.array(rect_hat)\n",
    "    \n",
    "    \n",
    "    def predict(self , path):\n",
    "        '''\n",
    "        svm的nms之后进行bounding box回归\n",
    "        '''\n",
    "        \n",
    "        #预测的框 概率 label\n",
    "        all_rects_hat_and_proba_and_labels , img_arr=self.svm_set.predict(path)\n",
    "        \n",
    "        print('finish svm') #debug\n",
    "        bbox_r_rects_hat_and_label = []\n",
    "        \n",
    "        for (nms_rects_hat , _ , label) in all_rects_hat_and_proba_and_labels:\n",
    "            \n",
    "            if len(nms_rects_hat) == 0:\n",
    "                #说明此图像不存在此label\n",
    "                bbox_r_rects_hat_and_label.append((np.array([]) , label))\n",
    "                continue \n",
    "            \n",
    "            nms_rects_hat_region = self.pr_generator.clip_region(img_arr , nms_rects_hat)\n",
    "            \n",
    "            nms_rects_hat_region_cnn_features = self.svm_set.alexnet.extract_feature(nms_rects_hat_region)\n",
    "    \n",
    "            nms_rects_hat_bb_r = self.__meta_predict(nms_rects_hat_region_cnn_features , nms_rects_hat , self.ridges[label-1])\n",
    "        \n",
    "            '''\n",
    "            最终的预测框子和label信息\n",
    "            '''\n",
    "            #一个元素为一个label对应的 一堆经过调整的框子 一个label\n",
    "            bbox_r_rects_hat_and_label.append((nms_rects_hat_bb_r , label))\n",
    "    \n",
    "        return bbox_r_rects_hat_and_label , img_arr #最终的框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-b9e9d786f6a6>:42: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "INFO:tensorflow:Summary name fc7/weights:0/gradient is illegal; using fc7/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0/gradient is illegal; using fc7/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0/gradient is illegal; using fc8/weights_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0/gradient is illegal; using fc8/biases_0/gradient instead.\n",
      "INFO:tensorflow:Summary name fc7/weights:0 is illegal; using fc7/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc7/biases:0 is illegal; using fc7/biases_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/weights:0 is illegal; using fc8/weights_0 instead.\n",
      "INFO:tensorflow:Summary name fc8/biases:0 is illegal; using fc8/biases_0 instead.\n",
      "loading all model......\n",
      "loading ../RCNN/qp/svm_model\\svm_1.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_2.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_3.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_4.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_5.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_6.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_7.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_8.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_9.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_10.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_11.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_12.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_13.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_14.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_15.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_16.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_17.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_18.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_19.m model ......\n",
      "loading ../RCNN/qp/svm_model\\svm_20.m model ......\n",
      "finish loading\n",
      "exist,loading......\n",
      "finish loading\n"
     ]
    }
   ],
   "source": [
    "bbox_r = Bbox_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "finish svm\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ../RCNN/qp/finetune_alexnet/model_epoch.ckpt\n"
     ]
    }
   ],
   "source": [
    "bbox_r_rects_hat_and_label , img_arr = bbox_r.predict('person.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display = Display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display.display_final(img_arr , bbox_r_rects_hat_and_label , name='xxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#效果展示\n",
    "class Display(object):\n",
    "    def __init__(self):\n",
    "        self.name_generator = self.__name_generator()\n",
    "    \n",
    "    def __name_generator(self):\n",
    "        for i in range(100000):\n",
    "            yield i\n",
    "    \n",
    "    def __meta_display(self , meta_img , labels , G_box , img_name):\n",
    "        #一幅图像中显示proposal个G框与label\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            x1 = G_box[i][0][0]\n",
    "            x2 = G_box[i][0][1]\n",
    "            y1 = G_box[i][0][2]\n",
    "            y2 = G_box[i][0][3]\n",
    "            #绘制G_box\n",
    "            meta_img = cv2.rectangle(meta_img , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "            #显示label字符串\n",
    "            meta_img = cv2.putText(meta_img , LABEL2STR[labels[i][0]] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "        \n",
    "        #plt.imshow(meta_img) #图像查看\n",
    "        \n",
    "        plt.imsave(arr=meta_img , fname = 'result/%s.jpg' % img_name) #保存图像\n",
    "        \n",
    "    #demo\n",
    "    def display(self , img , labels , G_box , img_names):\n",
    "        for i in range(img.shape[0]):\n",
    "            self.__meta_display(img[i] , labels[i] , G_box[i] , img_names[i])\n",
    "        \n",
    "    #demo\n",
    "    def display_svm(self , img , all_rects_hat_and_proba_and_labels , name='xxx'):\n",
    "        original_img = np.copy(img)\n",
    "        \n",
    "        for (nms_rects_hat , _ , label) in all_rects_hat_and_proba_and_labels:\n",
    "            img = np.copy(original_img)\n",
    "            \n",
    "            for (x1,x2,y1,y2) in nms_rects_hat:\n",
    "                img = cv2.rectangle(img , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "                img = cv2.putText(img , LABEL2STR[label] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "            \n",
    "            plt.imsave(arr=img[:,:,[2,1,0]] , fname = 'result/%s_%s.jpg' % (name , LABEL2STR[label])) #保存图像\n",
    "            \n",
    "    \n",
    "    #绘制20张图片 即20个类别中对应的类别中加框\n",
    "    def display_final(self , img_arr , bbox_r_rects_hat_and_label , name='xxx'):\n",
    "        label_i=1\n",
    "        original_img = np.copy(img_arr)\n",
    "        \n",
    "        for (rects_hat , label) in bbox_r_rects_hat_and_label:\n",
    "            img_arr = np.copy(original_img)\n",
    "            \n",
    "            for (x1,x2,y1,y2) in rects_hat:\n",
    "                img_arr = cv2.rectangle(img_arr , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "                img_arr = cv2.putText(img_arr , LABEL2STR[label] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "            \n",
    "            plt.imsave(arr=img_arr[:,:,[2,1,0]] , fname = 'result/%s_%s.jpg' % (name , LABEL2STR[label_i])) #保存图像\n",
    "            \n",
    "            label_i = label_i + 1\n",
    "        \n",
    "    def display_final_one(self , img_arr , bbox_r_rects_hat_and_label , name='xxx'):\n",
    "        label_i=1\n",
    "        img = np.copy(img_arr)\n",
    "        \n",
    "        for (rects_hat , label) in bbox_r_rects_hat_and_label:\n",
    "            for (x1,x2,y1,y2) in rects_hat:\n",
    "                img = cv2.rectangle(img , (x1 , y1) , (x2 , y2) , (255,255,255))\n",
    "                img = cv2.putText(img , LABEL2STR[label] , org=(x1 , y1+10) , fontFace = cv2.FONT_HERSHEY_PLAIN , fontScale=1 , color = (255,255,255), thickness = 1)\n",
    "            \n",
    "        plt.imsave(arr=img[:,:,[2,1,0]] , fname = 'result/%s.jpg' % name) #保存图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
