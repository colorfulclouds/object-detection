{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import xml\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STR = [\n",
    "    'person',\n",
    "    'bird','cat','cow','dog','horse','sheep',\n",
    "    'aeroplane','bicycle','boat','bus','car','motorbike','train',\n",
    "    'bottle','chair','diningtable','pottedplant','sofa','tvmonitor'\n",
    "]\n",
    "\n",
    "LABEL2STR = {idx:value for idx , value in enumerate(STR)}\n",
    "STR2LABEL = {value:key for key,value in LABEL2STR.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/JPEGImages/'\n",
    "TRAIN_XML_PATH = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xml_parse(xml_file):\n",
    "    xml_file = xml.dom.minidom.parse(xml_file)\n",
    "    xml_file_docu_ele = xml_file.documentElement\n",
    "\n",
    "    filename_list = xml_file_docu_ele.getElementsByTagName('filename')\n",
    "    #filename_list可能有多个filename的 所以要索引0(此数据集中filename只有一个)\n",
    "    filename = filename_list[0].childNodes[0].data #filename_list.firstChild.data\n",
    "\n",
    "    #图像的尺寸信息\n",
    "    size_list = xml_file_docu_ele.getElementsByTagName('size')\n",
    "\n",
    "    for size in size_list:\n",
    "        width_list = size.getElementsByTagName('width')\n",
    "        width = int(width_list[0].childNodes[0].data)\n",
    "\n",
    "        height_list = size.getElementsByTagName('height')\n",
    "        height = int(height_list[0].childNodes[0].data)\n",
    "\n",
    "        channel_list = size.getElementsByTagName('depth')\n",
    "        channel = int(channel_list[0].childNodes[0].data)\n",
    "\n",
    "    shape = (width , height , channel)\n",
    "\n",
    "    #一个文件中有多个object\n",
    "    object_list = xml_file_docu_ele.getElementsByTagName('object')\n",
    "\n",
    "    #多个object与多个object对应的详细信息\n",
    "    name_boxes = [] #一个元素就是一个object\n",
    "    crop_boxes = []\n",
    "\n",
    "    for objects in object_list:\n",
    "        #一次循环处理一个object信息\n",
    "        #一个xml文件（即一个图像中）有多个object\n",
    "\n",
    "        name_list = objects.getElementsByTagName('name')\n",
    "\n",
    "        #name_box中第0个元素是object的名称 后面的是详细物体part的名称\n",
    "        name_box = []\n",
    "\n",
    "        for i in range(len(name_list)):\n",
    "            name_box.append(name_list[i].childNodes[0].data)\n",
    "\n",
    "        bndbox = objects.getElementsByTagName('bndbox')\n",
    "\n",
    "        #crop_box中第0个元素是object的坐标 后面的为详细物体part的坐标\n",
    "        crop_box = []\n",
    "\n",
    "        for box in bndbox:\n",
    "\n",
    "            int(round(float('1.0542')))\n",
    "            x1_list = box.getElementsByTagName('xmin')\n",
    "            x1 = int( round( float(x1_list[0].childNodes[0].data) ) )\n",
    "\n",
    "            y1_list = box.getElementsByTagName('ymin')\n",
    "            y1 = int(round(float( y1_list[0].childNodes[0].data )))\n",
    "\n",
    "            x2_list = box.getElementsByTagName('xmax')\n",
    "            x2 = int(round(float( x2_list[0].childNodes[0].data )))\n",
    "\n",
    "            y2_list = box.getElementsByTagName('ymax')\n",
    "            y2 = int(round(float( y2_list[0].childNodes[0].data )))\n",
    "\n",
    "            crop_box.append([x1,x2,y1,y2])\n",
    "\n",
    "        name_boxes.append(name_box)\n",
    "        crop_boxes.append(crop_box)\n",
    "\n",
    "    return filename , shape , STR2LABEL[name_boxes[0][0]] , crop_boxes[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FAST = True\n",
    "ACCURATE = not FAST\n",
    "\n",
    "if FAST:\n",
    "    HEIGHT = 231\n",
    "    WIDTH = 231\n",
    "else:\n",
    "    HEIGHT = 221\n",
    "    WIDTH = 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#调整尺寸\n",
    "def resize(img , resize_type):\n",
    "    if resize_type == 'reg':\n",
    "        #resize_val 为(x,x)\n",
    "        return cv2.resize(img , (256,256))\n",
    "    \n",
    "    elif resize_type == 'min':\n",
    "        #resize_val scalar\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        ratio = height / width\n",
    "        \n",
    "        if height<width:\n",
    "            new_shape = (256 , int(256.0/ratio))\n",
    "        else:\n",
    "            new_shape = (int(256.0*ratio) , 256)\n",
    "        \n",
    "        return cv2.resize(img , new_shape)\n",
    "    \n",
    "    elif resize_type == 'max':\n",
    "        #resize_val scalar\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        ratio = height / width\n",
    "        \n",
    "        if height<width:\n",
    "            new_shape = (int(256.0*ratio) , 256)\n",
    "        else:\n",
    "            new_shape = (256 , int(256.0/ratio))\n",
    "            \n",
    "        return cv2.resize(img , new_shape)\n",
    "        \n",
    "#随机裁剪\n",
    "#def random_clip(img , crop_size):\n",
    "#    shape = img.shape\n",
    "#    \n",
    "#    if shape[0] == crop_size[0] and shape[1] == crop_size[1]:\n",
    "#        return img\n",
    "#    \n",
    "#    height_clip_domain = shape[0]-crop_size[0]\n",
    "#    width_clip_domain = shape[1]-crop_size[1]\n",
    "#    \n",
    "#    height_clip_idx = np.random.randint(0 , height_clip_domain)\n",
    "#    width_clip_idx = np.random.randint(0 , width_clip_domain)\n",
    "#    \n",
    "#    return img[height_clip_idx : height_clip_idx+crop_size[0] , width_clip_idx : width_clip_idx+crop_size[1] , :]\n",
    "\n",
    "\n",
    "def central_clip(img , crop_size):\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    \n",
    "    height_r = img_height - crop_size[0]\n",
    "    width_r = img_width - crop_size[1]\n",
    "    \n",
    "    top = height_r//2\n",
    "    left = width_r//2\n",
    "    \n",
    "    return img[top : top+crop_size[0] , left : left+crop_size[1] , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(train_size = 0.8):\n",
    "    # xml文件\n",
    "    filenames = glob(pathname = '../../tensorflow2/dataset/VOCtrainval_11-May-2012/Annotations/*.xml')\n",
    "    filenames = np.array(filenames)\n",
    "    \n",
    "    idx = list(range(len(filenames)))\n",
    "    np.random.shuffle(idx)    \n",
    "    \n",
    "    train_idx = idx[ : int(len(idx) * train_size)]\n",
    "    val_idx = idx[int(len(idx) * train_size) : ]\n",
    "    \n",
    "    return filenames[train_idx] , filenames[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_train(img , bbox):\n",
    "    #训练数据预处理\n",
    "    \n",
    "    shape = img.shape\n",
    "    height_ratio = HEIGHT/shape[0]\n",
    "    width_ratio = WIDTH/shape[1]\n",
    "    \n",
    "    img = cv2.resize(img , (HEIGHT , WIDTH))\n",
    "    #img = resize(img , 'max')\n",
    "    #img = central_clip(img , crop_size=(HEIGHT , WIDTH))\n",
    "    #img = random_clip(img , crop_size=(HEIGHT , WIDTH , 3))\n",
    "    \n",
    "    img = img/127.5 - 1.0\n",
    "    \n",
    "    bbox[0] = float(int(bbox[0]*width_ratio))\n",
    "    bbox[2] = float(int(bbox[2]*width_ratio))\n",
    "    \n",
    "    bbox[1] = float(int(bbox[1]*height_ratio))\n",
    "    bbox[3] = float(int(bbox[3]*height_ratio))\n",
    "    \n",
    "    return img , bbox\n",
    "    \n",
    "\n",
    "def preprocess_val(img , bbox):\n",
    "    #验证数据预处理\n",
    "    \n",
    "    shape = img.shape\n",
    "    height_ratio = HEIGHT/shape[0]\n",
    "    width_ratio = WIDTH/shape[1]\n",
    "    \n",
    "    img = cv2.resize(img , (HEIGHT , WIDTH))\n",
    "    #img = resize(img , 'max')\n",
    "    #img = central_clip(img , crop_size=(HEIGHT , WIDTH))\n",
    "    #img = random_clip(img , crop_size=(HEIGHT , WIDTH , 3))\n",
    "    \n",
    "    img = img/127.5 - 1.0\n",
    "    \n",
    "    bbox[0] = float(int(bbox[0]*width_ratio))\n",
    "    bbox[2] = float(int(bbox[2]*width_ratio))\n",
    "    \n",
    "    bbox[1] = float(int(bbox[1]*height_ratio))\n",
    "    bbox[3] = float(int(bbox[3]*height_ratio))\n",
    "    # img = central_clip(img , crop_size=(HEIGHT , WIDTH))\n",
    "    \n",
    "    return img , bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filenames , val_filenames = split_data(train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_num = len(train_filenames)\n",
    "val_num = len(val_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size , is_training = True):\n",
    "    data = []\n",
    "    bboxes = []\n",
    "    \n",
    "    if is_training:\n",
    "        #训练数据随机索引\n",
    "        shuffle_idx = np.random.randint(low=0 , high=train_num , size=batch_size)\n",
    "        \n",
    "        for i in shuffle_idx:\n",
    "            filename , _ , _ , bbox = xml_parse(train_filenames[i]) # _ shape label _\n",
    "            \n",
    "            img = cv2.imread(TRAIN_DATA_PATH + filename)\n",
    "            img , bbox = preprocess_train(img , bbox)\n",
    "            \n",
    "            data.append(img)\n",
    "            bboxes.append(bbox)\n",
    "            \n",
    "        return np.array(data) , np.array(bboxes)\n",
    "            \n",
    "    else:\n",
    "        #验证数据随机索引\n",
    "        shuffle_idx = np.random.randint(low=0 , high=val_num , size=batch_size)\n",
    "        \n",
    "        for i in shuffle_idx:\n",
    "            filename , _ , _ , bbox = xml_parse(val_filenames[i])\n",
    "            \n",
    "            img = cv2.imread(TRAIN_DATA_PATH + filename)\n",
    "            img , bbox = preprocess_val(img , bbox)\n",
    "            \n",
    "            data.append(img)\n",
    "            bboxes.append(bbox)\n",
    "            \n",
    "        return np.array(data) , np.array(bboxes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OverFeat(object):\n",
    "\n",
    "    def __init__(self , num_classes , model_type = 'fast'):\n",
    "        self.TYPE = model_type\n",
    "        \n",
    "        self.EPOCH = 90 #paper\n",
    "        \n",
    "        self.BATCH_SIZE = 128\n",
    "                \n",
    "        self.KEEP_PROB = 0.5\n",
    "        \n",
    "        if model_type == 'accurate':\n",
    "            self.HEIGHT = 221\n",
    "            self.WIDTH = 221\n",
    "            \n",
    "            self.X = tf.placeholder(dtype=tf.float32 , shape=(None , self.HEIGHT , self.WIDTH , 3))\n",
    "            self.y = tf.placeholder(dtype=tf.float32 , shape=(None , 4)) #tensorflow完成one-hot\n",
    "        \n",
    "            self.model_accurate()\n",
    "        else:\n",
    "            self.HEIGHT = 231\n",
    "            self.WIDTH = 231\n",
    "            \n",
    "            self.X = tf.placeholder(dtype=tf.float32 , shape=(None , self.HEIGHT , self.WIDTH , 3))\n",
    "            self.y = tf.placeholder(dtype=tf.float32 , shape=(None , 4)) #tensorflow完成one-hot\n",
    "            \n",
    "            self.model_fast()\n",
    "\n",
    "    def model_fast(self):\n",
    "        conv1 = self.conv(self.X , 11 , 11 , 96 , 4 , 4 , name='conv1')\n",
    "        max_pooling1 = self.max_pooling(conv1 , 2 , 2 , 2 , 2 , name='pooling1')\n",
    "        \n",
    "        conv2 = self.conv(max_pooling1 , 5 , 5 , 256 , 1 , 1 , name='conv2')\n",
    "        max_pooling2 = self.max_pooling(conv2 , 2 , 2 , 2 , 2 , name='pooling2')\n",
    "        \n",
    "        conv3 = self.conv(max_pooling2 , 3 , 3 , 512 , 1 , 1 , name='conv3')\n",
    "        \n",
    "        conv4 = self.conv(conv3 , 3 , 3 , 1024 , 1 , 1 , name='conv4')\n",
    "    \n",
    "        conv5 = self.conv(conv4 , 3 , 3 , 1024 , 1 , 1 , name='conv5')\n",
    "        max_pooling5 = self.max_pooling(conv5 , 2 , 2 , 2 , 2 , name='pooling5')\n",
    "        \n",
    "        #conv6 = self.fcn(max_pooling5 , output_channel=3072 , name='fcn') #FCN形式 全连接变为卷积形式\n",
    "        #===\n",
    "        max_pooling5 = tf.layers.flatten(max_pooling5)\n",
    "        #===\n",
    "        \n",
    "        fc6 = self.fc(max_pooling5 , 1024 , name='fc6') #应该是4096 显卡不行\n",
    "        fc6 = tf.layers.dropout(fc6 , rate=1. - self.KEEP_PROB)\n",
    "            \n",
    "        fc7 = self.fc(fc6 , 1024 , name='fc7')\n",
    "        fc7 = tf.layers.dropout(fc7 , rate=1. - self.KEEP_PROB)\n",
    "        \n",
    "        fc8 = self.fc(fc7 , 4 , name='fc8')\n",
    "        \n",
    "        self.logits = fc8\n",
    "        \n",
    "    \n",
    "    def model_accurate(self):\n",
    "        conv1 = self.conv(self.X , 7 , 7 , 96 , 2 , 2 , name='conv1')\n",
    "        max_pooling1 = self.max_pooling(conv1 , 3 , 3 , 3 , 3 , name='pooling1')\n",
    "        \n",
    "        conv2 = self.conv(max_pooling1 , 7 , 7 , 256 , 1 , 1 , name='conv2')\n",
    "        max_pooling2 = self.max_pooling(conv2 , 2 , 2 , 2 , 2 , name='pooling2')\n",
    "        \n",
    "        conv3 = self.conv(max_pooling2 , 3 , 3 , 512 , 1 , 1 , name='conv3')\n",
    "        \n",
    "        conv4 = self.conv(conv3 , 3 , 3 , 512 , 1 , 1 , name='conv4')\n",
    "        \n",
    "        conv5 = self.conv(conv4 , 3 , 3 , 1024 , 1 , 1 , name='conv5')\n",
    "        \n",
    "        conv6 = self.conv(conv5 , 3 , 3 , 1024 , 1 , 1 , name='conv6')\n",
    "        max_pooling6 = self.max_pooling(conv6 , 3 , 3 , 3 , 3 , name='pooling6')\n",
    "        \n",
    "        #conv7 = self.fcn(max_pooling6 , output_channel = 4096 , name='fcn') #FCN形式 全连接变为卷积形式\n",
    "        #===\n",
    "        max_pooling6 = tf.layers.flatten(max_pooling6)\n",
    "        #===\n",
    "        \n",
    "        fc7 = self.fc(max_pooling6 , 4096 , name='fc7')\n",
    "        fc7 = tf.layers.dropout(fc7 , rate=1. - self.KEEP_PROB)\n",
    "        \n",
    "        fc8 = self.fc(fc7 , 1024 , name='fc8')\n",
    "        fc8 = tf.layers.dropout(fc8 , rate=1. - self.KEEP_PROB)\n",
    "                \n",
    "        fc9 = self.fc(fc8 , 4 , name='fc9')\n",
    "        \n",
    "        self.logits = fc9\n",
    "    \n",
    "    def train(self):\n",
    "        #训练使用\n",
    "        loss = tf.reduce_mean( tf.square(tf.subtract(self.y , self.logits)) )\n",
    "        #构建训练过程\n",
    "        \n",
    "        epoch = tf.Variable(initial_value=0 , name='epoch' , trainable=False)\n",
    "        epoch_add = tf.assign_add(epoch , value=1) #对epoch加1 因为下面的lr需要变化\n",
    "        \n",
    "        learning_rate = tf.train.piecewise_constant(epoch , boundaries=[30,50,60,70,80] ,\n",
    "                                                    values=[0.05,0.025,0.0125,0.00625,0.003125,0.0015625])\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate , momentum=0.6)\n",
    "        \n",
    "        train_op = optimizer.minimize(loss)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            for i in range(self.EPOCH):\n",
    "                \n",
    "                for j in range(train_num // self.BATCH_SIZE):\n",
    "                    \n",
    "                    data , labels = next_batch(batch_size=self.BATCH_SIZE)\n",
    "                                        \n",
    "                    _ , _loss = sess.run((train_op , loss) , feed_dict={self.X : data, self.y : labels})\n",
    "\n",
    "                    print(_loss)\n",
    "                        \n",
    "\n",
    "                #for k in range(val_num // self.BATCH_SIZE):\n",
    "                #    \n",
    "                #    data , labels = next_batch(batch_size=self.BATCH_SIZE , is_training=False)\n",
    "                #    \n",
    "                #    _loss = sess.run(loss , feed_dict={self.X : data, self.y : labels})\n",
    "\n",
    "                #    print('val' , _loss)\n",
    "    \n",
    "                sess.run(epoch_add)\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "    \n",
    "    def conv(self , x , filter_height , filter_width , output_channel , stride_height , stride_width , name , padding='same'):\n",
    "        \n",
    "        return tf.layers.conv2d(x , output_channel , [filter_height , filter_width] , [stride_height , stride_width] , padding=padding ,\n",
    "                             activation=tf.nn.relu , kernel_initializer = tf.initializers.random_normal(stddev=1e-2) ,\n",
    "                             bias_initializer = tf.initializers.constant() , kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=1e-5) ,\n",
    "                             name=name , reuse=tf.AUTO_REUSE)\n",
    "    \n",
    "        #input_channel = x.get_shape().as_list()[-1]\n",
    "        \n",
    "        #with tf.variable_scope(name) as scope:\n",
    "            #weights = tf.get_variable(name='weights' , shape=[filter_height , filter_width , input_channel , output_channel] , initializer=tf.random_normal_initializer(0.0 , 1e-2) , regularizer=tf.contrib.layers.l2_regularizer(scale=1e-5))\n",
    "            #biases = tf.get_variable(name='biases' , shape=[output_channel] , initializer=tf.constant_initializer())\n",
    "            #\n",
    "            #conv = tf.nn.conv2d(x , weights , strides=[1 , stride_height , stride_width , 1] , padding=padding)\n",
    "            #biases = tf.nn.bias_add(conv , biases)\n",
    "            #\n",
    "            #relu = tf.nn.relu(biases)\n",
    "            \n",
    "            #return relu\n",
    "            \n",
    "    #3*3 pooling\n",
    "    def max_pooling(self , x , pooling_height , pooling_width , stride_height , stride_width  , name , padding='same'):\n",
    "        #return tf.nn.max_pool(x , [1 , pooling_height , pooling_width , 1] , strides=[1 , stride_height , stride_width , 1] , padding=padding , name=name)\n",
    "        \n",
    "        return tf.layers.max_pooling2d(x , [pooling_height , pooling_width] , [stride_height , stride_width] , padding=padding , name=name)\n",
    "    \n",
    "    def fc(self , x , output_size , name):\n",
    "        \n",
    "        return tf.layers.dense(x , output_size , activation=tf.nn.relu , kernel_initializer=tf.initializers.random_normal(stddev=1e-2) ,\n",
    "                               bias_initializer = tf.initializers.constant() , kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=1e-5),\n",
    "                               name = name , reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "        #with tf.variable_scope(name) as scope:\n",
    "        #    weights = tf.get_variable(name='weights' , shape=[input_size , output_size] , initializer=tf.random_normal_initializer())\n",
    "        #    biases = tf.get_variable(name='biases' , shape=[output_size] , initializer=tf.constant_initializer())\n",
    "        #    \n",
    "        #    biases = tf.nn.bias_add(tf.matmul(x , weights) , biases)\n",
    "        #    \n",
    "        #    if relu:\n",
    "        #        return tf.nn.relu(biases)\n",
    "        #    else:\n",
    "        #        return biases\n",
    "        #\n",
    "    \n",
    "    #所有卷积层后紧跟的fc层变为卷积层方式\n",
    "    def fcn(self , x , output_channel , name , padding='same'):\n",
    "        if self.TYPE == 'accurate':\n",
    "            return tf.layers.conv2d(x , output_channel , [6 , 6] , [1 , 1] , padding=padding ,\n",
    "                             activation=tf.nn.relu , kernel_initializer = tf.initializers.random_normal(stddev=1e-2) ,\n",
    "                             bias_initializer = tf.initializers.constant() , kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=1e-5) ,\n",
    "                             name=name , reuse=tf.AUTO_REUSE)\n",
    "        else:\n",
    "            return tf.layers.conv2d(x , output_channel , [5 , 5] , [1 , 1] , padding=padding ,\n",
    "                             activation=tf.nn.relu , kernel_initializer = tf.initializers.random_normal(stddev=1e-2) ,\n",
    "                             bias_initializer = tf.initializers.constant() , kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=1e-5) ,\n",
    "                             name=name , reuse=tf.AUTO_REUSE)\n",
    "        \n",
    "    def batch_norm(self , x , name):\n",
    "        return tf.layers.batch_normalization(x , axis=-1 , training=self.IS_TRAINING , renorm=True , fused=True , name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overfeat = OverFeat(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24347.93\n",
      "26980.455\n",
      "248441000000000.0\n",
      "26741.86\n",
      "26207.928\n",
      "25236.951\n",
      "26365.08\n",
      "24358.262\n",
      "25823.287\n",
      "24814.4\n",
      "25126.688\n",
      "23460.188\n",
      "25595.904\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3f387b65df4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moverfeat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-92e8f0cf75f7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_num\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                     \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "overfeat.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
